{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionaries for aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_daily = {'AVERAGE' : ['AAA10Y', 'AAAFF', 'BAA10Y', 'BAAFF', 'BAMLEM1BRRAAA2ACRPIEY', 'BAMLEM1BRRAAA2ACRPIOAS', 'BAMLEM1BRRAAA2ACRPITRIV', 'BAMLEM1RAAA2ALCRPIUSEY', 'BAMLEM1RAAA2ALCRPIUSOAS', 'BAMLEM1RAAA2ALCRPIUSTRIV', 'BAMLEM2BRRBBBCRPIEY', 'BAMLEM2BRRBBBCRPIOAS', 'BAMLEM2BRRBBBCRPITRIV', 'BAMLEM2RBBBLCRPIUSEY', 'BAMLEM2RBBBLCRPIUSOAS', 'BAMLEM2RBBBLCRPIUSTRIV', 'BAMLEM3BRRBBCRPIEY', 'BAMLEM3BRRBBCRPIOAS', 'BAMLEM3BRRBBCRPITRIV', 'BAMLEM3RBBLCRPIUSEY', 'BAMLEM3RBBLCRPIUSOAS', 'BAMLEM3RBBLCRPIUSTRIV', 'BAMLEM4BRRBLCRPIEY', 'BAMLEM4BRRBLCRPIOAS', 'BAMLEM4BRRBLCRPITRIV', 'BAMLEM4RBLLCRPIUSEY', 'BAMLEM4RBLLCRPIUSOAS', 'BAMLEM4RBLLCRPIUSTRIV', 'BAMLEM5BCOCRPIEY', 'BAMLEM5BCOCRPIOAS', 'BAMLEM5BCOCRPITRIV', 'BAMLEMALLCRPIASIAUSEY', 'BAMLEMALLCRPIASIAUSOAS', 'BAMLEMALLCRPIASIAUSTRIV', 'BAMLEMCBPIEY', 'BAMLEMCBPIOAS', 'BAMLEMCLLCRPIUSEY', 'BAMLEMCLLCRPIUSOAS', 'BAMLEMEBCRPIEEY', 'BAMLEMEBCRPIEOAS', 'BAMLEMEBCRPIETRIV', 'BAMLEMELLCRPIEMEAUSEY', 'BAMLEMELLCRPIEMEAUSOAS', 'BAMLEMELLCRPIEMEAUSTRIV', 'BAMLEMFLFLCRPIUSEY', 'BAMLEMFLFLCRPIUSOAS', 'BAMLEMFLFLCRPIUSTRIV', 'BAMLEMFSFCRPIEY', 'BAMLEMFSFCRPIOAS', 'BAMLEMFSFCRPITRIV', 'BAMLEMHBHYCRPIEY', 'BAMLEMHBHYCRPIOAS', 'BAMLEMHBHYCRPITRIV', 'BAMLEMHGHGLCRPIUSEY', 'BAMLEMHGHGLCRPIUSOAS', 'BAMLEMHGHGLCRPIUSTRIV', 'BAMLEMHYHYLCRPIUSEY', 'BAMLEMHYHYLCRPIUSOAS', 'BAMLEMHYHYLCRPIUSTRIV', 'BAMLEMIBHGCRPIEY', 'BAMLEMIBHGCRPIOAS', 'BAMLEMIBHGCRPITRIV', 'BAMLEMLLLCRPILAUSEY', 'BAMLEMLLLCRPILAUSOAS', 'BAMLEMLLLCRPILAUSTRIV', 'BAMLEMNFNFLCRPIUSEY', 'BAMLEMNFNFLCRPIUSOAS', 'BAMLEMNFNFLCRPIUSTRIV', 'BAMLEMNSNFCRPIEY', 'BAMLEMNSNFCRPIOAS', 'BAMLEMNSNFCRPITRIV', 'BAMLEMPBPUBSICRPIEY', 'BAMLEMPBPUBSICRPIOAS', 'BAMLEMPBPUBSICRPITRIV', 'BAMLEMPTPRVICRPIEY', 'BAMLEMPTPRVICRPIOAS', 'BAMLEMPTPRVICRPITRIV', 'BAMLEMPUPUBSLCRPIUSEY', 'BAMLEMPUPUBSLCRPIUSOAS', 'BAMLEMPUPUBSLCRPIUSTRIV', 'BAMLEMPVPRIVSLCRPIUSEY', 'BAMLEMPVPRIVSLCRPIUSOAS', 'BAMLEMPVPRIVSLCRPIUSTRIV', 'BAMLEMRACRPIASIAEY', 'BAMLEMRACRPIASIAOAS', 'BAMLEMRACRPIASIATRIV', 'BAMLEMRECRPIEMEAEY', 'BAMLEMRECRPIEMEAOAS', 'BAMLEMRECRPIEMEATRIV', 'BAMLEMRLCRPILAEY', 'BAMLEMRLCRPILAOAS', 'BAMLEMRLCRPILATRIV', 'BAMLEMUBCRPIUSEY', 'BAMLEMUBCRPIUSOAS', 'BAMLEMUBCRPIUSTRIV', 'BAMLEMXOCOLCRPIUSEY', 'BAMLEMXOCOLCRPIUSOAS', 'BAMLEMXOCOLCRPIUSTRIV', 'CPFF', 'DAAA', 'DBAA', 'DCOILBRENTEU', 'DCOILWTICO', 'DCPF1M', 'DCPF2M', 'DCPF3M', 'DCPN2M', 'DCPN30', 'DCPN3M', 'DDFUELLA', 'DDFUELNYH', 'DDFUELUSGULF', 'DEXBZUS', 'DEXCAUS', 'DEXCHUS', 'DEXDNUS', 'DEXHKUS', 'DEXINUS', 'DEXJPUS', 'DEXKOUS', 'DEXMAUS', 'DEXMXUS', 'DEXNOUS', 'DEXSDUS', 'DEXSFUS', 'DEXSIUS', 'DEXSLUS', 'DEXSZUS', 'DEXTAUS', 'DEXTHUS', 'DEXUSAL', 'DEXUSEU', 'DEXUSNZ', 'DEXUSUK', 'DEXVZUS', 'DFEDTARL', 'DFEDTARU', 'DFF', 'DFII10', 'DFII20', 'DFII30', 'DFII5', 'DFII7', 'DGASNYH', 'DGASUSGULF', 'DGS1', 'DGS10', 'DGS1MO', 'DGS2', 'DGS20', 'DGS3', 'DGS30', 'DGS3MO', 'DGS5', 'DGS6MO', 'DGS7', 'DHOILNYH', 'DJFUELUSGULF', 'DLTIIT', 'DPCREDIT', 'DPRIME', 'DPROPANEMBTX', 'DRGASLA', 'DTB1YR', 'DTB3', 'DTB4WK', 'DTB6', 'DTP10J22', 'DTP10J23', 'DTP10J24', 'DTP10J25', 'DTP10J26', 'DTP10J27', 'DTP10J28', 'DTP10J29', 'DTP10J30', 'DTP10L21', 'DTP10L22', 'DTP10L23', 'DTP10L24', 'DTP10L25', 'DTP10L26', 'DTP10L27', 'DTP10L28', 'DTP10L29', 'DTP20J25', 'DTP20J26', 'DTP20J27', 'DTP20J28', 'DTP20J29', 'DTP30A28', 'DTP30A29', 'DTP30F40', 'DTP30F41', 'DTP30F42', 'DTP30F43', 'DTP30F44', 'DTP30F45', 'DTP30F46', 'DTP30F47', 'DTP30F48', 'DTP30F49', 'DTP30F50', 'DTP3HA32', 'DTP5A22', 'DTP5A23', 'DTP5A24', 'DTP5A25', 'DTP5C24', 'DTWEXAFEGS', 'DTWEXBGS', 'DTWEXEMEGS', 'EFFR', 'EFFR1', 'EFFR25', 'EFFR75', 'EFFR99', 'ICERATES1100EUR10Y', 'ICERATES1100EUR12Y', 'ICERATES1100EUR15Y', 'ICERATES1100EUR1Y', 'ICERATES1100EUR20Y', 'ICERATES1100EUR25Y', 'ICERATES1100EUR2Y', 'ICERATES1100EUR30Y', 'ICERATES1100EUR3Y', 'ICERATES1100EUR4Y', 'ICERATES1100EUR5Y', 'ICERATES1100EUR6Y', 'ICERATES1100EUR7Y', 'ICERATES1100EUR8Y', 'ICERATES1100EUR9Y', 'ICERATES1100GBP10Y', 'ICERATES1100GBP12Y', 'ICERATES1100GBP15Y', 'ICERATES1100GBP1Y', 'ICERATES1100GBP20Y', 'ICERATES1100GBP25Y', 'ICERATES1100GBP2Y', 'ICERATES1100GBP30Y', 'ICERATES1100GBP3Y', 'ICERATES1100GBP4Y', 'ICERATES1100GBP5Y', 'ICERATES1100GBP6Y', 'ICERATES1100GBP7Y', 'ICERATES1100GBP8Y', 'ICERATES1100GBP9Y', 'ICERATES1100USD10Y', 'ICERATES1100USD15Y', 'ICERATES1100USD1Y', 'ICERATES1100USD20Y', 'ICERATES1100USD2Y', 'ICERATES1100USD30Y', 'ICERATES1100USD3Y', 'ICERATES1100USD4Y', 'ICERATES1100USD5Y', 'ICERATES1100USD6Y', 'ICERATES1100USD7Y', 'ICERATES1100USD8Y', 'ICERATES1100USD9Y', 'ICERATES1200EUR10Y', 'ICERATES1200EUR12Y', 'ICERATES1200EUR15Y', 'ICERATES1200EUR1Y', 'ICERATES1200EUR20Y', 'ICERATES1200EUR25Y', 'ICERATES1200EUR2Y', 'ICERATES1200EUR30Y', 'ICERATES1200EUR3Y', 'ICERATES1200EUR4Y', 'ICERATES1200EUR5Y', 'ICERATES1200EUR6Y', 'ICERATES1200EUR7Y', 'ICERATES1200EUR8Y', 'ICERATES1200EUR9Y', 'ICERATES1500USD1Y', 'ICESPREADS1100USD10Y', 'ICESPREADS1100USD2Y', 'ICESPREADS1100USD3Y', 'ICESPREADS1100USD5Y', 'ICESPREADS1100USD7Y', 'INFECTDISEMVTRACKD', 'IOER', 'IORR', 'OBFR', 'OBFR1', 'OBFR25', 'OBFR75', 'OBFR99', 'OBMMIC15YF', 'OBMMIC30YF', 'OBMMIC30YFLVGT80FB680A699', 'OBMMIC30YFLVGT80FB700A719', 'OBMMIC30YFLVGT80FB720A739', 'OBMMIC30YFLVGT80FGE740', 'OBMMIC30YFLVGT80FLT680', 'OBMMIC30YFLVLE80FB680A699', 'OBMMIC30YFLVLE80FB700A719', 'OBMMIC30YFLVLE80FB720A739', 'OBMMIC30YFLVLE80FGE740', 'OBMMIC30YFLVLE80FLT680', 'OBMMIC30YFNA', 'OBMMIFHA30YF', 'OBMMIJUMBO30YF', 'OBMMIUSDA30YF', 'OBMMIVA30YF', 'RIFSPPAAAD01NB', 'RIFSPPAAAD07NB', 'RIFSPPAAAD15NB', 'RIFSPPAAAD30NB', 'RIFSPPAAAD60NB', 'RIFSPPAAAD90NB', 'RIFSPPFAAD01NB', 'RIFSPPFAAD07NB', 'RIFSPPFAAD15NB', 'RIFSPPFAAD30NB', 'RIFSPPFAAD60NB', 'RIFSPPFAAD90NB', 'RIFSPPNA2P2D01NB', 'RIFSPPNA2P2D07NB', 'RIFSPPNA2P2D15NB', 'RIFSPPNA2P2D30NB', 'RIFSPPNA2P2D60NB', 'RIFSPPNA2P2D90NB', 'RIFSPPNAAD01NB', 'RIFSPPNAAD07NB', 'RIFSPPNAAD15NB', 'RIFSPPNAAD30NB', 'RIFSPPNAAD60NB', 'RIFSPPNAAD90NB', 'RRPONTSYAWARD', 'SOFR', 'SOFR1', 'SOFR180DAYAVG', 'SOFR25', 'SOFR30DAYAVG', 'SOFR75', 'SOFR90DAYAVG', 'SOFR99', 'SOFRINDEX', 'T10Y2Y', 'T10Y3M', 'T10YFF', 'T10YIE', 'T1YFF', 'T3MFF', 'T5YFF', 'T5YIE', 'T5YIFR', 'T6MFF', 'TEDRATE', 'THREEFF1', 'THREEFF10', 'THREEFF2', 'THREEFF3', 'THREEFF4', 'THREEFF5', 'THREEFF6', 'THREEFF7', 'THREEFF8', 'THREEFF9', 'THREEFFTP1', 'THREEFFTP10', 'THREEFFTP2', 'THREEFFTP3', 'THREEFFTP4', 'THREEFFTP5', 'THREEFFTP6', 'THREEFFTP7', 'THREEFFTP8', 'THREEFFTP9', 'THREEFY1', 'THREEFY10', 'THREEFY2', 'THREEFY3', 'THREEFY4', 'THREEFY5', 'THREEFY6', 'THREEFY7', 'THREEFY8', 'THREEFY9', 'THREEFYTP1', 'THREEFYTP10', 'THREEFYTP2', 'THREEFYTP3', 'THREEFYTP4', 'THREEFYTP5', 'THREEFYTP6', 'THREEFYTP7', 'THREEFYTP8', 'THREEFYTP9', 'USEPUINDXD', 'WLEMUINDXD'],\n",
    "             'SUM' : ['AB1020AAAMT', 'AB1020AAVOL', 'AB14AAAMT', 'AB14AAVOL', 'AB2140AAAMT', 'AB2140AAVOL', 'AB4180AAAMT', 'AB4180AAVOL', 'AB59AAAMT', 'AB59AAVOL', 'ABGT80AAAMT', 'ABGT80AAVOL', 'CBBCHUSD', 'CBBTCUSD', 'CBETHUSD', 'CBLTCUSD', 'DHHNGSP', 'EFFRVOL', 'FIN1020AAAMT', 'FIN1020AAVOL', 'FIN14AAAMT', 'FIN14AAVOL', 'FIN2140AAAMT', 'FIN2140AAVOL', 'FIN4180AAAMT', 'FIN4180AAVOL', 'FIN59AAAMT', 'FIN59AAVOL', 'FINGT80AAAMT', 'FINGT80AAVOL', 'MKT1020MKTAMT', 'MKT1020MKTVOL', 'MKT14MKTAMT', 'MKT14MKTVOL', 'MKT2140MKTAMT', 'MKT2140MKTVOL', 'MKT4180MKTAMT', 'MKT4180MKTVOL', 'MKT59MKTAMT', 'MKT59MKTVOL', 'MKTGT80MKTAMT', 'MKTGT80MKTVOL', 'NONFIN1020A2P2AMT', 'NONFIN1020A2P2VOL', 'NONFIN1020AAAMT', 'NONFIN1020AAVOL', 'NONFIN14A2P2AMT', 'NONFIN14A2P2VOL', 'NONFIN14AAAMT', 'NONFIN14AAVOL', 'NONFIN2140A2P2AMT', 'NONFIN2140A2P2VOL', 'NONFIN2140AAAMT', 'NONFIN2140AAVOL', 'NONFIN4180A2P2AMT', 'NONFIN4180A2P2VOL', 'NONFIN4180AAAMT', 'NONFIN4180AAVOL', 'NONFIN59A2P2AMT', 'NONFIN59A2P2VOL', 'NONFIN59AAAMT', 'NONFIN59AAVOL', 'NONFINGT80A2P2AMT', 'NONFINGT80A2P2VOL', 'NONFINGT80AAAMT', 'NONFINGT80AAVOL', 'OBFRVOL', 'RPAGYD', 'RPMBSD', 'RPONAGYD', 'RPONMBSD', 'RPONTSYD', 'RPONTTLD', 'RPTMAGYD', 'RPTMMBSD', 'RPTMTSYD', 'RPTMTTLD', 'RPTSYD', 'RPTTLD', 'RRPAGYD', 'RRPMBSD', 'RRPONAGYD', 'RRPONMBSD', 'RRPONTSYD', 'RRPONTTLD', 'RRPTMAGYD', 'RRPTMMBSD', 'RRPTMTSYD', 'RRPTMTTLD', 'RRPTSYD', 'RRPTTLD', 'SOFRVOL'],\n",
    "             'CLOSE' : ['BAMLC0A0CM', 'BAMLC0A0CMEY', 'BAMLC0A0CMSYTW', 'BAMLC0A1CAAA', 'BAMLC0A1CAAAEY', 'BAMLC0A1CAAASYTW', 'BAMLC0A2CAA', 'BAMLC0A2CAAEY', 'BAMLC0A2CAASYTW', 'BAMLC0A3CA', 'BAMLC0A3CAEY', 'BAMLC0A3CASYTW', 'BAMLC0A4CBBB', 'BAMLC0A4CBBBEY', 'BAMLC0A4CBBBSYTW', 'BAMLC1A0C13Y', 'BAMLC1A0C13YEY', 'BAMLC1A0C13YSYTW', 'BAMLC2A0C35Y', 'BAMLC2A0C35YEY', 'BAMLC2A0C35YSYTW', 'BAMLC3A0C57Y', 'BAMLC3A0C57YEY', 'BAMLC3A0C57YSYTW', 'BAMLC4A0C710Y', 'BAMLC4A0C710YEY', 'BAMLC4A0C710YSYTW', 'BAMLC7A0C1015Y', 'BAMLC7A0C1015YEY', 'BAMLC7A0C1015YSYTW', 'BAMLC8A0C15PY', 'BAMLC8A0C15PYEY', 'BAMLC8A0C15PYSYTW', 'BAMLCC0A0CMTRIV', 'BAMLCC0A1AAATRIV', 'BAMLCC0A2AATRIV', 'BAMLCC0A3ATRIV', 'BAMLCC0A4BBBTRIV', 'BAMLCC1A013YTRIV', 'BAMLCC2A035YTRIV', 'BAMLCC3A057YTRIV', 'BAMLCC4A0710YTRIV', 'BAMLCC7A01015YTRIV', 'BAMLCC8A015PYTRIV', 'BAMLEM1BRRAAA2ACRPISYTW', 'BAMLEM1RAAA2ALCRPIUSSYTW', 'BAMLEM2BRRBBBCRPISYTW', 'BAMLEM2RBBBLCRPIUSSYTW', 'BAMLEM3BRRBBCRPISYTW', 'BAMLEM3RBBLCRPIUSSYTW', 'BAMLEM4BRRBLCRPISYTW', 'BAMLEM4RBLLCRPIUSSYTW', 'BAMLEM5BCOCRPISYTW', 'BAMLEMALLCRPIASIAUSSYTW', 'BAMLEMCBPISYTW', 'BAMLEMCBPITRIV', 'BAMLEMCLLCRPIUSSYTW', 'BAMLEMCLLCRPIUSTRIV', 'BAMLEMEBCRPIESYTW', 'BAMLEMELLCRPIEMEAUSSYTW', 'BAMLEMFLFLCRPIUSSYTW', 'BAMLEMFSFCRPISYTW', 'BAMLEMHBHYCRPISYTW', 'BAMLEMHGHGLCRPIUSSYTW', 'BAMLEMHYHYLCRPIUSSYTW', 'BAMLEMIBHGCRPISYTW', 'BAMLEMLLLCRPILAUSSYTW', 'BAMLEMNFNFLCRPIUSSYTW', 'BAMLEMNSNFCRPISYTW', 'BAMLEMPBPUBSICRPISYTW', 'BAMLEMPTPRVICRPISYTW', 'BAMLEMPUPUBSLCRPIUSSYTW', 'BAMLEMPVPRIVSLCRPIUSSYTW', 'BAMLEMRACRPIASIASYTW', 'BAMLEMRECRPIEMEASYTW', 'BAMLEMRLCRPILASYTW', 'BAMLEMUBCRPIUSSYTW', 'BAMLEMXOCOLCRPIUSSYTW', 'BAMLH0A0HYM2', 'BAMLH0A0HYM2EY', 'BAMLH0A0HYM2SYTW', 'BAMLH0A1HYBB', 'BAMLH0A1HYBBEY', 'BAMLH0A1HYBBSYTW', 'BAMLH0A2HYB', 'BAMLH0A2HYBEY', 'BAMLH0A2HYBSYTW', 'BAMLH0A3HYC', 'BAMLH0A3HYCEY', 'BAMLH0A3HYCSYTW', 'BAMLHE00EHYIEY', 'BAMLHE00EHYIOAS', 'BAMLHE00EHYISYTW', 'BAMLHE00EHYITRIV', 'BAMLHYH0A0HYM2TRIV', 'BAMLHYH0A1BBTRIV', 'BAMLHYH0A2BTRIV', 'BAMLHYH0A3CMTRIV', 'DJCA', 'DJIA', 'DJTA', 'DJUA', 'GVZCLS', 'NASDAQ100', 'NASDAQCOM', 'NIKKEI225', 'OVXCLS', 'RVXCLS', 'SP500', 'WILL2500IND', 'WILL2500INDGR', 'WILL2500INDVAL', 'WILL2500PR', 'WILL2500PRGR', 'WILL2500PRVAL', 'WILL4500IND', 'WILL4500PR', 'WILL5000IND', 'WILL5000INDFC', 'WILL5000PR', 'WILL5000PRFC', 'WILLLRGCAP', 'WILLLRGCAPGR', 'WILLLRGCAPGRPR', 'WILLLRGCAPPR', 'WILLLRGCAPVAL', 'WILLLRGCAPVALPR', 'WILLMICROCAP', 'WILLMICROCAPPR', 'WILLMIDCAP', 'WILLMIDCAPGR', 'WILLMIDCAPGRPR', 'WILLMIDCAPPR', 'WILLMIDCAPVAL', 'WILLMIDCAPVALPR', 'WILLREITIND', 'WILLREITPR', 'WILLRESIND', 'WILLRESIPR', 'WILLSMLCAP', 'WILLSMLCAPGR', 'WILLSMLCAPGRPR', 'WILLSMLCAPPR', 'WILLSMLCAPVAL', 'WILLSMLCAPVALPR']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL\n",
    "# agg_weekly = {'AVERAGE' : ['ANFCI', 'BUSAPPWNSAUSYY', 'CBUSAPPWNSAUSYY', 'FF', 'GASALLCOVW', 'GASALLREFW', 'GASALLW', 'GASDESLSW', 'GASDESW', 'GASMIDCOVW', 'GASMIDREFW', 'GASMIDW', 'GASPRMCOVW', 'GASPRMREFW', 'GASPRMW', 'GASREGCOVW', 'GASREGREFW', 'GASREGW', 'HBUSAPPWNSAUSYY', 'IURSA', 'LTGS', 'MORTGAGE30US', 'MORTGAGE5US', 'MORTMRGN5US', 'MORTPTS15US', 'MORTPTS30US', 'MORTPTS5US', 'NFCI', 'NFCICREDIT', 'NFCILEVERAGE', 'NFCINONFINLEVERAGE', 'NFCIRISK', 'STLFSI2', 'WAAA', 'WBAA', 'WBUSAPPWNSAUSYY', 'WCOILBRENTEU', 'WCOILWTICO', 'WCPF1M', 'WCPF2M', 'WCPF3M', 'WCPN1M', 'WCPN2M', 'WCPN3M', 'WDFUELLA', 'WDFUELNYH', 'WDFUELUSGULF', 'WEI', 'WFII10', 'WFII20', 'WFII30', 'WFII5', 'WFII7', 'WGASNYH', 'WGASUSGULF', 'WGS10YR', 'WGS1MO', 'WGS1YR', 'WGS20YR', 'WGS2YR', 'WGS30YR', 'WGS3MO', 'WGS3YR', 'WGS5YR', 'WGS6MO', 'WGS7YR', 'WHHNGSP', 'WHOILNYH', 'WJFUELUSGULF', 'WLTIIT', 'WPCREDIT', 'WPRIME', 'WPROPANEMBTX', 'WRGASLA', 'WTB1YR', 'WTB3MS', 'WTB4WK', 'WTB6MS'],\n",
    "#               'SUM' : ['ABCOMP', 'ALLACBW027SBOG', 'ALLDCBW027SBOG', 'ALLFRIW027SBOG', 'ALLLCBW027SBOG', 'ALLSCBW027SBOG', 'AOCACBW027SBOG', 'AOCDCBW027SBOG', 'AOCFRIW027SBOG', 'AOCLCBW027SBOG', 'AOCSCBW027SBOG', 'AOLACBW027SBOG', 'AOLDCBW027SBOG', 'AOLFRIW027SBOG', 'AOLLCBW027SBOG', 'AOLSCBW027SBOG', 'BC0DCBW027SBOG', 'BC0FRIW027SBOG', 'BC0LCBW027SBOG', 'BC0SCBW027SBOG', 'BUSAPPWNSAUS', 'CACP', 'CAOCARC', 'CAOCASFDICS04151934', 'CAOCASFDICSP', 'CARACBW027SBOG', 'CARDCBW027SBOG', 'CARFRIW027SBOG', 'CARLCBW027SBOG', 'CARSCBW027SBOG', 'CASACBW027SBOG', 'CASDCBW027SBOG', 'CASFRIW027SBOG', 'CASLCBW027SBOG', 'CASS13B', 'CASS7', 'CASSCBW027SBOG', 'CASSNS', 'CASTOTS', 'CATOTCA', 'CBUSAPPWNSAUS', 'CC4WSA', 'CCLACBW027SBOG', 'CCLDCBW027SBOG', 'CCLFRIW027SBOG', 'CCLLCBW027SBOG', 'CCLSCBW027SBOG', 'CCSA', 'CIBOARDNSA', 'CILDCBW027SBOG', 'CILFRIW027SBOG', 'CILSCBW027SBOG', 'CLDACBW027SBOG', 'CLDDCBW027SBOG', 'CLDFRIW027SBOG', 'CLDLCBW027SBOG', 'CLDSCBW027SBOG', 'CLSACBW027SBOG', 'CLSDCBW027SBOG', 'CLSFRIW027SBOG', 'CLSLCBW027SBOG', 'CLSSCBW027SBOG', 'COMPAPER', 'COMPOUT', 'COVEMP', 'CREACBW027SBOG', 'CREDCBW027SBOG', 'CREFRIW027SBOG', 'CRELCBW027SBOG', 'CRESCBW027SBOG', 'CRLACBW027SBOG', 'CRLDCBW027SBOG', 'CRLFRIW027SBOG', 'CRLLCBW027SBOG', 'CRLSCBW027SBOG', 'DFINCP', 'DNFINCP', 'DPSACBW027SBOG', 'DPSDCBW027SBOG', 'DPSFRIW027SBOG', 'DPSLCBW027SBOG', 'DPSSCBW027SBOG', 'DTBSPCKANYRENDWW', 'DTBSPCKCT1NWW', 'DTBSPCKCT1NYRENDWW', 'DTBSPCKCT2NWW', 'DTBSPCKCT2NYRENDWW', 'DTBSPCKFDBNWW', 'DTBSPCKFDNNWW', 'DTBSPCKFDONWW', 'DTBSPCKFDUNWW', 'DTBSPCKFFBNWW', 'DTBSPCKFFONWW', 'DTBSPCKFOWW', 'DTBSPCKNOWW', 'DTBSPCKNYRENDWW', 'DTBSPCKPLANWW', 'DTBSPCKPLFNWW', 'DTBSPCKPLNNWW', 'DTBSPCKPLONWW', 'DTBSPCKPTANWW', 'DTBSPCKPTFNWW', 'DTBSPCKPTNNWW', 'DTBSPCKPTONWW', 'FEDD10Y', 'FEDD15', 'FEDD1690', 'FEDD1T5', 'FEDD5T10', 'FEDD911Y', 'FEDDT', 'FFINCP', 'FINCP', 'FNFINCP', 'H41RESH4ENWW', 'H41RESH4EXAWNWW', 'H41RESH4EXAWXCH1NWW', 'H41RESH4EXAWXCH52NWW', 'H41RESH4EXCH1NWW', 'H41RESH4EXCH52NWW', 'H41RESPPAABHANWW', 'H41RESPPAABHCNWW', 'H41RESPPAABNWW', 'H41RESPPAABXAWNWW', 'H41RESPPAABXAWXCH1NWW', 'H41RESPPAABXAWXCH52NWW', 'H41RESPPAABXCH1NWW', 'H41RESPPAABXCH52NWW', 'H41RESPPAAC2HANWW', 'H41RESPPAAC2HCNWW', 'H41RESPPAAC2HNWW', 'H41RESPPAAC2HXAWNWW', 'H41RESPPAAC2HXAWXCH1NWW', 'H41RESPPAAC2HXAWXCH52NWW', 'H41RESPPAAC2HXCH1NWW', 'H41RESPPAAC2HXCH52NWW', 'H41RESPPAAC2MBD15NWW', 'H41RESPPAAC2MBD16T90NWW', 'H41RESPPAAC2MBNWW', 'H41RESPPAAC2MBY01NWW', 'H41RESPPAADHANWW', 'H41RESPPAADHCNWW', 'H41RESPPAADHNWW', 'H41RESPPAADHUD15NWW', 'H41RESPPAADHUD16T90NWW', 'H41RESPPAADHUNWW', 'H41RESPPAADHUY01NWW', 'H41RESPPAADHUY01T05NWW', 'H41RESPPAADHXAWNWW', 'H41RESPPAADHXAWXCH1NWW', 'H41RESPPAADHXAWXCH52NWW', 'H41RESPPAADHXCH1NWW', 'H41RESPPAADHXCH52NWW', 'H41RESPPAAEHANWW', 'H41RESPPAAEHCNWW', 'H41RESPPAAELD15NWW', 'H41RESPPAAELD16T90NWW', 'H41RESPPAAELNWW', 'H41RESPPAAELY01NWW', 'H41RESPPAAELY01T05NWW', 'H41RESPPAAENWW', 'H41RESPPAAEXAWNWW', 'H41RESPPAAEXAWXCH1NWW', 'H41RESPPAAEXAWXCH52NWW', 'H41RESPPAAEXCH1NWW', 'H41RESPPAAEXCH52NWW', 'H41RESPPAATAL2HANWW', 'H41RESPPAATAL2HCNWW', 'H41RESPPAATAL2HNWW', 'H41RESPPAATAL2HXAWNWW', 'H41RESPPAATAL2HXAWXCH1NWW', 'H41RESPPAATAL2HXCH1NWW', 'H41RESPPAATAL2HXCH52NWW', 'H41RESPPAATAL2LD15NWW', 'H41RESPPAATAL2LD16T90NWW', 'H41RESPPAATAL2LNWW', 'H41RESPPAATAL2LY01NWW', 'H41RESPPAATAL2LY01T05NWW', 'H41RESPPAENWW', 'H41RESPPALDBNWW', 'H41RESPPALDBXAWNWW', 'H41RESPPALDBXAWXCH1NWW', 'H41RESPPALDBXAWXCH52NWW', 'H41RESPPALDHNWW', 'H41RESPPALDHXAWNWW', 'H41RESPPALDHXAWXCH1NWW', 'H41RESPPALDHXAWXCH52NWW', 'H41RESPPALDJNWW', 'H41RESPPALDJXAWNWW', 'H41RESPPALDJXAWXCH1NWW', 'H41RESPPALDJXAWXCH52NWW', 'H41RESPPALDOBNWW', 'H41RESPPALDOC2NWW', 'H41RESPPALDODNWW', 'H41RESPPALDOENWW', 'H41RESPPALDOTAL2NWW', 'H41RESPPALGASMRNWW', 'H41RESPPALGASMSNWW', 'H41RESPPALGTRFNWW', 'H41RESPPALGTRFXAWNWW', 'H41RESPPALGTRFXAWXCH1NWW', 'H41RESPPALGTRFXAWXCH52NWW', 'H41RESPPALGTRONWW', 'H41RESPPALGTROXAWNWW', 'H41RESPPALGTROXAWXCH1NWW', 'H41RESPPALGTROXAWXCH52NWW', 'H41RESPPARNWW', 'H41RESPPLLDENWW', 'H41RESPPLLENWW', 'H8B3053NCBA', 'H8B3053NDMA', 'H8B3053NFRA', 'H8B3053NLGA', 'H8B3053NSMA', 'H8B3092NCBA', 'H8B3092NDMA', 'H8B3092NFRA', 'H8B3092NLGA', 'H8B3092NSMA', 'H8B3094NCBA', 'H8B3094NDMA', 'H8B3094NFRA', 'H8B3094NLGA', 'H8B3094NSMA', 'H8B3095NCBA', 'H8B3095NDMA', 'H8B3095NFRA', 'H8B3095NLGA', 'H8B3095NSMA', 'HBUSAPPWNSAUS', 'HMRESPPMAIXNWW', 'HMRESPPMAXNWW', 'HMRESPPMLLCXNWW', 'HMRESPPMLLDOXNWW', 'HMRESPPMLLDXNWW', 'HMRESPPMLLXNWW', 'IC4WSA', 'ICSA', 'LCBACBW027SBOG', 'LCBDCBW027SBOG', 'LCBFRIW027SBOG', 'LCBLCBW027SBOG', 'LCBSCBW027SBOG', 'LDDFRB', 'LDDNMBSDNMB', 'LDFBFOA', 'LDGUST', 'LDMB', 'LDOD', 'LDODHDI', 'LDSDMB', 'LDTDHDI', 'LDTOTD', 'LDUSTSA', 'LLBDCBW027SBOG', 'LLBFRIW027SBOG', 'LLBLCBW027SBOG', 'LLBSCBW027SBOG', 'LNCFRBNC', 'LNCFRNC', 'LNFACBW027SBOG', 'LNFDCBW027SBOG', 'LNFFRIW027SBOG', 'LNFLCBW027SBOG', 'LNFSCBW027SBOG', 'LOLAOL', 'LOLDOFRB', 'LOLGFT', 'LOLRPA', 'LTDACBW027SBOG', 'LTDDCBW027SBOG', 'LTDFRIW027SBOG', 'LTDLCBW027SBOG', 'LTDSCBW027SBOG', 'LTOTL', 'MBBOPMKAR', 'MBS10Y', 'MBS15', 'MBS1690', 'MBS1T5', 'MBS5T10', 'MBS911Y', 'MCONLIAPFC', 'MCONLIBPFC', 'MDLNWM', 'MINLOCMILA', 'MRAATAAR', 'MRAGGCTGGCLIB', 'NDFACBW027SBOG', 'NDFDCBW027SBOG', 'NDFFRIW027SBOG', 'NDFLCBW027SBOG', 'NDFSCBW027SBOG', 'NFINCP', 'NUGACBW027SBOG', 'NUGDCBW027SBOG', 'NUGFRIW027SBOG', 'NUGLCBW027SBOG', 'NUGSCBW027SBOG', 'OCLACBW027SBOG', 'OCLDCBW027SBOG', 'OCLFRIW027SBOG', 'OCLLCBW027SBOG', 'OCLSCBW027SBOG', 'ODSACBW027SBOG', 'ODSDCBW027SBOG', 'ODSFRIW027SBOG', 'ODSLCBW027SBOG', 'ODSSCBW027SBOG', 'OLNACBW027SBOG', 'OLNDCBW027SBOG', 'OLNFRIW027SBOG', 'OLNLCBW027SBOG', 'OLNSCBW027SBOG', 'OMBACBW027SBOG', 'OMBDCBW027SBOG', 'OMBFRIW027SBOG', 'OMBLCBW027SBOG', 'OMBSCBW027SBOG', 'ONMACBW027SBOG', 'ONMDCBW027SBOG', 'ONMFRIW027SBOG', 'ONMLCBW027SBOG', 'ONMSCBW027SBOG', 'OSEACBW027SBOG', 'OSEDCBW027SBOG', 'OSEFRIW027SBOG', 'OSELCBW027SBOG', 'OSESCBW027SBOG', 'OTHCOMPN', 'OTHL15', 'OTHL1690', 'OTHL1T5', 'OTHL5T10', 'OTHL91T1Y', 'RAAAAPABO', 'RAAHURA', 'RAATA', 'RABBOM', 'RABDL10D', 'RABDL30D', 'RABDL60D', 'RABDL90D', 'RABDLNS', 'RABDLO90D', 'RABDOB', 'RABDSGWOL', 'RABDTBD', 'RABP', 'RACBLS', 'RADDB', 'RADFFB', 'RADFOFRB', 'RADRCA', 'RAFAOBO', 'RAFAOHURA', 'RAFAONS', 'RAFAOTFAO', 'RAFCDA', 'RAFDICS', 'RAFLG', 'RAFRNNA', 'RAGGCGCA', 'RAGGCGCC', 'RAGGCGFA', 'RAGGCGFRA', 'RAGGCGRF', 'RAGGCGSF', 'RAGGCHEFRN', 'RAGGCTGFR', 'RAGGCTGGC', 'RAGSHURA', 'RAGSOCID', 'RAGSONBI', 'RAGSONBN', 'RAGSOSTC', 'RAGSOTBO', 'RAGSOUSB', 'RAGSOUSCID1PA', 'RAGSOUSCIDO', 'RAGSOUSTB', 'RAGSOUSTN', 'RAGSOUSTSIC', 'RAGSOUSVN', 'RAGSTUSTS', 'RAGTCFFB', 'RAIAIL', 'RAIMWOEA', 'RAIPGRNPCPFF', 'RAIPGRNPML1', 'RAIPGRNPML2', 'RAIPGRNPML3', 'RAIPGRNPTALF', 'RAIPGRPH', 'RALACBW027SBOG', 'RALDCBW027SBOG', 'RALFRIW027SBOG', 'RALGCB', 'RALLCBW027SBOG', 'RALSCBW027SBOG', 'RALTSCCRO', 'RAMBS', 'RANRC', 'RAOE', 'RAOR', 'RAOS', 'RARFFRBN', 'RATAC', 'RATBOH', 'RATDGD', 'RATEATIESTBS', 'RATPRA', 'RATR', 'RATSHO', 'RAUDSHO', 'RAUICIP', 'RAUPSHO', 'RELACBW027SBOG', 'RELDCBW027SBOG', 'RELFRIW027SBOG', 'RELLCBW027SBOG', 'RELSCBW027SBOG', 'REP15', 'REP1690', 'RESH4AOXAWXCH1NWW', 'RESH4AOXAWXCH52NWW', 'RESH4AXAWXCH1NWW', 'RESH4AXAWXCH52NWW', 'RESH4DOFXAWXCH1NWW', 'RESH4DOFXAWXCH52NWW', 'RESH4DOTXAWXCH1NWW', 'RESH4DOTXAWXCH52NWW', 'RESH4DOXAWXCH1NWW', 'RESH4DOXAWXCH52NWW', 'RESH4DXAWXCH1NWW', 'RESH4DXAWXCH52NWW', 'RESH4FAXAWXCH1NWW', 'RESH4FAXAWXCH52NWW', 'RESH4FGXAWXCH1NWW', 'RESH4FGXAWXCH52NWW', 'RESH4FOXAWXCH1NWW', 'RESH4FOXAWXCH52NWW', 'RESH4FXAWXCH1NWW', 'RESH4FXAWXCH52NWW', 'RESH4MFNWW', 'RESH4RXAWXCH1NWW', 'RESH4RXAWXCH52NWW', 'RESH4SCFXAWXCH1NWW', 'RESH4SCFXAWXCH52NWW', 'RESH4SCSXAWXCH1NWW', 'RESH4SCSXAWXCH52NWW', 'RESH4SCSXCH1NWW', 'RESH4SCSXCH52NWW', 'RESH4SCXAWXCH1NWW', 'RESH4SCXAWXCH52NWW', 'RESH4SOXAWXCH1NWW', 'RESH4SOXAWXCH52NWW', 'RESH4SXAWXCH1NWW', 'RESH4SXAWXCH52NWW', 'RESPPAAML1LINWW', 'RESPPAAML1LPNWW', 'RESPPAAML2LINWW', 'RESPPAAML2LPNWW', 'RESPPAAML3LINWW', 'RESPPAAML3LPNWW', 'RESPPAATAL2HXAWXCH52NWW', 'RESPPACXCH1NWW', 'RESPPACXCH52NWW', 'RESPPAGXCH1NWW', 'RESPPAGXCH52NWW', 'RESPPAINWW', 'RESPPALDCXAWXCH1NWW', 'RESPPALDCXAWXCH52NWW', 'RESPPALDPXAWXCH1NWW', 'RESPPALDPXAWXCH52NWW', 'RESPPALDQXAWXCH1NWW', 'RESPPALDQXAWXCH52NWW', 'RESPPALDSXAWXCH1NWW', 'RESPPALDSXAWXCH52NWW', 'RESPPALDTXAWXCH1NWW', 'RESPPALDTXAWXCH52NWW', 'RESPPALDVNWW', 'RESPPALDXAWNWW', 'RESPPALDXAWXCH1NWW', 'RESPPALDXAWXCH52NWW', 'RESPPALDXCH1NWW', 'RESPPALDXCH52NWW', 'RESPPALGAMD15XCH1NWW', 'RESPPALGAMD16T90XCH1NWW', 'RESPPALGAMXCH1NWW', 'RESPPALGAMY01T05XCH1NWW', 'RESPPALGAMY01XCH1NWW', 'RESPPALGAMY05T10XCH1NWW', 'RESPPALGAMY10PXCH1NWW', 'RESPPALGAOXAWXCH1NWW', 'RESPPALGAOXAWXCH52NWW', 'RESPPALGAOXCH1NWW', 'RESPPALGAOXCH52NWW', 'RESPPALGASMCBNWW', 'RESPPALGASMCSNWW', 'RESPPALGASMENWW', 'RESPPALGASMOD15XCH1NWW', 'RESPPALGASMOD16T90XCH1NWW', 'RESPPALGASMOXAWXCH1NWW', 'RESPPALGASMOXAWXCH52NWW', 'RESPPALGASMOXCH1NWW', 'RESPPALGASMOXCH52NWW', 'RESPPALGASMOY01T05XCH1NWW', 'RESPPALGASMOY01XCH1NWW', 'RESPPALGASMOY05T10XCH1NWW', 'RESPPALGASMOY10PXCH1NWW', 'RESPPALGTRXAWXCH1NWW', 'RESPPALGTRXAWXCH52NWW', 'RESPPALGTRXCH1NWW', 'RESPPALGTRXCH52NWW', 'RESPPALGUMD15XCH1NWW', 'RESPPALGUMD16T90XCH1NWW', 'RESPPALGUMXCH1NWW', 'RESPPALGUMY01T05XCH1NWW', 'RESPPALGUMY01XCH1NWW', 'RESPPALGUMY05T10XCH1NWW', 'RESPPALGUMY10PXCH1NWW', 'RESPPALGUOBXAWXCH1NWW', 'RESPPALGUOBXAWXCH52NWW', 'RESPPALGUOBXCH1NWW', 'RESPPALGUOBXCH52NWW', 'RESPPALGUOMCXAWXCH1NWW', 'RESPPALGUOMCXAWXCH52NWW', 'RESPPALGUOMCXCH1NWW', 'RESPPALGUOMCXCH52NWW', 'RESPPALGUOMIXAWXCH1NWW', 'RESPPALGUOMIXAWXCH52NWW', 'RESPPALGUOMIXCH1NWW', 'RESPPALGUOMIXCH52NWW', 'RESPPALGUOMNXAWXCH1NWW', 'RESPPALGUOMNXAWXCH52NWW', 'RESPPALGUOMNXCH1NWW', 'RESPPALGUOMNXCH52NWW', 'RESPPALGUONNWW', 'RESPPALGUOXAWXCH1NWW', 'RESPPALGUOXAWXCH52NWW', 'RESPPALGUOXCH1NWW', 'RESPPALGUOXCH52NWW', 'RESPPALGXAWXCH1NWW', 'RESPPALGXAWXCH52NWW', 'RESPPALGXCH1NWW', 'RESPPALGXCH52NWW', 'RESPPALSDXAWNWW', 'RESPPALSDXAWXCH1NWW', 'RESPPALSDXAWXCH52NWW', 'RESPPALSDXCH1NWW', 'RESPPALSDXCH52NWW', 'RESPPALSPXAWNWW', 'RESPPALSPXAWXCH1NWW', 'RESPPALSPXAWXCH52NWW', 'RESPPALSPXCH1NWW', 'RESPPALSPXCH52NWW', 'RESPPALXCH1NWW', 'RESPPALXCH52NWW', 'RESPPANNWW', 'RESPPANWW', 'RESPPAOFXAWNWW', 'RESPPAOFXAWXCH1NWW', 'RESPPAOFXAWXCH52NWW', 'RESPPAOFXCH1NWW', 'RESPPAOFXCH52NWW', 'RESPPAOXCH1NWW', 'RESPPAOXCH52NWW', 'RESPPAPXCH1NWW', 'RESPPAPXCH52NWW', 'RESPPASXAWXCH1NWW', 'RESPPASXAWXCH52NWW', 'RESPPASXCH1NWW', 'RESPPASXCH52NWW', 'RESPPLAML1LTNWW', 'RESPPLAML2LTNWW', 'RESPPLAML3LTNWW', 'RESPPLCPXCH1NWW', 'RESPPLCPXCH52NWW', 'RESPPLCSXCH1NWW', 'RESPPLCSXCH52NWW', 'RESPPLCUXCH1NWW', 'RESPPLCUXCH52NWW', 'RESPPLCXCH1NWW', 'RESPPLCXCH52NWW', 'RESPPLLBXAWXCH1NWW', 'RESPPLLBXAWXCH52NWW', 'RESPPLLCNWW', 'RESPPLLDAXAWXCH1NWW', 'RESPPLLDAXAWXCH52NWW', 'RESPPLLDAXCH1NWW', 'RESPPLLDAXCH52NWW', 'RESPPLLDDXCH1NWW', 'RESPPLLDDXCH52NWW', 'RESPPLLDFXAWXCH1NWW', 'RESPPLLDFXAWXCH52NWW', 'RESPPLLDFXCH1NWW', 'RESPPLLDFXCH52NWW', 'RESPPLLDNWW', 'RESPPLLDOXAWXCH1NWW', 'RESPPLLDOXAWXCH52NWW', 'RESPPLLDOXCH1NWW', 'RESPPLLDOXCH52NWW', 'RESPPLLDTXAWXCH1NWW', 'RESPPLLDTXAWXCH52NWW', 'RESPPLLDTXCH1NWW', 'RESPPLLDTXCH52NWW', 'RESPPLLNHNWW', 'RESPPLLNOCNWW', 'RESPPLLNONNWW', 'RESPPLLNONWW', 'RESPPLLNWW', 'RESPPLLNXCH1NWW', 'RESPPLLNXCH52NWW', 'RESPPLLOONWW', 'RESPPLLOPNWW', 'RESPPLLOXCH1NWW', 'RESPPLLOXCH52NWW', 'RESPPLLRDXAWXCH1NWW', 'RESPPLLRDXAWXCH52NWW', 'RESPPLLRFXAWXCH1NWW', 'RESPPLLRFXAWXCH52NWW', 'RESPPLLRXAWXCH1NWW', 'RESPPLLRXAWXCH52NWW', 'RESPPLLRXCH1NWW', 'RESPPLLRXCH52NWW', 'RESPPLNWW', 'RESPPMAIXCH1NWW', 'RESPPMAIXCH52NWW', 'RESPPMAXCH1NWW', 'RESPPMAXCH52NWW', 'RESPPMLLCXCH1NWW', 'RESPPMLLCXCH52NWW', 'RESPPMLLDONWW', 'RESPPMLLDXCH1NWW', 'RESPPMLLDXCH52NWW', 'RESPPMLLXCH1NWW', 'RESPPMLLXCH52NWW', 'RESPPNGNWW', 'RESPPNNWW', 'RESPPNONWW', 'RESPPNSNWW', 'RESPPNTEPNWW', 'RESPPNTEPPNWW', 'RESPPNTNWW', 'RESTBCXAWXCH1NWW', 'RESTBCXAWXCH52NWW', 'RESTBHTXAWXCH1NWW', 'RESTBHTXAWXCH52NWW', 'RESTBMGXAWXCH1NWW', 'RESTBMGXAWXCH52NWW', 'RESTBMTXAWXCH1NWW', 'RESTBMTXAWXCH52NWW', 'RHEACBW027SBOG', 'RHEDCBW027SBOG', 'RHEFRIW027SBOG', 'RHELCBW027SBOG', 'RHESCBW027SBOG', 'RREACBW027SBOG', 'RREDCBW027SBOG', 'RREFRIW027SBOG', 'RRELCBW027SBOG', 'RREP15', 'RREP1690', 'RRESCBW027SBOG', 'SBCACBW027SBOG', 'SBCDCBW027SBOG', 'SBCFRIW027SBOG', 'SBCLCBW027SBOG', 'SBCSCBW027SBOG', 'SBFACBW027SBOG', 'SBFDCBW027SBOG', 'SBFFRIW027SBOG', 'SBFLCBW027SBOG', 'SBFSCBW027SBOG', 'SMPACBW027SBOG', 'SMPDCBW027SBOG', 'SMPFRIW027SBOG', 'SMPLCBW027SBOG', 'SMPSCBW027SBOG', 'SNFACBW027SBOG', 'SNFDCBW027SBOG', 'SNFFRIW027SBOG', 'SNFLCBW027SBOG', 'SNFSCBW027SBOG', 'SWP10Y', 'SWP15', 'SWP1690', 'SWP1T5', 'SWP5T10', 'SWP911Y', 'SWPT', 'TAMACBW027SBOG', 'TAMDCBW027SBOG', 'TAMFRIW027SBOG', 'TAMLCBW027SBOG', 'TAMSCBW027SBOG', 'TASACBW027SBOG', 'TASDCBW027SBOG', 'TASFRIW027SBOG', 'TASLCBW027SBOG', 'TASSCBW027SBOG', 'TERM15', 'TERM1690', 'TERM911Y', 'TERMT', 'TLAACBW027SBOG', 'TLADCBW027SBOG', 'TLAFRIW027SBOG', 'TLALCBW027SBOG', 'TLASCBW027SBOG', 'TLBACBW027SBOG', 'TLBDCBW027SBOG', 'TLBFRIW027SBOG', 'TLBLCBW027SBOG', 'TLBSCBW027SBOG', 'TMBACBW027SBOG', 'TMBDCBW027SBOG', 'TMBFRIW027SBOG', 'TMBLCBW027SBOG', 'TMBSCBW027SBOG', 'TNMACBW027SBOG', 'TNMDCBW027SBOG', 'TNMFRIW027SBOG', 'TNMLCBW027SBOG', 'TNMSCBW027SBOG', 'TOTBKCR', 'TOTBORR', 'TOTCI', 'TOTLCA', 'TOTLL', 'TOTRA', 'TREAS10Y', 'TREAS15', 'TREAS1590', 'TREAS1T5', 'TREAS5T10', 'TREAS911Y', 'TREAST', 'WABPL', 'WACL', 'WALCL', 'WALL', 'WAOAL', 'WBUSAPPWNSAUS', 'WCBLSA', 'WCICL', 'WCPCA', 'WCPIL', 'WCSL', 'WCTCL', 'WCURCIR', 'WCURRNS', 'WDDNS', 'WDFOA', 'WDFOL', 'WDSFAL', 'WDTGAL', 'WFASEC1', 'WFASECL1', 'WFCDA', 'WFEDSEC', 'WGCAL', 'WLAD', 'WLCFLL', 'WLCFLPCL', 'WLCFLSCL', 'WLCFLSECL', 'WLCFOCEL', 'WLDACL', 'WLDACLC', 'WLDECL', 'WLDLCL', 'WLFN', 'WLOCL', 'WLODL', 'WLODLL', 'WLRRAA', 'WLRRAFOIAL', 'WLRRAL', 'WLRRAOL', 'WLTDHDIA', 'WLTEC', 'WLTLECL', 'WM1NS', 'WM2NS', 'WMBSEC', 'WMTSEC1', 'WMTSECL1', 'WOCE', 'WOFDRBORBA', 'WOFDRBORBL', 'WOFDRBTHA', 'WOFDRBTHL', 'WOFRAL', 'WOFSRBFA', 'WOFSRBFL', 'WOFSRBGSA', 'WOFSRBGSL', 'WOFSRBRBC', 'WOLCL', 'WORAL', 'WOSDRA', 'WOSDRL', 'WOTHAST', 'WOTHLB', 'WOTHLIAB', 'WPC', 'WPCL', 'WPCLC', 'WRBWFRBL', 'WREPO', 'WREPODEL', 'WREPOFOR', 'WRESBAL', 'WRESCRT', 'WRMFNS', 'WSB', 'WSC', 'WSDEAL', 'WSDEALL', 'WSDFDSA', 'WSDFDSL', 'WSDONT', 'WSDONTL', 'WSDTREAA', 'WSDTREAL', 'WSECOUT', 'WSEFINO', 'WSEFINOL', 'WSEFINT1', 'WSEFINTL1', 'WSHOBA', 'WSHOBL', 'WSHOFADSL', 'WSHOICA', 'WSHOICL', 'WSHOMCB', 'WSHONBIIA', 'WSHONBIIL', 'WSHONBNA', 'WSHONBNL', 'WSHOSHO', 'WSHOTSA', 'WSHOTSL', 'WSMTMNS', 'WSRLL', 'WTCOA', 'WTCOL', 'WTFORBAFA', 'WTFORBAFL', 'WTFSRFA', 'WTFSRFL', 'WTREGEN', 'WUDSHO', 'WUPSHO']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_weekly = {'AVERAGE' : ['ANFCI', 'BUSAPPWNSAUSYY', 'CBUSAPPWNSAUSYY', 'FF', 'GASALLCOVW', 'GASALLREFW', 'GASALLW', 'GASDESLSW', 'GASDESW', 'GASMIDCOVW', 'GASMIDREFW', 'GASMIDW', 'GASPRMCOVW', 'GASPRMREFW', 'GASPRMW', 'GASREGCOVW', 'GASREGREFW', 'GASREGW', 'HBUSAPPWNSAUSYY', 'IURSA', 'LTGS', 'MORTGAGE30US', 'MORTGAGE5US', 'MORTMRGN5US', 'MORTPTS15US', 'MORTPTS30US', 'MORTPTS5US', 'NFCI', 'NFCICREDIT', 'NFCILEVERAGE', 'NFCINONFINLEVERAGE', 'NFCIRISK', 'STLFSI2', 'WAAA', 'WBAA', 'WBUSAPPWNSAUSYY', 'WCOILBRENTEU', 'WCOILWTICO', 'WCPF1M', 'WCPF2M', 'WCPF3M', 'WCPN1M', 'WCPN2M', 'WCPN3M', 'WDFUELLA', 'WDFUELNYH', 'WDFUELUSGULF', 'WEI', 'WFII10', 'WFII20', 'WFII30', 'WFII5', 'WFII7', 'WGASNYH', 'WGASUSGULF', 'WGS10YR', 'WGS1MO', 'WGS1YR', 'WGS20YR', 'WGS2YR', 'WGS30YR', 'WGS3MO', 'WGS3YR', 'WGS5YR', 'WGS6MO', 'WGS7YR', 'WHHNGSP', 'WHOILNYH', 'WJFUELUSGULF', 'WLTIIT', 'WPCREDIT', 'WPRIME', 'WPROPANEMBTX', 'WRGASLA', 'WTB1YR', 'WTB3MS', 'WTB4WK', 'WTB6MS'],\n",
    "              'SUM' : ['ABCOMP', 'ALLACBW027SBOG', 'ALLDCBW027SBOG', 'ALLFRIW027SBOG', 'ALLLCBW027SBOG', 'ALLSCBW027SBOG', 'AOCACBW027SBOG', 'AOCDCBW027SBOG', 'AOCFRIW027SBOG', 'AOCLCBW027SBOG', 'AOCSCBW027SBOG', 'AOLACBW027SBOG', 'AOLDCBW027SBOG', 'AOLFRIW027SBOG', 'AOLLCBW027SBOG', 'AOLSCBW027SBOG', 'BC0DCBW027SBOG', 'BC0FRIW027SBOG', 'BC0LCBW027SBOG', 'BC0SCBW027SBOG', 'BUSAPPWNSAUS', 'CACP', 'CAOCARC', 'CARACBW027SBOG', 'CARDCBW027SBOG', 'CARFRIW027SBOG', 'CARLCBW027SBOG', 'CARSCBW027SBOG', 'CASACBW027SBOG', 'CASDCBW027SBOG', 'CASFRIW027SBOG', 'CASLCBW027SBOG', 'CASS7', 'CASSCBW027SBOG', 'CASSNS', 'CASTOTS', 'CATOTCA', 'CBUSAPPWNSAUS', 'CC4WSA', 'CCLACBW027SBOG', 'CCLDCBW027SBOG', 'CCLFRIW027SBOG', 'CCLLCBW027SBOG', 'CCLSCBW027SBOG', 'CCSA', 'CIBOARDNSA', 'CILDCBW027SBOG', 'CILFRIW027SBOG', 'CILSCBW027SBOG', 'CLDACBW027SBOG', 'CLDDCBW027SBOG', 'CLDFRIW027SBOG', 'CLDLCBW027SBOG', 'CLDSCBW027SBOG', 'CLSACBW027SBOG', 'CLSDCBW027SBOG', 'CLSFRIW027SBOG', 'CLSLCBW027SBOG', 'CLSSCBW027SBOG', 'COMPAPER', 'COMPOUT', 'COVEMP', 'CREACBW027SBOG', 'CREDCBW027SBOG', 'CREFRIW027SBOG', 'CRELCBW027SBOG', 'CRESCBW027SBOG', 'CRLACBW027SBOG', 'CRLDCBW027SBOG', 'CRLFRIW027SBOG', 'CRLLCBW027SBOG', 'CRLSCBW027SBOG', 'DFINCP', 'DNFINCP', 'DPSACBW027SBOG', 'DPSDCBW027SBOG', 'DPSFRIW027SBOG', 'DPSLCBW027SBOG', 'DPSSCBW027SBOG', 'DTBSPCKANYRENDWW', 'DTBSPCKCT1NWW', 'DTBSPCKCT1NYRENDWW', 'DTBSPCKCT2NWW', 'DTBSPCKCT2NYRENDWW', 'DTBSPCKFDBNWW', 'DTBSPCKFDNNWW', 'DTBSPCKFDONWW', 'DTBSPCKFDUNWW', 'DTBSPCKFFBNWW', 'DTBSPCKFFONWW', 'DTBSPCKFOWW', 'DTBSPCKNOWW', 'DTBSPCKNYRENDWW', 'DTBSPCKPLANWW', 'DTBSPCKPLFNWW', 'DTBSPCKPLNNWW', 'DTBSPCKPLONWW', 'DTBSPCKPTANWW', 'DTBSPCKPTFNWW', 'DTBSPCKPTNNWW', 'DTBSPCKPTONWW', 'FEDD10Y', 'FEDD15', 'FEDD1690', 'FEDD1T5', 'FEDD5T10', 'FEDD911Y', 'FEDDT', 'FFINCP', 'FINCP', 'FNFINCP', 'H41RESH4ENWW', 'H41RESH4EXAWNWW', 'H41RESH4EXAWXCH1NWW', 'H41RESH4EXAWXCH52NWW', 'H41RESH4EXCH1NWW', 'H41RESH4EXCH52NWW', 'H41RESPPAABHANWW', 'H41RESPPAABHCNWW', 'H41RESPPAABNWW', 'H41RESPPAABXAWNWW', 'H41RESPPAABXAWXCH1NWW', 'H41RESPPAABXAWXCH52NWW', 'H41RESPPAABXCH1NWW', 'H41RESPPAABXCH52NWW', 'H41RESPPAAC2HANWW', 'H41RESPPAAC2HCNWW', 'H41RESPPAAC2HNWW', 'H41RESPPAAC2HXAWNWW', 'H41RESPPAAC2HXAWXCH1NWW', 'H41RESPPAAC2HXAWXCH52NWW', 'H41RESPPAAC2HXCH1NWW', 'H41RESPPAAC2HXCH52NWW', 'H41RESPPAAC2MBD15NWW', 'H41RESPPAAC2MBD16T90NWW', 'H41RESPPAAC2MBNWW', 'H41RESPPAAC2MBY01NWW', 'H41RESPPAADHANWW', 'H41RESPPAADHCNWW', 'H41RESPPAADHNWW', 'H41RESPPAADHUD15NWW', 'H41RESPPAADHUD16T90NWW', 'H41RESPPAADHUNWW', 'H41RESPPAADHUY01NWW', 'H41RESPPAADHUY01T05NWW', 'H41RESPPAADHXAWNWW', 'H41RESPPAADHXAWXCH1NWW', 'H41RESPPAADHXAWXCH52NWW', 'H41RESPPAADHXCH1NWW', 'H41RESPPAADHXCH52NWW', 'H41RESPPAAEHANWW', 'H41RESPPAAEHCNWW', 'H41RESPPAAELD15NWW', 'H41RESPPAAELD16T90NWW', 'H41RESPPAAELNWW', 'H41RESPPAAELY01NWW', 'H41RESPPAAELY01T05NWW', 'H41RESPPAAENWW', 'H41RESPPAAEXAWNWW', 'H41RESPPAAEXAWXCH1NWW', 'H41RESPPAAEXAWXCH52NWW', 'H41RESPPAAEXCH1NWW', 'H41RESPPAAEXCH52NWW', 'H41RESPPAATAL2HANWW', 'H41RESPPAATAL2HCNWW', 'H41RESPPAATAL2HNWW', 'H41RESPPAATAL2HXAWNWW', 'H41RESPPAATAL2HXAWXCH1NWW', 'H41RESPPAATAL2HXCH1NWW', 'H41RESPPAATAL2HXCH52NWW', 'H41RESPPAATAL2LD15NWW', 'H41RESPPAATAL2LD16T90NWW', 'H41RESPPAATAL2LNWW', 'H41RESPPAATAL2LY01NWW', 'H41RESPPAATAL2LY01T05NWW', 'H41RESPPAENWW', 'H41RESPPALDBNWW', 'H41RESPPALDBXAWNWW', 'H41RESPPALDBXAWXCH1NWW', 'H41RESPPALDBXAWXCH52NWW', 'H41RESPPALDHNWW', 'H41RESPPALDHXAWNWW', 'H41RESPPALDHXAWXCH1NWW', 'H41RESPPALDHXAWXCH52NWW', 'H41RESPPALDJNWW', 'H41RESPPALDJXAWNWW', 'H41RESPPALDJXAWXCH1NWW', 'H41RESPPALDJXAWXCH52NWW', 'H41RESPPALDOBNWW', 'H41RESPPALDOC2NWW', 'H41RESPPALDODNWW', 'H41RESPPALDOENWW', 'H41RESPPALDOTAL2NWW', 'H41RESPPALGASMRNWW', 'H41RESPPALGASMSNWW', 'H41RESPPALGTRFNWW', 'H41RESPPALGTRFXAWNWW', 'H41RESPPALGTRFXAWXCH1NWW', 'H41RESPPALGTRFXAWXCH52NWW', 'H41RESPPALGTRONWW', 'H41RESPPALGTROXAWNWW', 'H41RESPPALGTROXAWXCH1NWW', 'H41RESPPALGTROXAWXCH52NWW', 'H41RESPPARNWW', 'H41RESPPLLDENWW', 'H41RESPPLLENWW', 'H8B3053NCBA', 'H8B3053NDMA', 'H8B3053NFRA', 'H8B3053NLGA', 'H8B3053NSMA', 'H8B3092NCBA', 'H8B3092NDMA', 'H8B3092NFRA', 'H8B3092NLGA', 'H8B3092NSMA', 'H8B3094NCBA', 'H8B3094NDMA', 'H8B3094NFRA', 'H8B3094NLGA', 'H8B3094NSMA', 'H8B3095NCBA', 'H8B3095NDMA', 'H8B3095NFRA', 'H8B3095NLGA', 'H8B3095NSMA', 'HBUSAPPWNSAUS', 'HMRESPPMAIXNWW', 'HMRESPPMAXNWW', 'HMRESPPMLLCXNWW', 'HMRESPPMLLDOXNWW', 'HMRESPPMLLDXNWW', 'HMRESPPMLLXNWW', 'IC4WSA', 'ICSA', 'LCBACBW027SBOG', 'LCBDCBW027SBOG', 'LCBFRIW027SBOG', 'LCBLCBW027SBOG', 'LCBSCBW027SBOG', 'LDDFRB', 'LDFBFOA', 'LDGUST', 'LDMB', 'LDOD', 'LDODHDI', 'LDTDHDI', 'LDTOTD', 'LDUSTSA', 'LLBDCBW027SBOG', 'LLBFRIW027SBOG', 'LLBLCBW027SBOG', 'LLBSCBW027SBOG', 'LNCFRNC', 'LNFACBW027SBOG', 'LNFDCBW027SBOG', 'LNFFRIW027SBOG', 'LNFLCBW027SBOG', 'LNFSCBW027SBOG', 'LOLAOL', 'LOLDOFRB', 'LOLRPA', 'LTDACBW027SBOG', 'LTDDCBW027SBOG', 'LTDFRIW027SBOG', 'LTDLCBW027SBOG', 'LTDSCBW027SBOG', 'LTOTL', 'MBS10Y', 'MBS15', 'MBS1690', 'MBS1T5', 'MBS5T10', 'MBS911Y', 'MCONLIAPFC', 'MDLNWM', 'MRAGGCTGGCLIB', 'NDFACBW027SBOG', 'NDFDCBW027SBOG', 'NDFFRIW027SBOG', 'NDFLCBW027SBOG', 'NDFSCBW027SBOG', 'NFINCP', 'NUGACBW027SBOG', 'NUGDCBW027SBOG', 'NUGFRIW027SBOG', 'NUGLCBW027SBOG', 'NUGSCBW027SBOG', 'OCLACBW027SBOG', 'OCLDCBW027SBOG', 'OCLFRIW027SBOG', 'OCLLCBW027SBOG', 'OCLSCBW027SBOG', 'ODSACBW027SBOG', 'ODSDCBW027SBOG', 'ODSFRIW027SBOG', 'ODSLCBW027SBOG', 'ODSSCBW027SBOG', 'OLNACBW027SBOG', 'OLNDCBW027SBOG', 'OLNFRIW027SBOG', 'OLNLCBW027SBOG', 'OLNSCBW027SBOG', 'OMBACBW027SBOG', 'OMBDCBW027SBOG', 'OMBFRIW027SBOG', 'OMBLCBW027SBOG', 'OMBSCBW027SBOG', 'ONMACBW027SBOG', 'ONMDCBW027SBOG', 'ONMFRIW027SBOG', 'ONMLCBW027SBOG', 'ONMSCBW027SBOG', 'OSEACBW027SBOG', 'OSEDCBW027SBOG', 'OSEFRIW027SBOG', 'OSELCBW027SBOG', 'OSESCBW027SBOG', 'OTHCOMPN', 'OTHL15', 'OTHL1690', 'OTHL1T5', 'OTHL5T10', 'OTHL91T1Y', 'RAAAAPABO', 'RAAHURA', 'RAATA', 'RABDSGWOL', 'RABDTBD', 'RABP', 'RACBLS', 'RADFFB', 'RADFOFRB', 'RADRCA', 'RAFAOBO', 'RAFAOHURA', 'RAFAONS', 'RAFAOTFAO', 'RAFCDA', 'RAGGCGCA', 'RAGGCGRF', 'RAGGCTGGC', 'RAGSHURA', 'RAGSONBI', 'RAGSONBN', 'RAGSOTBO', 'RAGSOUSB', 'RAGSOUSCIDO', 'RAGSOUSTB', 'RAGSOUSTN', 'RAGSOUSTSIC', 'RAGSTUSTS', 'RAIAIL', 'RAIPGRNPCPFF', 'RAIPGRNPML1', 'RAIPGRNPML2', 'RAIPGRNPML3', 'RAIPGRNPTALF', 'RAIPGRPH', 'RALACBW027SBOG', 'RALDCBW027SBOG', 'RALFRIW027SBOG', 'RALLCBW027SBOG', 'RALSCBW027SBOG', 'RALTSCCRO', 'RAMBS', 'RAOE', 'RAOR', 'RATAC', 'RATEATIESTBS', 'RATPRA', 'RATR', 'RATSHO', 'RAUDSHO', 'RAUICIP', 'RAUPSHO', 'RELACBW027SBOG', 'RELDCBW027SBOG', 'RELFRIW027SBOG', 'RELLCBW027SBOG', 'RELSCBW027SBOG', 'REP15', 'REP1690', 'RESH4AOXAWXCH1NWW', 'RESH4AOXAWXCH52NWW', 'RESH4AXAWXCH1NWW', 'RESH4AXAWXCH52NWW', 'RESH4DOFXAWXCH1NWW', 'RESH4DOFXAWXCH52NWW', 'RESH4DOTXAWXCH1NWW', 'RESH4DOTXAWXCH52NWW', 'RESH4DOXAWXCH1NWW', 'RESH4DOXAWXCH52NWW', 'RESH4DXAWXCH1NWW', 'RESH4DXAWXCH52NWW', 'RESH4FAXAWXCH1NWW', 'RESH4FAXAWXCH52NWW', 'RESH4FGXAWXCH1NWW', 'RESH4FGXAWXCH52NWW', 'RESH4FOXAWXCH1NWW', 'RESH4FOXAWXCH52NWW', 'RESH4FXAWXCH1NWW', 'RESH4FXAWXCH52NWW', 'RESH4MFNWW', 'RESH4RXAWXCH1NWW', 'RESH4RXAWXCH52NWW', 'RESH4SCFXAWXCH1NWW', 'RESH4SCFXAWXCH52NWW', 'RESH4SCSXAWXCH1NWW', 'RESH4SCSXAWXCH52NWW', 'RESH4SCSXCH1NWW', 'RESH4SCSXCH52NWW', 'RESH4SCXAWXCH1NWW', 'RESH4SCXAWXCH52NWW', 'RESH4SOXAWXCH1NWW', 'RESH4SOXAWXCH52NWW', 'RESH4SXAWXCH1NWW', 'RESH4SXAWXCH52NWW', 'RESPPAAML1LINWW', 'RESPPAAML1LPNWW', 'RESPPAAML2LINWW', 'RESPPAAML2LPNWW', 'RESPPAAML3LINWW', 'RESPPAAML3LPNWW', 'RESPPAATAL2HXAWXCH52NWW', 'RESPPACXCH1NWW', 'RESPPACXCH52NWW', 'RESPPAGXCH1NWW', 'RESPPAGXCH52NWW', 'RESPPAINWW', 'RESPPALDCXAWXCH1NWW', 'RESPPALDCXAWXCH52NWW', 'RESPPALDPXAWXCH1NWW', 'RESPPALDPXAWXCH52NWW', 'RESPPALDQXAWXCH1NWW', 'RESPPALDQXAWXCH52NWW', 'RESPPALDSXAWXCH1NWW', 'RESPPALDSXAWXCH52NWW', 'RESPPALDTXAWXCH1NWW', 'RESPPALDTXAWXCH52NWW', 'RESPPALDVNWW', 'RESPPALDXAWNWW', 'RESPPALDXAWXCH1NWW', 'RESPPALDXAWXCH52NWW', 'RESPPALDXCH1NWW', 'RESPPALDXCH52NWW', 'RESPPALGAMD15XCH1NWW', 'RESPPALGAMD16T90XCH1NWW', 'RESPPALGAMXCH1NWW', 'RESPPALGAMY01T05XCH1NWW', 'RESPPALGAMY01XCH1NWW', 'RESPPALGAMY05T10XCH1NWW', 'RESPPALGAMY10PXCH1NWW', 'RESPPALGAOXAWXCH1NWW', 'RESPPALGAOXAWXCH52NWW', 'RESPPALGAOXCH1NWW', 'RESPPALGAOXCH52NWW', 'RESPPALGASMCBNWW', 'RESPPALGASMCSNWW', 'RESPPALGASMENWW', 'RESPPALGASMOD15XCH1NWW', 'RESPPALGASMOD16T90XCH1NWW', 'RESPPALGASMOXAWXCH1NWW', 'RESPPALGASMOXAWXCH52NWW', 'RESPPALGASMOXCH1NWW', 'RESPPALGASMOXCH52NWW', 'RESPPALGASMOY01T05XCH1NWW', 'RESPPALGASMOY01XCH1NWW', 'RESPPALGASMOY05T10XCH1NWW', 'RESPPALGASMOY10PXCH1NWW', 'RESPPALGTRXAWXCH1NWW', 'RESPPALGTRXAWXCH52NWW', 'RESPPALGTRXCH1NWW', 'RESPPALGTRXCH52NWW', 'RESPPALGUMD15XCH1NWW', 'RESPPALGUMD16T90XCH1NWW', 'RESPPALGUMXCH1NWW', 'RESPPALGUMY01T05XCH1NWW', 'RESPPALGUMY01XCH1NWW', 'RESPPALGUMY05T10XCH1NWW', 'RESPPALGUMY10PXCH1NWW', 'RESPPALGUOBXAWXCH1NWW', 'RESPPALGUOBXAWXCH52NWW', 'RESPPALGUOBXCH1NWW', 'RESPPALGUOBXCH52NWW', 'RESPPALGUOMCXAWXCH1NWW', 'RESPPALGUOMCXAWXCH52NWW', 'RESPPALGUOMCXCH1NWW', 'RESPPALGUOMCXCH52NWW', 'RESPPALGUOMIXAWXCH1NWW', 'RESPPALGUOMIXAWXCH52NWW', 'RESPPALGUOMIXCH1NWW', 'RESPPALGUOMIXCH52NWW', 'RESPPALGUOMNXAWXCH1NWW', 'RESPPALGUOMNXAWXCH52NWW', 'RESPPALGUOMNXCH1NWW', 'RESPPALGUOMNXCH52NWW', 'RESPPALGUONNWW', 'RESPPALGUOXAWXCH1NWW', 'RESPPALGUOXAWXCH52NWW', 'RESPPALGUOXCH1NWW', 'RESPPALGUOXCH52NWW', 'RESPPALGXAWXCH1NWW', 'RESPPALGXAWXCH52NWW', 'RESPPALGXCH1NWW', 'RESPPALGXCH52NWW', 'RESPPALSDXAWNWW', 'RESPPALSDXAWXCH1NWW', 'RESPPALSDXAWXCH52NWW', 'RESPPALSDXCH1NWW', 'RESPPALSDXCH52NWW', 'RESPPALSPXAWNWW', 'RESPPALSPXAWXCH1NWW', 'RESPPALSPXAWXCH52NWW', 'RESPPALSPXCH1NWW', 'RESPPALSPXCH52NWW', 'RESPPALXCH1NWW', 'RESPPALXCH52NWW', 'RESPPANNWW', 'RESPPANWW', 'RESPPAOFXAWNWW', 'RESPPAOFXAWXCH1NWW', 'RESPPAOFXAWXCH52NWW', 'RESPPAOFXCH1NWW', 'RESPPAOFXCH52NWW', 'RESPPAOXCH1NWW', 'RESPPAOXCH52NWW', 'RESPPAPXCH1NWW', 'RESPPAPXCH52NWW', 'RESPPASXAWXCH1NWW', 'RESPPASXAWXCH52NWW', 'RESPPASXCH1NWW', 'RESPPASXCH52NWW', 'RESPPLAML1LTNWW', 'RESPPLAML2LTNWW', 'RESPPLAML3LTNWW', 'RESPPLCPXCH1NWW', 'RESPPLCPXCH52NWW', 'RESPPLCSXCH1NWW', 'RESPPLCSXCH52NWW', 'RESPPLCUXCH1NWW', 'RESPPLCUXCH52NWW', 'RESPPLCXCH1NWW', 'RESPPLCXCH52NWW', 'RESPPLLBXAWXCH1NWW', 'RESPPLLBXAWXCH52NWW', 'RESPPLLCNWW', 'RESPPLLDAXAWXCH1NWW', 'RESPPLLDAXAWXCH52NWW', 'RESPPLLDAXCH1NWW', 'RESPPLLDAXCH52NWW', 'RESPPLLDDXCH1NWW', 'RESPPLLDDXCH52NWW', 'RESPPLLDFXAWXCH1NWW', 'RESPPLLDFXAWXCH52NWW', 'RESPPLLDFXCH1NWW', 'RESPPLLDFXCH52NWW', 'RESPPLLDNWW', 'RESPPLLDOXAWXCH1NWW', 'RESPPLLDOXAWXCH52NWW', 'RESPPLLDOXCH1NWW', 'RESPPLLDOXCH52NWW', 'RESPPLLDTXAWXCH1NWW', 'RESPPLLDTXAWXCH52NWW', 'RESPPLLDTXCH1NWW', 'RESPPLLDTXCH52NWW', 'RESPPLLNHNWW', 'RESPPLLNOCNWW', 'RESPPLLNONNWW', 'RESPPLLNONWW', 'RESPPLLNWW', 'RESPPLLNXCH1NWW', 'RESPPLLNXCH52NWW', 'RESPPLLOONWW', 'RESPPLLOPNWW', 'RESPPLLOXCH1NWW', 'RESPPLLOXCH52NWW', 'RESPPLLRDXAWXCH1NWW', 'RESPPLLRDXAWXCH52NWW', 'RESPPLLRFXAWXCH1NWW', 'RESPPLLRFXAWXCH52NWW', 'RESPPLLRXAWXCH1NWW', 'RESPPLLRXAWXCH52NWW', 'RESPPLLRXCH1NWW', 'RESPPLLRXCH52NWW', 'RESPPLNWW', 'RESPPMAIXCH1NWW', 'RESPPMAIXCH52NWW', 'RESPPMAXCH1NWW', 'RESPPMAXCH52NWW', 'RESPPMLLCXCH1NWW', 'RESPPMLLCXCH52NWW', 'RESPPMLLDONWW', 'RESPPMLLDXCH1NWW', 'RESPPMLLDXCH52NWW', 'RESPPMLLXCH1NWW', 'RESPPMLLXCH52NWW', 'RESPPNGNWW', 'RESPPNNWW', 'RESPPNONWW', 'RESPPNSNWW', 'RESPPNTEPNWW', 'RESPPNTEPPNWW', 'RESPPNTNWW', 'RESTBCXAWXCH1NWW', 'RESTBCXAWXCH52NWW', 'RESTBHTXAWXCH1NWW', 'RESTBHTXAWXCH52NWW', 'RESTBMGXAWXCH1NWW', 'RESTBMGXAWXCH52NWW', 'RESTBMTXAWXCH1NWW', 'RESTBMTXAWXCH52NWW', 'RHEACBW027SBOG', 'RHEDCBW027SBOG', 'RHEFRIW027SBOG', 'RHELCBW027SBOG', 'RHESCBW027SBOG', 'RREACBW027SBOG', 'RREDCBW027SBOG', 'RREFRIW027SBOG', 'RRELCBW027SBOG', 'RREP15', 'RREP1690', 'RRESCBW027SBOG', 'SBCACBW027SBOG', 'SBCDCBW027SBOG', 'SBCFRIW027SBOG', 'SBCLCBW027SBOG', 'SBCSCBW027SBOG', 'SBFACBW027SBOG', 'SBFDCBW027SBOG', 'SBFFRIW027SBOG', 'SBFLCBW027SBOG', 'SBFSCBW027SBOG', 'SMPACBW027SBOG', 'SMPDCBW027SBOG', 'SMPFRIW027SBOG', 'SMPLCBW027SBOG', 'SMPSCBW027SBOG', 'SNFACBW027SBOG', 'SNFDCBW027SBOG', 'SNFFRIW027SBOG', 'SNFLCBW027SBOG', 'SNFSCBW027SBOG', 'SWP10Y', 'SWP15', 'SWP1690', 'SWP1T5', 'SWP5T10', 'SWP911Y', 'SWPT', 'TAMACBW027SBOG', 'TAMDCBW027SBOG', 'TAMFRIW027SBOG', 'TAMLCBW027SBOG', 'TAMSCBW027SBOG', 'TASACBW027SBOG', 'TASDCBW027SBOG', 'TASFRIW027SBOG', 'TASLCBW027SBOG', 'TASSCBW027SBOG', 'TERM15', 'TERM1690', 'TERM911Y', 'TERMT', 'TLAACBW027SBOG', 'TLADCBW027SBOG', 'TLAFRIW027SBOG', 'TLALCBW027SBOG', 'TLASCBW027SBOG', 'TLBACBW027SBOG', 'TLBDCBW027SBOG', 'TLBFRIW027SBOG', 'TLBLCBW027SBOG', 'TLBSCBW027SBOG', 'TMBACBW027SBOG', 'TMBDCBW027SBOG', 'TMBFRIW027SBOG', 'TMBLCBW027SBOG', 'TMBSCBW027SBOG', 'TNMACBW027SBOG', 'TNMDCBW027SBOG', 'TNMFRIW027SBOG', 'TNMLCBW027SBOG', 'TNMSCBW027SBOG', 'TOTBKCR', 'TOTBORR', 'TOTCI', 'TOTLCA', 'TOTLL', 'TOTRA', 'TREAS10Y', 'TREAS15', 'TREAS1590', 'TREAS1T5', 'TREAS5T10', 'TREAS911Y', 'TREAST', 'WABPL', 'WACL', 'WALCL', 'WALL', 'WAOAL', 'WBUSAPPWNSAUS', 'WCBLSA', 'WCICL', 'WCPCA', 'WCPIL', 'WCSL', 'WCTCL', 'WCURCIR', 'WCURRNS', 'WDDNS', 'WDFOA', 'WDFOL', 'WDSFAL', 'WDTGAL', 'WFASEC1', 'WFASECL1', 'WFCDA', 'WFEDSEC', 'WGCAL', 'WLAD', 'WLCFLL', 'WLCFLPCL', 'WLCFLSCL', 'WLCFLSECL', 'WLCFOCEL', 'WLDACL', 'WLDACLC', 'WLDECL', 'WLDLCL', 'WLFN', 'WLOCL', 'WLODL', 'WLODLL', 'WLRRAA', 'WLRRAFOIAL', 'WLRRAL', 'WLRRAOL', 'WLTDHDIA', 'WLTEC', 'WLTLECL', 'WM1NS', 'WM2NS', 'WMBSEC', 'WMTSEC1', 'WMTSECL1', 'WOCE', 'WOFDRBORBA', 'WOFDRBORBL', 'WOFDRBTHA', 'WOFDRBTHL', 'WOFRAL', 'WOFSRBFA', 'WOFSRBFL', 'WOFSRBGSA', 'WOFSRBGSL', 'WOFSRBRBC', 'WOLCL', 'WORAL', 'WOSDRA', 'WOSDRL', 'WOTHAST', 'WOTHLB', 'WOTHLIAB', 'WPC', 'WPCL', 'WPCLC', 'WRBWFRBL', 'WREPO', 'WREPODEL', 'WREPOFOR', 'WRESBAL', 'WRESCRT', 'WRMFNS', 'WSB', 'WSC', 'WSDEAL', 'WSDEALL', 'WSDFDSA', 'WSDFDSL', 'WSDONT', 'WSDONTL', 'WSDTREAA', 'WSDTREAL', 'WSECOUT', 'WSEFINO', 'WSEFINOL', 'WSEFINT1', 'WSEFINTL1', 'WSHOBA', 'WSHOBL', 'WSHOFADSL', 'WSHOICA', 'WSHOICL', 'WSHOMCB', 'WSHONBIIA', 'WSHONBIIL', 'WSHONBNA', 'WSHONBNL', 'WSHOSHO', 'WSHOTSA', 'WSHOTSL', 'WSMTMNS', 'WSRLL', 'WTCOA', 'WTCOL', 'WTFORBAFA', 'WTFORBAFL', 'WTFSRFA', 'WTFSRFL', 'WTREGEN', 'WUDSHO', 'WUPSHO']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_daily_reverse = {'AAA10Y': 'AVERAGE',\n",
    "                     'AAAFF': 'AVERAGE',\n",
    "                     'BAA10Y': 'AVERAGE',\n",
    "                     'BAAFF': 'AVERAGE',\n",
    "                     'BAMLEM1BRRAAA2ACRPIEY': 'AVERAGE',\n",
    "                     'BAMLEM1BRRAAA2ACRPIOAS': 'AVERAGE',\n",
    "                     'BAMLEM1BRRAAA2ACRPITRIV': 'AVERAGE',\n",
    "                     'BAMLEM1RAAA2ALCRPIUSEY': 'AVERAGE',\n",
    "                     'BAMLEM1RAAA2ALCRPIUSOAS': 'AVERAGE',\n",
    "                     'BAMLEM1RAAA2ALCRPIUSTRIV': 'AVERAGE',\n",
    "                     'BAMLEM2BRRBBBCRPIEY': 'AVERAGE',\n",
    "                     'BAMLEM2BRRBBBCRPIOAS': 'AVERAGE',\n",
    "                     'BAMLEM2BRRBBBCRPITRIV': 'AVERAGE',\n",
    "                     'BAMLEM2RBBBLCRPIUSEY': 'AVERAGE',\n",
    "                     'BAMLEM2RBBBLCRPIUSOAS': 'AVERAGE',\n",
    "                     'BAMLEM2RBBBLCRPIUSTRIV': 'AVERAGE',\n",
    "                     'BAMLEM3BRRBBCRPIEY': 'AVERAGE',\n",
    "                     'BAMLEM3BRRBBCRPIOAS': 'AVERAGE',\n",
    "                     'BAMLEM3BRRBBCRPITRIV': 'AVERAGE',\n",
    "                     'BAMLEM3RBBLCRPIUSEY': 'AVERAGE',\n",
    "                     'BAMLEM3RBBLCRPIUSOAS': 'AVERAGE',\n",
    "                     'BAMLEM3RBBLCRPIUSTRIV': 'AVERAGE',\n",
    "                     'BAMLEM4BRRBLCRPIEY': 'AVERAGE',\n",
    "                     'BAMLEM4BRRBLCRPIOAS': 'AVERAGE',\n",
    "                     'BAMLEM4BRRBLCRPITRIV': 'AVERAGE',\n",
    "                     'BAMLEM4RBLLCRPIUSEY': 'AVERAGE',\n",
    "                     'BAMLEM4RBLLCRPIUSOAS': 'AVERAGE',\n",
    "                     'BAMLEM4RBLLCRPIUSTRIV': 'AVERAGE',\n",
    "                     'BAMLEM5BCOCRPIEY': 'AVERAGE',\n",
    "                     'BAMLEM5BCOCRPIOAS': 'AVERAGE',\n",
    "                     'BAMLEM5BCOCRPITRIV': 'AVERAGE',\n",
    "                     'BAMLEMALLCRPIASIAUSEY': 'AVERAGE',\n",
    "                     'BAMLEMALLCRPIASIAUSOAS': 'AVERAGE',\n",
    "                     'BAMLEMALLCRPIASIAUSTRIV': 'AVERAGE',\n",
    "                     'BAMLEMCBPIEY': 'AVERAGE',\n",
    "                     'BAMLEMCBPIOAS': 'AVERAGE',\n",
    "                     'BAMLEMCLLCRPIUSEY': 'AVERAGE',\n",
    "                     'BAMLEMCLLCRPIUSOAS': 'AVERAGE',\n",
    "                     'BAMLEMEBCRPIEEY': 'AVERAGE',\n",
    "                     'BAMLEMEBCRPIEOAS': 'AVERAGE',\n",
    "                     'BAMLEMEBCRPIETRIV': 'AVERAGE',\n",
    "                     'BAMLEMELLCRPIEMEAUSEY': 'AVERAGE',\n",
    "                     'BAMLEMELLCRPIEMEAUSOAS': 'AVERAGE',\n",
    "                     'BAMLEMELLCRPIEMEAUSTRIV': 'AVERAGE',\n",
    "                     'BAMLEMFLFLCRPIUSEY': 'AVERAGE',\n",
    "                     'BAMLEMFLFLCRPIUSOAS': 'AVERAGE',\n",
    "                     'BAMLEMFLFLCRPIUSTRIV': 'AVERAGE',\n",
    "                     'BAMLEMFSFCRPIEY': 'AVERAGE',\n",
    "                     'BAMLEMFSFCRPIOAS': 'AVERAGE',\n",
    "                     'BAMLEMFSFCRPITRIV': 'AVERAGE',\n",
    "                     'BAMLEMHBHYCRPIEY': 'AVERAGE',\n",
    "                     'BAMLEMHBHYCRPIOAS': 'AVERAGE',\n",
    "                     'BAMLEMHBHYCRPITRIV': 'AVERAGE',\n",
    "                     'BAMLEMHGHGLCRPIUSEY': 'AVERAGE',\n",
    "                     'BAMLEMHGHGLCRPIUSOAS': 'AVERAGE',\n",
    "                     'BAMLEMHGHGLCRPIUSTRIV': 'AVERAGE',\n",
    "                     'BAMLEMHYHYLCRPIUSEY': 'AVERAGE',\n",
    "                     'BAMLEMHYHYLCRPIUSOAS': 'AVERAGE',\n",
    "                     'BAMLEMHYHYLCRPIUSTRIV': 'AVERAGE',\n",
    "                     'BAMLEMIBHGCRPIEY': 'AVERAGE',\n",
    "                     'BAMLEMIBHGCRPIOAS': 'AVERAGE',\n",
    "                     'BAMLEMIBHGCRPITRIV': 'AVERAGE',\n",
    "                     'BAMLEMLLLCRPILAUSEY': 'AVERAGE',\n",
    "                     'BAMLEMLLLCRPILAUSOAS': 'AVERAGE',\n",
    "                     'BAMLEMLLLCRPILAUSTRIV': 'AVERAGE',\n",
    "                     'BAMLEMNFNFLCRPIUSEY': 'AVERAGE',\n",
    "                     'BAMLEMNFNFLCRPIUSOAS': 'AVERAGE',\n",
    "                     'BAMLEMNFNFLCRPIUSTRIV': 'AVERAGE',\n",
    "                     'BAMLEMNSNFCRPIEY': 'AVERAGE',\n",
    "                     'BAMLEMNSNFCRPIOAS': 'AVERAGE',\n",
    "                     'BAMLEMNSNFCRPITRIV': 'AVERAGE',\n",
    "                     'BAMLEMPBPUBSICRPIEY': 'AVERAGE',\n",
    "                     'BAMLEMPBPUBSICRPIOAS': 'AVERAGE',\n",
    "                     'BAMLEMPBPUBSICRPITRIV': 'AVERAGE',\n",
    "                     'BAMLEMPTPRVICRPIEY': 'AVERAGE',\n",
    "                     'BAMLEMPTPRVICRPIOAS': 'AVERAGE',\n",
    "                     'BAMLEMPTPRVICRPITRIV': 'AVERAGE',\n",
    "                     'BAMLEMPUPUBSLCRPIUSEY': 'AVERAGE',\n",
    "                     'BAMLEMPUPUBSLCRPIUSOAS': 'AVERAGE',\n",
    "                     'BAMLEMPUPUBSLCRPIUSTRIV': 'AVERAGE',\n",
    "                     'BAMLEMPVPRIVSLCRPIUSEY': 'AVERAGE',\n",
    "                     'BAMLEMPVPRIVSLCRPIUSOAS': 'AVERAGE',\n",
    "                     'BAMLEMPVPRIVSLCRPIUSTRIV': 'AVERAGE',\n",
    "                     'BAMLEMRACRPIASIAEY': 'AVERAGE',\n",
    "                     'BAMLEMRACRPIASIAOAS': 'AVERAGE',\n",
    "                     'BAMLEMRACRPIASIATRIV': 'AVERAGE',\n",
    "                     'BAMLEMRECRPIEMEAEY': 'AVERAGE',\n",
    "                     'BAMLEMRECRPIEMEAOAS': 'AVERAGE',\n",
    "                     'BAMLEMRECRPIEMEATRIV': 'AVERAGE',\n",
    "                     'BAMLEMRLCRPILAEY': 'AVERAGE',\n",
    "                     'BAMLEMRLCRPILAOAS': 'AVERAGE',\n",
    "                     'BAMLEMRLCRPILATRIV': 'AVERAGE',\n",
    "                     'BAMLEMUBCRPIUSEY': 'AVERAGE',\n",
    "                     'BAMLEMUBCRPIUSOAS': 'AVERAGE',\n",
    "                     'BAMLEMUBCRPIUSTRIV': 'AVERAGE',\n",
    "                     'BAMLEMXOCOLCRPIUSEY': 'AVERAGE',\n",
    "                     'BAMLEMXOCOLCRPIUSOAS': 'AVERAGE',\n",
    "                     'BAMLEMXOCOLCRPIUSTRIV': 'AVERAGE',\n",
    "                     'CPFF': 'AVERAGE',\n",
    "                     'DAAA': 'AVERAGE',\n",
    "                     'DBAA': 'AVERAGE',\n",
    "                     'DCOILBRENTEU': 'AVERAGE',\n",
    "                     'DCOILWTICO': 'AVERAGE',\n",
    "                     'DCPF1M': 'AVERAGE',\n",
    "                     'DCPF2M': 'AVERAGE',\n",
    "                     'DCPF3M': 'AVERAGE',\n",
    "                     'DCPN2M': 'AVERAGE',\n",
    "                     'DCPN30': 'AVERAGE',\n",
    "                     'DCPN3M': 'AVERAGE',\n",
    "                     'DDFUELLA': 'AVERAGE',\n",
    "                     'DDFUELNYH': 'AVERAGE',\n",
    "                     'DDFUELUSGULF': 'AVERAGE',\n",
    "                     'DEXBZUS': 'AVERAGE',\n",
    "                     'DEXCAUS': 'AVERAGE',\n",
    "                     'DEXCHUS': 'AVERAGE',\n",
    "                     'DEXDNUS': 'AVERAGE',\n",
    "                     'DEXHKUS': 'AVERAGE',\n",
    "                     'DEXINUS': 'AVERAGE',\n",
    "                     'DEXJPUS': 'AVERAGE',\n",
    "                     'DEXKOUS': 'AVERAGE',\n",
    "                     'DEXMAUS': 'AVERAGE',\n",
    "                     'DEXMXUS': 'AVERAGE',\n",
    "                     'DEXNOUS': 'AVERAGE',\n",
    "                     'DEXSDUS': 'AVERAGE',\n",
    "                     'DEXSFUS': 'AVERAGE',\n",
    "                     'DEXSIUS': 'AVERAGE',\n",
    "                     'DEXSLUS': 'AVERAGE',\n",
    "                     'DEXSZUS': 'AVERAGE',\n",
    "                     'DEXTAUS': 'AVERAGE',\n",
    "                     'DEXTHUS': 'AVERAGE',\n",
    "                     'DEXUSAL': 'AVERAGE',\n",
    "                     'DEXUSEU': 'AVERAGE',\n",
    "                     'DEXUSNZ': 'AVERAGE',\n",
    "                     'DEXUSUK': 'AVERAGE',\n",
    "                     'DEXVZUS': 'AVERAGE',\n",
    "                     'DFEDTARL': 'AVERAGE',\n",
    "                     'DFEDTARU': 'AVERAGE',\n",
    "                     'DFF': 'AVERAGE',\n",
    "                     'DFII10': 'AVERAGE',\n",
    "                     'DFII20': 'AVERAGE',\n",
    "                     'DFII30': 'AVERAGE',\n",
    "                     'DFII5': 'AVERAGE',\n",
    "                     'DFII7': 'AVERAGE',\n",
    "                     'DGASNYH': 'AVERAGE',\n",
    "                     'DGASUSGULF': 'AVERAGE',\n",
    "                     'DGS1': 'AVERAGE',\n",
    "                     'DGS10': 'AVERAGE',\n",
    "                     'DGS1MO': 'AVERAGE',\n",
    "                     'DGS2': 'AVERAGE',\n",
    "                     'DGS20': 'AVERAGE',\n",
    "                     'DGS3': 'AVERAGE',\n",
    "                     'DGS30': 'AVERAGE',\n",
    "                     'DGS3MO': 'AVERAGE',\n",
    "                     'DGS5': 'AVERAGE',\n",
    "                     'DGS6MO': 'AVERAGE',\n",
    "                     'DGS7': 'AVERAGE',\n",
    "                     'DHOILNYH': 'AVERAGE',\n",
    "                     'DJFUELUSGULF': 'AVERAGE',\n",
    "                     'DLTIIT': 'AVERAGE',\n",
    "                     'DPCREDIT': 'AVERAGE',\n",
    "                     'DPRIME': 'AVERAGE',\n",
    "                     'DPROPANEMBTX': 'AVERAGE',\n",
    "                     'DRGASLA': 'AVERAGE',\n",
    "                     'DTB1YR': 'AVERAGE',\n",
    "                     'DTB3': 'AVERAGE',\n",
    "                     'DTB4WK': 'AVERAGE',\n",
    "                     'DTB6': 'AVERAGE',\n",
    "                     'DTP10J22': 'AVERAGE',\n",
    "                     'DTP10J23': 'AVERAGE',\n",
    "                     'DTP10J24': 'AVERAGE',\n",
    "                     'DTP10J25': 'AVERAGE',\n",
    "                     'DTP10J26': 'AVERAGE',\n",
    "                     'DTP10J27': 'AVERAGE',\n",
    "                     'DTP10J28': 'AVERAGE',\n",
    "                     'DTP10J29': 'AVERAGE',\n",
    "                     'DTP10J30': 'AVERAGE',\n",
    "                     'DTP10L21': 'AVERAGE',\n",
    "                     'DTP10L22': 'AVERAGE',\n",
    "                     'DTP10L23': 'AVERAGE',\n",
    "                     'DTP10L24': 'AVERAGE',\n",
    "                     'DTP10L25': 'AVERAGE',\n",
    "                     'DTP10L26': 'AVERAGE',\n",
    "                     'DTP10L27': 'AVERAGE',\n",
    "                     'DTP10L28': 'AVERAGE',\n",
    "                     'DTP10L29': 'AVERAGE',\n",
    "                     'DTP20J25': 'AVERAGE',\n",
    "                     'DTP20J26': 'AVERAGE',\n",
    "                     'DTP20J27': 'AVERAGE',\n",
    "                     'DTP20J28': 'AVERAGE',\n",
    "                     'DTP20J29': 'AVERAGE',\n",
    "                     'DTP30A28': 'AVERAGE',\n",
    "                     'DTP30A29': 'AVERAGE',\n",
    "                     'DTP30F40': 'AVERAGE',\n",
    "                     'DTP30F41': 'AVERAGE',\n",
    "                     'DTP30F42': 'AVERAGE',\n",
    "                     'DTP30F43': 'AVERAGE',\n",
    "                     'DTP30F44': 'AVERAGE',\n",
    "                     'DTP30F45': 'AVERAGE',\n",
    "                     'DTP30F46': 'AVERAGE',\n",
    "                     'DTP30F47': 'AVERAGE',\n",
    "                     'DTP30F48': 'AVERAGE',\n",
    "                     'DTP30F49': 'AVERAGE',\n",
    "                     'DTP30F50': 'AVERAGE',\n",
    "                     'DTP3HA32': 'AVERAGE',\n",
    "                     'DTP5A22': 'AVERAGE',\n",
    "                     'DTP5A23': 'AVERAGE',\n",
    "                     'DTP5A24': 'AVERAGE',\n",
    "                     'DTP5A25': 'AVERAGE',\n",
    "                     'DTP5C24': 'AVERAGE',\n",
    "                     'DTWEXAFEGS': 'AVERAGE',\n",
    "                     'DTWEXBGS': 'AVERAGE',\n",
    "                     'DTWEXEMEGS': 'AVERAGE',\n",
    "                     'EFFR': 'AVERAGE',\n",
    "                     'EFFR1': 'AVERAGE',\n",
    "                     'EFFR25': 'AVERAGE',\n",
    "                     'EFFR75': 'AVERAGE',\n",
    "                     'EFFR99': 'AVERAGE',\n",
    "                     'ICERATES1100EUR10Y': 'AVERAGE',\n",
    "                     'ICERATES1100EUR12Y': 'AVERAGE',\n",
    "                     'ICERATES1100EUR15Y': 'AVERAGE',\n",
    "                     'ICERATES1100EUR1Y': 'AVERAGE',\n",
    "                     'ICERATES1100EUR20Y': 'AVERAGE',\n",
    "                     'ICERATES1100EUR25Y': 'AVERAGE',\n",
    "                     'ICERATES1100EUR2Y': 'AVERAGE',\n",
    "                     'ICERATES1100EUR30Y': 'AVERAGE',\n",
    "                     'ICERATES1100EUR3Y': 'AVERAGE',\n",
    "                     'ICERATES1100EUR4Y': 'AVERAGE',\n",
    "                     'ICERATES1100EUR5Y': 'AVERAGE',\n",
    "                     'ICERATES1100EUR6Y': 'AVERAGE',\n",
    "                     'ICERATES1100EUR7Y': 'AVERAGE',\n",
    "                     'ICERATES1100EUR8Y': 'AVERAGE',\n",
    "                     'ICERATES1100EUR9Y': 'AVERAGE',\n",
    "                     'ICERATES1100GBP10Y': 'AVERAGE',\n",
    "                     'ICERATES1100GBP12Y': 'AVERAGE',\n",
    "                     'ICERATES1100GBP15Y': 'AVERAGE',\n",
    "                     'ICERATES1100GBP1Y': 'AVERAGE',\n",
    "                     'ICERATES1100GBP20Y': 'AVERAGE',\n",
    "                     'ICERATES1100GBP25Y': 'AVERAGE',\n",
    "                     'ICERATES1100GBP2Y': 'AVERAGE',\n",
    "                     'ICERATES1100GBP30Y': 'AVERAGE',\n",
    "                     'ICERATES1100GBP3Y': 'AVERAGE',\n",
    "                     'ICERATES1100GBP4Y': 'AVERAGE',\n",
    "                     'ICERATES1100GBP5Y': 'AVERAGE',\n",
    "                     'ICERATES1100GBP6Y': 'AVERAGE',\n",
    "                     'ICERATES1100GBP7Y': 'AVERAGE',\n",
    "                     'ICERATES1100GBP8Y': 'AVERAGE',\n",
    "                     'ICERATES1100GBP9Y': 'AVERAGE',\n",
    "                     'ICERATES1100USD10Y': 'AVERAGE',\n",
    "                     'ICERATES1100USD15Y': 'AVERAGE',\n",
    "                     'ICERATES1100USD1Y': 'AVERAGE',\n",
    "                     'ICERATES1100USD20Y': 'AVERAGE',\n",
    "                     'ICERATES1100USD2Y': 'AVERAGE',\n",
    "                     'ICERATES1100USD30Y': 'AVERAGE',\n",
    "                     'ICERATES1100USD3Y': 'AVERAGE',\n",
    "                     'ICERATES1100USD4Y': 'AVERAGE',\n",
    "                     'ICERATES1100USD5Y': 'AVERAGE',\n",
    "                     'ICERATES1100USD6Y': 'AVERAGE',\n",
    "                     'ICERATES1100USD7Y': 'AVERAGE',\n",
    "                     'ICERATES1100USD8Y': 'AVERAGE',\n",
    "                     'ICERATES1100USD9Y': 'AVERAGE',\n",
    "                     'ICERATES1200EUR10Y': 'AVERAGE',\n",
    "                     'ICERATES1200EUR12Y': 'AVERAGE',\n",
    "                     'ICERATES1200EUR15Y': 'AVERAGE',\n",
    "                     'ICERATES1200EUR1Y': 'AVERAGE',\n",
    "                     'ICERATES1200EUR20Y': 'AVERAGE',\n",
    "                     'ICERATES1200EUR25Y': 'AVERAGE',\n",
    "                     'ICERATES1200EUR2Y': 'AVERAGE',\n",
    "                     'ICERATES1200EUR30Y': 'AVERAGE',\n",
    "                     'ICERATES1200EUR3Y': 'AVERAGE',\n",
    "                     'ICERATES1200EUR4Y': 'AVERAGE',\n",
    "                     'ICERATES1200EUR5Y': 'AVERAGE',\n",
    "                     'ICERATES1200EUR6Y': 'AVERAGE',\n",
    "                     'ICERATES1200EUR7Y': 'AVERAGE',\n",
    "                     'ICERATES1200EUR8Y': 'AVERAGE',\n",
    "                     'ICERATES1200EUR9Y': 'AVERAGE',\n",
    "                     'ICERATES1500USD1Y': 'AVERAGE',\n",
    "                     'ICESPREADS1100USD10Y': 'AVERAGE',\n",
    "                     'ICESPREADS1100USD2Y': 'AVERAGE',\n",
    "                     'ICESPREADS1100USD3Y': 'AVERAGE',\n",
    "                     'ICESPREADS1100USD5Y': 'AVERAGE',\n",
    "                     'ICESPREADS1100USD7Y': 'AVERAGE',\n",
    "                     'INFECTDISEMVTRACKD': 'AVERAGE',\n",
    "                     'IOER': 'AVERAGE',\n",
    "                     'IORR': 'AVERAGE',\n",
    "                     'OBFR': 'AVERAGE',\n",
    "                     'OBFR1': 'AVERAGE',\n",
    "                     'OBFR25': 'AVERAGE',\n",
    "                     'OBFR75': 'AVERAGE',\n",
    "                     'OBFR99': 'AVERAGE',\n",
    "                     'OBMMIC15YF': 'AVERAGE',\n",
    "                     'OBMMIC30YF': 'AVERAGE',\n",
    "                     'OBMMIC30YFLVGT80FB680A699': 'AVERAGE',\n",
    "                     'OBMMIC30YFLVGT80FB700A719': 'AVERAGE',\n",
    "                     'OBMMIC30YFLVGT80FB720A739': 'AVERAGE',\n",
    "                     'OBMMIC30YFLVGT80FGE740': 'AVERAGE',\n",
    "                     'OBMMIC30YFLVGT80FLT680': 'AVERAGE',\n",
    "                     'OBMMIC30YFLVLE80FB680A699': 'AVERAGE',\n",
    "                     'OBMMIC30YFLVLE80FB700A719': 'AVERAGE',\n",
    "                     'OBMMIC30YFLVLE80FB720A739': 'AVERAGE',\n",
    "                     'OBMMIC30YFLVLE80FGE740': 'AVERAGE',\n",
    "                     'OBMMIC30YFLVLE80FLT680': 'AVERAGE',\n",
    "                     'OBMMIC30YFNA': 'AVERAGE',\n",
    "                     'OBMMIFHA30YF': 'AVERAGE',\n",
    "                     'OBMMIJUMBO30YF': 'AVERAGE',\n",
    "                     'OBMMIUSDA30YF': 'AVERAGE',\n",
    "                     'OBMMIVA30YF': 'AVERAGE',\n",
    "                     'RIFSPPAAAD01NB': 'AVERAGE',\n",
    "                     'RIFSPPAAAD07NB': 'AVERAGE',\n",
    "                     'RIFSPPAAAD15NB': 'AVERAGE',\n",
    "                     'RIFSPPAAAD30NB': 'AVERAGE',\n",
    "                     'RIFSPPAAAD60NB': 'AVERAGE',\n",
    "                     'RIFSPPAAAD90NB': 'AVERAGE',\n",
    "                     'RIFSPPFAAD01NB': 'AVERAGE',\n",
    "                     'RIFSPPFAAD07NB': 'AVERAGE',\n",
    "                     'RIFSPPFAAD15NB': 'AVERAGE',\n",
    "                     'RIFSPPFAAD30NB': 'AVERAGE',\n",
    "                     'RIFSPPFAAD60NB': 'AVERAGE',\n",
    "                     'RIFSPPFAAD90NB': 'AVERAGE',\n",
    "                     'RIFSPPNA2P2D01NB': 'AVERAGE',\n",
    "                     'RIFSPPNA2P2D07NB': 'AVERAGE',\n",
    "                     'RIFSPPNA2P2D15NB': 'AVERAGE',\n",
    "                     'RIFSPPNA2P2D30NB': 'AVERAGE',\n",
    "                     'RIFSPPNA2P2D60NB': 'AVERAGE',\n",
    "                     'RIFSPPNA2P2D90NB': 'AVERAGE',\n",
    "                     'RIFSPPNAAD01NB': 'AVERAGE',\n",
    "                     'RIFSPPNAAD07NB': 'AVERAGE',\n",
    "                     'RIFSPPNAAD15NB': 'AVERAGE',\n",
    "                     'RIFSPPNAAD30NB': 'AVERAGE',\n",
    "                     'RIFSPPNAAD60NB': 'AVERAGE',\n",
    "                     'RIFSPPNAAD90NB': 'AVERAGE',\n",
    "                     'RRPONTSYAWARD': 'AVERAGE',\n",
    "                     'SOFR': 'AVERAGE',\n",
    "                     'SOFR1': 'AVERAGE',\n",
    "                     'SOFR180DAYAVG': 'AVERAGE',\n",
    "                     'SOFR25': 'AVERAGE',\n",
    "                     'SOFR30DAYAVG': 'AVERAGE',\n",
    "                     'SOFR75': 'AVERAGE',\n",
    "                     'SOFR90DAYAVG': 'AVERAGE',\n",
    "                     'SOFR99': 'AVERAGE',\n",
    "                     'SOFRINDEX': 'AVERAGE',\n",
    "                     'T10Y2Y': 'AVERAGE',\n",
    "                     'T10Y3M': 'AVERAGE',\n",
    "                     'T10YFF': 'AVERAGE',\n",
    "                     'T10YIE': 'AVERAGE',\n",
    "                     'T1YFF': 'AVERAGE',\n",
    "                     'T3MFF': 'AVERAGE',\n",
    "                     'T5YFF': 'AVERAGE',\n",
    "                     'T5YIE': 'AVERAGE',\n",
    "                     'T5YIFR': 'AVERAGE',\n",
    "                     'T6MFF': 'AVERAGE',\n",
    "                     'TEDRATE': 'AVERAGE',\n",
    "                     'THREEFF1': 'AVERAGE',\n",
    "                     'THREEFF10': 'AVERAGE',\n",
    "                     'THREEFF2': 'AVERAGE',\n",
    "                     'THREEFF3': 'AVERAGE',\n",
    "                     'THREEFF4': 'AVERAGE',\n",
    "                     'THREEFF5': 'AVERAGE',\n",
    "                     'THREEFF6': 'AVERAGE',\n",
    "                     'THREEFF7': 'AVERAGE',\n",
    "                     'THREEFF8': 'AVERAGE',\n",
    "                     'THREEFF9': 'AVERAGE',\n",
    "                     'THREEFFTP1': 'AVERAGE',\n",
    "                     'THREEFFTP10': 'AVERAGE',\n",
    "                     'THREEFFTP2': 'AVERAGE',\n",
    "                     'THREEFFTP3': 'AVERAGE',\n",
    "                     'THREEFFTP4': 'AVERAGE',\n",
    "                     'THREEFFTP5': 'AVERAGE',\n",
    "                     'THREEFFTP6': 'AVERAGE',\n",
    "                     'THREEFFTP7': 'AVERAGE',\n",
    "                     'THREEFFTP8': 'AVERAGE',\n",
    "                     'THREEFFTP9': 'AVERAGE',\n",
    "                     'THREEFY1': 'AVERAGE',\n",
    "                     'THREEFY10': 'AVERAGE',\n",
    "                     'THREEFY2': 'AVERAGE',\n",
    "                     'THREEFY3': 'AVERAGE',\n",
    "                     'THREEFY4': 'AVERAGE',\n",
    "                     'THREEFY5': 'AVERAGE',\n",
    "                     'THREEFY6': 'AVERAGE',\n",
    "                     'THREEFY7': 'AVERAGE',\n",
    "                     'THREEFY8': 'AVERAGE',\n",
    "                     'THREEFY9': 'AVERAGE',\n",
    "                     'THREEFYTP1': 'AVERAGE',\n",
    "                     'THREEFYTP10': 'AVERAGE',\n",
    "                     'THREEFYTP2': 'AVERAGE',\n",
    "                     'THREEFYTP3': 'AVERAGE',\n",
    "                     'THREEFYTP4': 'AVERAGE',\n",
    "                     'THREEFYTP5': 'AVERAGE',\n",
    "                     'THREEFYTP6': 'AVERAGE',\n",
    "                     'THREEFYTP7': 'AVERAGE',\n",
    "                     'THREEFYTP8': 'AVERAGE',\n",
    "                     'THREEFYTP9': 'AVERAGE',\n",
    "                     'USEPUINDXD': 'AVERAGE',\n",
    "                     'WLEMUINDXD': 'AVERAGE',\n",
    "                     'AB1020AAAMT': 'SUM',\n",
    "                     'AB1020AAVOL': 'SUM',\n",
    "                     'AB14AAAMT': 'SUM',\n",
    "                     'AB14AAVOL': 'SUM',\n",
    "                     'AB2140AAAMT': 'SUM',\n",
    "                     'AB2140AAVOL': 'SUM',\n",
    "                     'AB4180AAAMT': 'SUM',\n",
    "                     'AB4180AAVOL': 'SUM',\n",
    "                     'AB59AAAMT': 'SUM',\n",
    "                     'AB59AAVOL': 'SUM',\n",
    "                     'ABGT80AAAMT': 'SUM',\n",
    "                     'ABGT80AAVOL': 'SUM',\n",
    "                     'CBBCHUSD': 'SUM',\n",
    "                     'CBBTCUSD': 'SUM',\n",
    "                     'CBETHUSD': 'SUM',\n",
    "                     'CBLTCUSD': 'SUM',\n",
    "                     'DHHNGSP': 'SUM',\n",
    "                     'EFFRVOL': 'SUM',\n",
    "                     'FIN1020AAAMT': 'SUM',\n",
    "                     'FIN1020AAVOL': 'SUM',\n",
    "                     'FIN14AAAMT': 'SUM',\n",
    "                     'FIN14AAVOL': 'SUM',\n",
    "                     'FIN2140AAAMT': 'SUM',\n",
    "                     'FIN2140AAVOL': 'SUM',\n",
    "                     'FIN4180AAAMT': 'SUM',\n",
    "                     'FIN4180AAVOL': 'SUM',\n",
    "                     'FIN59AAAMT': 'SUM',\n",
    "                     'FIN59AAVOL': 'SUM',\n",
    "                     'FINGT80AAAMT': 'SUM',\n",
    "                     'FINGT80AAVOL': 'SUM',\n",
    "                     'MKT1020MKTAMT': 'SUM',\n",
    "                     'MKT1020MKTVOL': 'SUM',\n",
    "                     'MKT14MKTAMT': 'SUM',\n",
    "                     'MKT14MKTVOL': 'SUM',\n",
    "                     'MKT2140MKTAMT': 'SUM',\n",
    "                     'MKT2140MKTVOL': 'SUM',\n",
    "                     'MKT4180MKTAMT': 'SUM',\n",
    "                     'MKT4180MKTVOL': 'SUM',\n",
    "                     'MKT59MKTAMT': 'SUM',\n",
    "                     'MKT59MKTVOL': 'SUM',\n",
    "                     'MKTGT80MKTAMT': 'SUM',\n",
    "                     'MKTGT80MKTVOL': 'SUM',\n",
    "                     'NONFIN1020A2P2AMT': 'SUM',\n",
    "                     'NONFIN1020A2P2VOL': 'SUM',\n",
    "                     'NONFIN1020AAAMT': 'SUM',\n",
    "                     'NONFIN1020AAVOL': 'SUM',\n",
    "                     'NONFIN14A2P2AMT': 'SUM',\n",
    "                     'NONFIN14A2P2VOL': 'SUM',\n",
    "                     'NONFIN14AAAMT': 'SUM',\n",
    "                     'NONFIN14AAVOL': 'SUM',\n",
    "                     'NONFIN2140A2P2AMT': 'SUM',\n",
    "                     'NONFIN2140A2P2VOL': 'SUM',\n",
    "                     'NONFIN2140AAAMT': 'SUM',\n",
    "                     'NONFIN2140AAVOL': 'SUM',\n",
    "                     'NONFIN4180A2P2AMT': 'SUM',\n",
    "                     'NONFIN4180A2P2VOL': 'SUM',\n",
    "                     'NONFIN4180AAAMT': 'SUM',\n",
    "                     'NONFIN4180AAVOL': 'SUM',\n",
    "                     'NONFIN59A2P2AMT': 'SUM',\n",
    "                     'NONFIN59A2P2VOL': 'SUM',\n",
    "                     'NONFIN59AAAMT': 'SUM',\n",
    "                     'NONFIN59AAVOL': 'SUM',\n",
    "                     'NONFINGT80A2P2AMT': 'SUM',\n",
    "                     'NONFINGT80A2P2VOL': 'SUM',\n",
    "                     'NONFINGT80AAAMT': 'SUM',\n",
    "                     'NONFINGT80AAVOL': 'SUM',\n",
    "                     'OBFRVOL': 'SUM',\n",
    "                     'RPAGYD': 'SUM',\n",
    "                     'RPMBSD': 'SUM',\n",
    "                     'RPONAGYD': 'SUM',\n",
    "                     'RPONMBSD': 'SUM',\n",
    "                     'RPONTSYD': 'SUM',\n",
    "                     'RPONTTLD': 'SUM',\n",
    "                     'RPTMAGYD': 'SUM',\n",
    "                     'RPTMMBSD': 'SUM',\n",
    "                     'RPTMTSYD': 'SUM',\n",
    "                     'RPTMTTLD': 'SUM',\n",
    "                     'RPTSYD': 'SUM',\n",
    "                     'RPTTLD': 'SUM',\n",
    "                     'RRPAGYD': 'SUM',\n",
    "                     'RRPMBSD': 'SUM',\n",
    "                     'RRPONAGYD': 'SUM',\n",
    "                     'RRPONMBSD': 'SUM',\n",
    "                     'RRPONTSYD': 'SUM',\n",
    "                     'RRPONTTLD': 'SUM',\n",
    "                     'RRPTMAGYD': 'SUM',\n",
    "                     'RRPTMMBSD': 'SUM',\n",
    "                     'RRPTMTSYD': 'SUM',\n",
    "                     'RRPTMTTLD': 'SUM',\n",
    "                     'RRPTSYD': 'SUM',\n",
    "                     'RRPTTLD': 'SUM',\n",
    "                     'SOFRVOL': 'SUM',\n",
    "                     'BAMLC0A0CM': 'CLOSE',\n",
    "                     'BAMLC0A0CMEY': 'CLOSE',\n",
    "                     'BAMLC0A0CMSYTW': 'CLOSE',\n",
    "                     'BAMLC0A1CAAA': 'CLOSE',\n",
    "                     'BAMLC0A1CAAAEY': 'CLOSE',\n",
    "                     'BAMLC0A1CAAASYTW': 'CLOSE',\n",
    "                     'BAMLC0A2CAA': 'CLOSE',\n",
    "                     'BAMLC0A2CAAEY': 'CLOSE',\n",
    "                     'BAMLC0A2CAASYTW': 'CLOSE',\n",
    "                     'BAMLC0A3CA': 'CLOSE',\n",
    "                     'BAMLC0A3CAEY': 'CLOSE',\n",
    "                     'BAMLC0A3CASYTW': 'CLOSE',\n",
    "                     'BAMLC0A4CBBB': 'CLOSE',\n",
    "                     'BAMLC0A4CBBBEY': 'CLOSE',\n",
    "                     'BAMLC0A4CBBBSYTW': 'CLOSE',\n",
    "                     'BAMLC1A0C13Y': 'CLOSE',\n",
    "                     'BAMLC1A0C13YEY': 'CLOSE',\n",
    "                     'BAMLC1A0C13YSYTW': 'CLOSE',\n",
    "                     'BAMLC2A0C35Y': 'CLOSE',\n",
    "                     'BAMLC2A0C35YEY': 'CLOSE',\n",
    "                     'BAMLC2A0C35YSYTW': 'CLOSE',\n",
    "                     'BAMLC3A0C57Y': 'CLOSE',\n",
    "                     'BAMLC3A0C57YEY': 'CLOSE',\n",
    "                     'BAMLC3A0C57YSYTW': 'CLOSE',\n",
    "                     'BAMLC4A0C710Y': 'CLOSE',\n",
    "                     'BAMLC4A0C710YEY': 'CLOSE',\n",
    "                     'BAMLC4A0C710YSYTW': 'CLOSE',\n",
    "                     'BAMLC7A0C1015Y': 'CLOSE',\n",
    "                     'BAMLC7A0C1015YEY': 'CLOSE',\n",
    "                     'BAMLC7A0C1015YSYTW': 'CLOSE',\n",
    "                     'BAMLC8A0C15PY': 'CLOSE',\n",
    "                     'BAMLC8A0C15PYEY': 'CLOSE',\n",
    "                     'BAMLC8A0C15PYSYTW': 'CLOSE',\n",
    "                     'BAMLCC0A0CMTRIV': 'CLOSE',\n",
    "                     'BAMLCC0A1AAATRIV': 'CLOSE',\n",
    "                     'BAMLCC0A2AATRIV': 'CLOSE',\n",
    "                     'BAMLCC0A3ATRIV': 'CLOSE',\n",
    "                     'BAMLCC0A4BBBTRIV': 'CLOSE',\n",
    "                     'BAMLCC1A013YTRIV': 'CLOSE',\n",
    "                     'BAMLCC2A035YTRIV': 'CLOSE',\n",
    "                     'BAMLCC3A057YTRIV': 'CLOSE',\n",
    "                     'BAMLCC4A0710YTRIV': 'CLOSE',\n",
    "                     'BAMLCC7A01015YTRIV': 'CLOSE',\n",
    "                     'BAMLCC8A015PYTRIV': 'CLOSE',\n",
    "                     'BAMLEM1BRRAAA2ACRPISYTW': 'CLOSE',\n",
    "                     'BAMLEM1RAAA2ALCRPIUSSYTW': 'CLOSE',\n",
    "                     'BAMLEM2BRRBBBCRPISYTW': 'CLOSE',\n",
    "                     'BAMLEM2RBBBLCRPIUSSYTW': 'CLOSE',\n",
    "                     'BAMLEM3BRRBBCRPISYTW': 'CLOSE',\n",
    "                     'BAMLEM3RBBLCRPIUSSYTW': 'CLOSE',\n",
    "                     'BAMLEM4BRRBLCRPISYTW': 'CLOSE',\n",
    "                     'BAMLEM4RBLLCRPIUSSYTW': 'CLOSE',\n",
    "                     'BAMLEM5BCOCRPISYTW': 'CLOSE',\n",
    "                     'BAMLEMALLCRPIASIAUSSYTW': 'CLOSE',\n",
    "                     'BAMLEMCBPISYTW': 'CLOSE',\n",
    "                     'BAMLEMCBPITRIV': 'CLOSE',\n",
    "                     'BAMLEMCLLCRPIUSSYTW': 'CLOSE',\n",
    "                     'BAMLEMCLLCRPIUSTRIV': 'CLOSE',\n",
    "                     'BAMLEMEBCRPIESYTW': 'CLOSE',\n",
    "                     'BAMLEMELLCRPIEMEAUSSYTW': 'CLOSE',\n",
    "                     'BAMLEMFLFLCRPIUSSYTW': 'CLOSE',\n",
    "                     'BAMLEMFSFCRPISYTW': 'CLOSE',\n",
    "                     'BAMLEMHBHYCRPISYTW': 'CLOSE',\n",
    "                     'BAMLEMHGHGLCRPIUSSYTW': 'CLOSE',\n",
    "                     'BAMLEMHYHYLCRPIUSSYTW': 'CLOSE',\n",
    "                     'BAMLEMIBHGCRPISYTW': 'CLOSE',\n",
    "                     'BAMLEMLLLCRPILAUSSYTW': 'CLOSE',\n",
    "                     'BAMLEMNFNFLCRPIUSSYTW': 'CLOSE',\n",
    "                     'BAMLEMNSNFCRPISYTW': 'CLOSE',\n",
    "                     'BAMLEMPBPUBSICRPISYTW': 'CLOSE',\n",
    "                     'BAMLEMPTPRVICRPISYTW': 'CLOSE',\n",
    "                     'BAMLEMPUPUBSLCRPIUSSYTW': 'CLOSE',\n",
    "                     'BAMLEMPVPRIVSLCRPIUSSYTW': 'CLOSE',\n",
    "                     'BAMLEMRACRPIASIASYTW': 'CLOSE',\n",
    "                     'BAMLEMRECRPIEMEASYTW': 'CLOSE',\n",
    "                     'BAMLEMRLCRPILASYTW': 'CLOSE',\n",
    "                     'BAMLEMUBCRPIUSSYTW': 'CLOSE',\n",
    "                     'BAMLEMXOCOLCRPIUSSYTW': 'CLOSE',\n",
    "                     'BAMLH0A0HYM2': 'CLOSE',\n",
    "                     'BAMLH0A0HYM2EY': 'CLOSE',\n",
    "                     'BAMLH0A0HYM2SYTW': 'CLOSE',\n",
    "                     'BAMLH0A1HYBB': 'CLOSE',\n",
    "                     'BAMLH0A1HYBBEY': 'CLOSE',\n",
    "                     'BAMLH0A1HYBBSYTW': 'CLOSE',\n",
    "                     'BAMLH0A2HYB': 'CLOSE',\n",
    "                     'BAMLH0A2HYBEY': 'CLOSE',\n",
    "                     'BAMLH0A2HYBSYTW': 'CLOSE',\n",
    "                     'BAMLH0A3HYC': 'CLOSE',\n",
    "                     'BAMLH0A3HYCEY': 'CLOSE',\n",
    "                     'BAMLH0A3HYCSYTW': 'CLOSE',\n",
    "                     'BAMLHE00EHYIEY': 'CLOSE',\n",
    "                     'BAMLHE00EHYIOAS': 'CLOSE',\n",
    "                     'BAMLHE00EHYISYTW': 'CLOSE',\n",
    "                     'BAMLHE00EHYITRIV': 'CLOSE',\n",
    "                     'BAMLHYH0A0HYM2TRIV': 'CLOSE',\n",
    "                     'BAMLHYH0A1BBTRIV': 'CLOSE',\n",
    "                     'BAMLHYH0A2BTRIV': 'CLOSE',\n",
    "                     'BAMLHYH0A3CMTRIV': 'CLOSE',\n",
    "                     'DJCA': 'CLOSE',\n",
    "                     'DJIA': 'CLOSE',\n",
    "                     'DJTA': 'CLOSE',\n",
    "                     'DJUA': 'CLOSE',\n",
    "                     'GVZCLS': 'CLOSE',\n",
    "                     'NASDAQ100': 'CLOSE',\n",
    "                     'NASDAQCOM': 'CLOSE',\n",
    "                     'NIKKEI225': 'CLOSE',\n",
    "                     'OVXCLS': 'CLOSE',\n",
    "                     'RVXCLS': 'CLOSE',\n",
    "                     'SP500': 'CLOSE',\n",
    "                     'WILL2500IND': 'CLOSE',\n",
    "                     'WILL2500INDGR': 'CLOSE',\n",
    "                     'WILL2500INDVAL': 'CLOSE',\n",
    "                     'WILL2500PR': 'CLOSE',\n",
    "                     'WILL2500PRGR': 'CLOSE',\n",
    "                     'WILL2500PRVAL': 'CLOSE',\n",
    "                     'WILL4500IND': 'CLOSE',\n",
    "                     'WILL4500PR': 'CLOSE',\n",
    "                     'WILL5000IND': 'CLOSE',\n",
    "                     'WILL5000INDFC': 'CLOSE',\n",
    "                     'WILL5000PR': 'CLOSE',\n",
    "                     'WILL5000PRFC': 'CLOSE',\n",
    "                     'WILLLRGCAP': 'CLOSE',\n",
    "                     'WILLLRGCAPGR': 'CLOSE',\n",
    "                     'WILLLRGCAPGRPR': 'CLOSE',\n",
    "                     'WILLLRGCAPPR': 'CLOSE',\n",
    "                     'WILLLRGCAPVAL': 'CLOSE',\n",
    "                     'WILLLRGCAPVALPR': 'CLOSE',\n",
    "                     'WILLMICROCAP': 'CLOSE',\n",
    "                     'WILLMICROCAPPR': 'CLOSE',\n",
    "                     'WILLMIDCAP': 'CLOSE',\n",
    "                     'WILLMIDCAPGR': 'CLOSE',\n",
    "                     'WILLMIDCAPGRPR': 'CLOSE',\n",
    "                     'WILLMIDCAPPR': 'CLOSE',\n",
    "                     'WILLMIDCAPVAL': 'CLOSE',\n",
    "                     'WILLMIDCAPVALPR': 'CLOSE',\n",
    "                     'WILLREITIND': 'CLOSE',\n",
    "                     'WILLREITPR': 'CLOSE',\n",
    "                     'WILLRESIND': 'CLOSE',\n",
    "                     'WILLRESIPR': 'CLOSE',\n",
    "                     'WILLSMLCAP': 'CLOSE',\n",
    "                     'WILLSMLCAPGR': 'CLOSE',\n",
    "                     'WILLSMLCAPGRPR': 'CLOSE',\n",
    "                     'WILLSMLCAPPR': 'CLOSE',\n",
    "                     'WILLSMLCAPVAL': 'CLOSE',\n",
    "                     'WILLSMLCAPVALPR': 'CLOSE'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_weekly_reverse = {'ANFCI': 'AVERAGE',\n",
    "                     'BUSAPPWNSAUSYY': 'AVERAGE',\n",
    "                     'CBUSAPPWNSAUSYY': 'AVERAGE',\n",
    "                     'FF': 'AVERAGE',\n",
    "                     'GASALLCOVW': 'AVERAGE',\n",
    "                     'GASALLREFW': 'AVERAGE',\n",
    "                     'GASALLW': 'AVERAGE',\n",
    "                     'GASDESLSW': 'AVERAGE',\n",
    "                     'GASDESW': 'AVERAGE',\n",
    "                     'GASMIDCOVW': 'AVERAGE',\n",
    "                     'GASMIDREFW': 'AVERAGE',\n",
    "                     'GASMIDW': 'AVERAGE',\n",
    "                     'GASPRMCOVW': 'AVERAGE',\n",
    "                     'GASPRMREFW': 'AVERAGE',\n",
    "                     'GASPRMW': 'AVERAGE',\n",
    "                     'GASREGCOVW': 'AVERAGE',\n",
    "                     'GASREGREFW': 'AVERAGE',\n",
    "                     'GASREGW': 'AVERAGE',\n",
    "                     'HBUSAPPWNSAUSYY': 'AVERAGE',\n",
    "                     'IURSA': 'AVERAGE',\n",
    "                     'LTGS': 'AVERAGE',\n",
    "                     'MORTGAGE30US': 'AVERAGE',\n",
    "                     'MORTGAGE5US': 'AVERAGE',\n",
    "                     'MORTMRGN5US': 'AVERAGE',\n",
    "                     'MORTPTS15US': 'AVERAGE',\n",
    "                     'MORTPTS30US': 'AVERAGE',\n",
    "                     'MORTPTS5US': 'AVERAGE',\n",
    "                     'NFCI': 'AVERAGE',\n",
    "                     'NFCICREDIT': 'AVERAGE',\n",
    "                     'NFCILEVERAGE': 'AVERAGE',\n",
    "                     'NFCINONFINLEVERAGE': 'AVERAGE',\n",
    "                     'NFCIRISK': 'AVERAGE',\n",
    "                     'STLFSI2': 'AVERAGE',\n",
    "                     'WAAA': 'AVERAGE',\n",
    "                     'WBAA': 'AVERAGE',\n",
    "                     'WBUSAPPWNSAUSYY': 'AVERAGE',\n",
    "                     'WCOILBRENTEU': 'AVERAGE',\n",
    "                     'WCOILWTICO': 'AVERAGE',\n",
    "                     'WCPF1M': 'AVERAGE',\n",
    "                     'WCPF2M': 'AVERAGE',\n",
    "                     'WCPF3M': 'AVERAGE',\n",
    "                     'WCPN1M': 'AVERAGE',\n",
    "                     'WCPN2M': 'AVERAGE',\n",
    "                     'WCPN3M': 'AVERAGE',\n",
    "                     'WDFUELLA': 'AVERAGE',\n",
    "                     'WDFUELNYH': 'AVERAGE',\n",
    "                     'WDFUELUSGULF': 'AVERAGE',\n",
    "                     'WEI': 'AVERAGE',\n",
    "                     'WFII10': 'AVERAGE',\n",
    "                     'WFII20': 'AVERAGE',\n",
    "                     'WFII30': 'AVERAGE',\n",
    "                     'WFII5': 'AVERAGE',\n",
    "                     'WFII7': 'AVERAGE',\n",
    "                     'WGASNYH': 'AVERAGE',\n",
    "                     'WGASUSGULF': 'AVERAGE',\n",
    "                     'WGS10YR': 'AVERAGE',\n",
    "                     'WGS1MO': 'AVERAGE',\n",
    "                     'WGS1YR': 'AVERAGE',\n",
    "                     'WGS20YR': 'AVERAGE',\n",
    "                     'WGS2YR': 'AVERAGE',\n",
    "                     'WGS30YR': 'AVERAGE',\n",
    "                     'WGS3MO': 'AVERAGE',\n",
    "                     'WGS3YR': 'AVERAGE',\n",
    "                     'WGS5YR': 'AVERAGE',\n",
    "                     'WGS6MO': 'AVERAGE',\n",
    "                     'WGS7YR': 'AVERAGE',\n",
    "                     'WHHNGSP': 'AVERAGE',\n",
    "                     'WHOILNYH': 'AVERAGE',\n",
    "                     'WJFUELUSGULF': 'AVERAGE',\n",
    "                     'WLTIIT': 'AVERAGE',\n",
    "                     'WPCREDIT': 'AVERAGE',\n",
    "                     'WPRIME': 'AVERAGE',\n",
    "                     'WPROPANEMBTX': 'AVERAGE',\n",
    "                     'WRGASLA': 'AVERAGE',\n",
    "                     'WTB1YR': 'AVERAGE',\n",
    "                     'WTB3MS': 'AVERAGE',\n",
    "                     'WTB4WK': 'AVERAGE',\n",
    "                     'WTB6MS': 'AVERAGE',\n",
    "                     'ABCOMP': 'SUM',\n",
    "                     'ALLACBW027SBOG': 'SUM',\n",
    "                     'ALLDCBW027SBOG': 'SUM',\n",
    "                     'ALLFRIW027SBOG': 'SUM',\n",
    "                     'ALLLCBW027SBOG': 'SUM',\n",
    "                     'ALLSCBW027SBOG': 'SUM',\n",
    "                     'AOCACBW027SBOG': 'SUM',\n",
    "                     'AOCDCBW027SBOG': 'SUM',\n",
    "                     'AOCFRIW027SBOG': 'SUM',\n",
    "                     'AOCLCBW027SBOG': 'SUM',\n",
    "                     'AOCSCBW027SBOG': 'SUM',\n",
    "                     'AOLACBW027SBOG': 'SUM',\n",
    "                     'AOLDCBW027SBOG': 'SUM',\n",
    "                     'AOLFRIW027SBOG': 'SUM',\n",
    "                     'AOLLCBW027SBOG': 'SUM',\n",
    "                     'AOLSCBW027SBOG': 'SUM',\n",
    "                     'BC0DCBW027SBOG': 'SUM',\n",
    "                     'BC0FRIW027SBOG': 'SUM',\n",
    "                     'BC0LCBW027SBOG': 'SUM',\n",
    "                     'BC0SCBW027SBOG': 'SUM',\n",
    "                     'BUSAPPWNSAUS': 'SUM',\n",
    "                     'CACP': 'SUM',\n",
    "                     'CAOCARC': 'SUM',\n",
    "                     'CARACBW027SBOG': 'SUM',\n",
    "                     'CARDCBW027SBOG': 'SUM',\n",
    "                     'CARFRIW027SBOG': 'SUM',\n",
    "                     'CARLCBW027SBOG': 'SUM',\n",
    "                     'CARSCBW027SBOG': 'SUM',\n",
    "                     'CASACBW027SBOG': 'SUM',\n",
    "                     'CASDCBW027SBOG': 'SUM',\n",
    "                     'CASFRIW027SBOG': 'SUM',\n",
    "                     'CASLCBW027SBOG': 'SUM',\n",
    "                     'CASS7': 'SUM',\n",
    "                     'CASSCBW027SBOG': 'SUM',\n",
    "                     'CASSNS': 'SUM',\n",
    "                     'CASTOTS': 'SUM',\n",
    "                     'CATOTCA': 'SUM',\n",
    "                     'CBUSAPPWNSAUS': 'SUM',\n",
    "                     'CC4WSA': 'SUM',\n",
    "                     'CCLACBW027SBOG': 'SUM',\n",
    "                     'CCLDCBW027SBOG': 'SUM',\n",
    "                     'CCLFRIW027SBOG': 'SUM',\n",
    "                     'CCLLCBW027SBOG': 'SUM',\n",
    "                     'CCLSCBW027SBOG': 'SUM',\n",
    "                     'CCSA': 'SUM',\n",
    "                     'CIBOARDNSA': 'SUM',\n",
    "                     'CILDCBW027SBOG': 'SUM',\n",
    "                     'CILFRIW027SBOG': 'SUM',\n",
    "                     'CILSCBW027SBOG': 'SUM',\n",
    "                     'CLDACBW027SBOG': 'SUM',\n",
    "                     'CLDDCBW027SBOG': 'SUM',\n",
    "                     'CLDFRIW027SBOG': 'SUM',\n",
    "                     'CLDLCBW027SBOG': 'SUM',\n",
    "                     'CLDSCBW027SBOG': 'SUM',\n",
    "                     'CLSACBW027SBOG': 'SUM',\n",
    "                     'CLSDCBW027SBOG': 'SUM',\n",
    "                     'CLSFRIW027SBOG': 'SUM',\n",
    "                     'CLSLCBW027SBOG': 'SUM',\n",
    "                     'CLSSCBW027SBOG': 'SUM',\n",
    "                     'COMPAPER': 'SUM',\n",
    "                     'COMPOUT': 'SUM',\n",
    "                     'COVEMP': 'SUM',\n",
    "                     'CREACBW027SBOG': 'SUM',\n",
    "                     'CREDCBW027SBOG': 'SUM',\n",
    "                     'CREFRIW027SBOG': 'SUM',\n",
    "                     'CRELCBW027SBOG': 'SUM',\n",
    "                     'CRESCBW027SBOG': 'SUM',\n",
    "                     'CRLACBW027SBOG': 'SUM',\n",
    "                     'CRLDCBW027SBOG': 'SUM',\n",
    "                     'CRLFRIW027SBOG': 'SUM',\n",
    "                     'CRLLCBW027SBOG': 'SUM',\n",
    "                     'CRLSCBW027SBOG': 'SUM',\n",
    "                     'DFINCP': 'SUM',\n",
    "                     'DNFINCP': 'SUM',\n",
    "                     'DPSACBW027SBOG': 'SUM',\n",
    "                     'DPSDCBW027SBOG': 'SUM',\n",
    "                     'DPSFRIW027SBOG': 'SUM',\n",
    "                     'DPSLCBW027SBOG': 'SUM',\n",
    "                     'DPSSCBW027SBOG': 'SUM',\n",
    "                     'DTBSPCKANYRENDWW': 'SUM',\n",
    "                     'DTBSPCKCT1NWW': 'SUM',\n",
    "                     'DTBSPCKCT1NYRENDWW': 'SUM',\n",
    "                     'DTBSPCKCT2NWW': 'SUM',\n",
    "                     'DTBSPCKCT2NYRENDWW': 'SUM',\n",
    "                     'DTBSPCKFDBNWW': 'SUM',\n",
    "                     'DTBSPCKFDNNWW': 'SUM',\n",
    "                     'DTBSPCKFDONWW': 'SUM',\n",
    "                     'DTBSPCKFDUNWW': 'SUM',\n",
    "                     'DTBSPCKFFBNWW': 'SUM',\n",
    "                     'DTBSPCKFFONWW': 'SUM',\n",
    "                     'DTBSPCKFOWW': 'SUM',\n",
    "                     'DTBSPCKNOWW': 'SUM',\n",
    "                     'DTBSPCKNYRENDWW': 'SUM',\n",
    "                     'DTBSPCKPLANWW': 'SUM',\n",
    "                     'DTBSPCKPLFNWW': 'SUM',\n",
    "                     'DTBSPCKPLNNWW': 'SUM',\n",
    "                     'DTBSPCKPLONWW': 'SUM',\n",
    "                     'DTBSPCKPTANWW': 'SUM',\n",
    "                     'DTBSPCKPTFNWW': 'SUM',\n",
    "                     'DTBSPCKPTNNWW': 'SUM',\n",
    "                     'DTBSPCKPTONWW': 'SUM',\n",
    "                     'FEDD10Y': 'SUM',\n",
    "                     'FEDD15': 'SUM',\n",
    "                     'FEDD1690': 'SUM',\n",
    "                     'FEDD1T5': 'SUM',\n",
    "                     'FEDD5T10': 'SUM',\n",
    "                     'FEDD911Y': 'SUM',\n",
    "                     'FEDDT': 'SUM',\n",
    "                     'FFINCP': 'SUM',\n",
    "                     'FINCP': 'SUM',\n",
    "                     'FNFINCP': 'SUM',\n",
    "                     'H41RESH4ENWW': 'SUM',\n",
    "                     'H41RESH4EXAWNWW': 'SUM',\n",
    "                     'H41RESH4EXAWXCH1NWW': 'SUM',\n",
    "                     'H41RESH4EXAWXCH52NWW': 'SUM',\n",
    "                     'H41RESH4EXCH1NWW': 'SUM',\n",
    "                     'H41RESH4EXCH52NWW': 'SUM',\n",
    "                     'H41RESPPAABHANWW': 'SUM',\n",
    "                     'H41RESPPAABHCNWW': 'SUM',\n",
    "                     'H41RESPPAABNWW': 'SUM',\n",
    "                     'H41RESPPAABXAWNWW': 'SUM',\n",
    "                     'H41RESPPAABXAWXCH1NWW': 'SUM',\n",
    "                     'H41RESPPAABXAWXCH52NWW': 'SUM',\n",
    "                     'H41RESPPAABXCH1NWW': 'SUM',\n",
    "                     'H41RESPPAABXCH52NWW': 'SUM',\n",
    "                     'H41RESPPAAC2HANWW': 'SUM',\n",
    "                     'H41RESPPAAC2HCNWW': 'SUM',\n",
    "                     'H41RESPPAAC2HNWW': 'SUM',\n",
    "                     'H41RESPPAAC2HXAWNWW': 'SUM',\n",
    "                     'H41RESPPAAC2HXAWXCH1NWW': 'SUM',\n",
    "                     'H41RESPPAAC2HXAWXCH52NWW': 'SUM',\n",
    "                     'H41RESPPAAC2HXCH1NWW': 'SUM',\n",
    "                     'H41RESPPAAC2HXCH52NWW': 'SUM',\n",
    "                     'H41RESPPAAC2MBD15NWW': 'SUM',\n",
    "                     'H41RESPPAAC2MBD16T90NWW': 'SUM',\n",
    "                     'H41RESPPAAC2MBNWW': 'SUM',\n",
    "                     'H41RESPPAAC2MBY01NWW': 'SUM',\n",
    "                     'H41RESPPAADHANWW': 'SUM',\n",
    "                     'H41RESPPAADHCNWW': 'SUM',\n",
    "                     'H41RESPPAADHNWW': 'SUM',\n",
    "                     'H41RESPPAADHUD15NWW': 'SUM',\n",
    "                     'H41RESPPAADHUD16T90NWW': 'SUM',\n",
    "                     'H41RESPPAADHUNWW': 'SUM',\n",
    "                     'H41RESPPAADHUY01NWW': 'SUM',\n",
    "                     'H41RESPPAADHUY01T05NWW': 'SUM',\n",
    "                     'H41RESPPAADHXAWNWW': 'SUM',\n",
    "                     'H41RESPPAADHXAWXCH1NWW': 'SUM',\n",
    "                     'H41RESPPAADHXAWXCH52NWW': 'SUM',\n",
    "                     'H41RESPPAADHXCH1NWW': 'SUM',\n",
    "                     'H41RESPPAADHXCH52NWW': 'SUM',\n",
    "                     'H41RESPPAAEHANWW': 'SUM',\n",
    "                     'H41RESPPAAEHCNWW': 'SUM',\n",
    "                     'H41RESPPAAELD15NWW': 'SUM',\n",
    "                     'H41RESPPAAELD16T90NWW': 'SUM',\n",
    "                     'H41RESPPAAELNWW': 'SUM',\n",
    "                     'H41RESPPAAELY01NWW': 'SUM',\n",
    "                     'H41RESPPAAELY01T05NWW': 'SUM',\n",
    "                     'H41RESPPAAENWW': 'SUM',\n",
    "                     'H41RESPPAAEXAWNWW': 'SUM',\n",
    "                     'H41RESPPAAEXAWXCH1NWW': 'SUM',\n",
    "                     'H41RESPPAAEXAWXCH52NWW': 'SUM',\n",
    "                     'H41RESPPAAEXCH1NWW': 'SUM',\n",
    "                     'H41RESPPAAEXCH52NWW': 'SUM',\n",
    "                     'H41RESPPAATAL2HANWW': 'SUM',\n",
    "                     'H41RESPPAATAL2HCNWW': 'SUM',\n",
    "                     'H41RESPPAATAL2HNWW': 'SUM',\n",
    "                     'H41RESPPAATAL2HXAWNWW': 'SUM',\n",
    "                     'H41RESPPAATAL2HXAWXCH1NWW': 'SUM',\n",
    "                     'H41RESPPAATAL2HXCH1NWW': 'SUM',\n",
    "                     'H41RESPPAATAL2HXCH52NWW': 'SUM',\n",
    "                     'H41RESPPAATAL2LD15NWW': 'SUM',\n",
    "                     'H41RESPPAATAL2LD16T90NWW': 'SUM',\n",
    "                     'H41RESPPAATAL2LNWW': 'SUM',\n",
    "                     'H41RESPPAATAL2LY01NWW': 'SUM',\n",
    "                     'H41RESPPAATAL2LY01T05NWW': 'SUM',\n",
    "                     'H41RESPPAENWW': 'SUM',\n",
    "                     'H41RESPPALDBNWW': 'SUM',\n",
    "                     'H41RESPPALDBXAWNWW': 'SUM',\n",
    "                     'H41RESPPALDBXAWXCH1NWW': 'SUM',\n",
    "                     'H41RESPPALDBXAWXCH52NWW': 'SUM',\n",
    "                     'H41RESPPALDHNWW': 'SUM',\n",
    "                     'H41RESPPALDHXAWNWW': 'SUM',\n",
    "                     'H41RESPPALDHXAWXCH1NWW': 'SUM',\n",
    "                     'H41RESPPALDHXAWXCH52NWW': 'SUM',\n",
    "                     'H41RESPPALDJNWW': 'SUM',\n",
    "                     'H41RESPPALDJXAWNWW': 'SUM',\n",
    "                     'H41RESPPALDJXAWXCH1NWW': 'SUM',\n",
    "                     'H41RESPPALDJXAWXCH52NWW': 'SUM',\n",
    "                     'H41RESPPALDOBNWW': 'SUM',\n",
    "                     'H41RESPPALDOC2NWW': 'SUM',\n",
    "                     'H41RESPPALDODNWW': 'SUM',\n",
    "                     'H41RESPPALDOENWW': 'SUM',\n",
    "                     'H41RESPPALDOTAL2NWW': 'SUM',\n",
    "                     'H41RESPPALGASMRNWW': 'SUM',\n",
    "                     'H41RESPPALGASMSNWW': 'SUM',\n",
    "                     'H41RESPPALGTRFNWW': 'SUM',\n",
    "                     'H41RESPPALGTRFXAWNWW': 'SUM',\n",
    "                     'H41RESPPALGTRFXAWXCH1NWW': 'SUM',\n",
    "                     'H41RESPPALGTRFXAWXCH52NWW': 'SUM',\n",
    "                     'H41RESPPALGTRONWW': 'SUM',\n",
    "                     'H41RESPPALGTROXAWNWW': 'SUM',\n",
    "                     'H41RESPPALGTROXAWXCH1NWW': 'SUM',\n",
    "                     'H41RESPPALGTROXAWXCH52NWW': 'SUM',\n",
    "                     'H41RESPPARNWW': 'SUM',\n",
    "                     'H41RESPPLLDENWW': 'SUM',\n",
    "                     'H41RESPPLLENWW': 'SUM',\n",
    "                     'H8B3053NCBA': 'SUM',\n",
    "                     'H8B3053NDMA': 'SUM',\n",
    "                     'H8B3053NFRA': 'SUM',\n",
    "                     'H8B3053NLGA': 'SUM',\n",
    "                     'H8B3053NSMA': 'SUM',\n",
    "                     'H8B3092NCBA': 'SUM',\n",
    "                     'H8B3092NDMA': 'SUM',\n",
    "                     'H8B3092NFRA': 'SUM',\n",
    "                     'H8B3092NLGA': 'SUM',\n",
    "                     'H8B3092NSMA': 'SUM',\n",
    "                     'H8B3094NCBA': 'SUM',\n",
    "                     'H8B3094NDMA': 'SUM',\n",
    "                     'H8B3094NFRA': 'SUM',\n",
    "                     'H8B3094NLGA': 'SUM',\n",
    "                     'H8B3094NSMA': 'SUM',\n",
    "                     'H8B3095NCBA': 'SUM',\n",
    "                     'H8B3095NDMA': 'SUM',\n",
    "                     'H8B3095NFRA': 'SUM',\n",
    "                     'H8B3095NLGA': 'SUM',\n",
    "                     'H8B3095NSMA': 'SUM',\n",
    "                     'HBUSAPPWNSAUS': 'SUM',\n",
    "                     'HMRESPPMAIXNWW': 'SUM',\n",
    "                     'HMRESPPMAXNWW': 'SUM',\n",
    "                     'HMRESPPMLLCXNWW': 'SUM',\n",
    "                     'HMRESPPMLLDOXNWW': 'SUM',\n",
    "                     'HMRESPPMLLDXNWW': 'SUM',\n",
    "                     'HMRESPPMLLXNWW': 'SUM',\n",
    "                     'IC4WSA': 'SUM',\n",
    "                     'ICSA': 'SUM',\n",
    "                     'LCBACBW027SBOG': 'SUM',\n",
    "                     'LCBDCBW027SBOG': 'SUM',\n",
    "                     'LCBFRIW027SBOG': 'SUM',\n",
    "                     'LCBLCBW027SBOG': 'SUM',\n",
    "                     'LCBSCBW027SBOG': 'SUM',\n",
    "                     'LDDFRB': 'SUM',\n",
    "                     'LDFBFOA': 'SUM',\n",
    "                     'LDGUST': 'SUM',\n",
    "                     'LDMB': 'SUM',\n",
    "                     'LDOD': 'SUM',\n",
    "                     'LDODHDI': 'SUM',\n",
    "                     'LDTDHDI': 'SUM',\n",
    "                     'LDTOTD': 'SUM',\n",
    "                     'LDUSTSA': 'SUM',\n",
    "                     'LLBDCBW027SBOG': 'SUM',\n",
    "                     'LLBFRIW027SBOG': 'SUM',\n",
    "                     'LLBLCBW027SBOG': 'SUM',\n",
    "                     'LLBSCBW027SBOG': 'SUM',\n",
    "                     'LNCFRNC': 'SUM',\n",
    "                     'LNFACBW027SBOG': 'SUM',\n",
    "                     'LNFDCBW027SBOG': 'SUM',\n",
    "                     'LNFFRIW027SBOG': 'SUM',\n",
    "                     'LNFLCBW027SBOG': 'SUM',\n",
    "                     'LNFSCBW027SBOG': 'SUM',\n",
    "                     'LOLAOL': 'SUM',\n",
    "                     'LOLDOFRB': 'SUM',\n",
    "                     'LOLRPA': 'SUM',\n",
    "                     'LTDACBW027SBOG': 'SUM',\n",
    "                     'LTDDCBW027SBOG': 'SUM',\n",
    "                     'LTDFRIW027SBOG': 'SUM',\n",
    "                     'LTDLCBW027SBOG': 'SUM',\n",
    "                     'LTDSCBW027SBOG': 'SUM',\n",
    "                     'LTOTL': 'SUM',\n",
    "                     'MBS10Y': 'SUM',\n",
    "                     'MBS15': 'SUM',\n",
    "                     'MBS1690': 'SUM',\n",
    "                     'MBS1T5': 'SUM',\n",
    "                     'MBS5T10': 'SUM',\n",
    "                     'MBS911Y': 'SUM',\n",
    "                     'MCONLIAPFC': 'SUM',\n",
    "                     'MDLNWM': 'SUM',\n",
    "                     'MRAGGCTGGCLIB': 'SUM',\n",
    "                     'NDFACBW027SBOG': 'SUM',\n",
    "                     'NDFDCBW027SBOG': 'SUM',\n",
    "                     'NDFFRIW027SBOG': 'SUM',\n",
    "                     'NDFLCBW027SBOG': 'SUM',\n",
    "                     'NDFSCBW027SBOG': 'SUM',\n",
    "                     'NFINCP': 'SUM',\n",
    "                     'NUGACBW027SBOG': 'SUM',\n",
    "                     'NUGDCBW027SBOG': 'SUM',\n",
    "                     'NUGFRIW027SBOG': 'SUM',\n",
    "                     'NUGLCBW027SBOG': 'SUM',\n",
    "                     'NUGSCBW027SBOG': 'SUM',\n",
    "                     'OCLACBW027SBOG': 'SUM',\n",
    "                     'OCLDCBW027SBOG': 'SUM',\n",
    "                     'OCLFRIW027SBOG': 'SUM',\n",
    "                     'OCLLCBW027SBOG': 'SUM',\n",
    "                     'OCLSCBW027SBOG': 'SUM',\n",
    "                     'ODSACBW027SBOG': 'SUM',\n",
    "                     'ODSDCBW027SBOG': 'SUM',\n",
    "                     'ODSFRIW027SBOG': 'SUM',\n",
    "                     'ODSLCBW027SBOG': 'SUM',\n",
    "                     'ODSSCBW027SBOG': 'SUM',\n",
    "                     'OLNACBW027SBOG': 'SUM',\n",
    "                     'OLNDCBW027SBOG': 'SUM',\n",
    "                     'OLNFRIW027SBOG': 'SUM',\n",
    "                     'OLNLCBW027SBOG': 'SUM',\n",
    "                     'OLNSCBW027SBOG': 'SUM',\n",
    "                     'OMBACBW027SBOG': 'SUM',\n",
    "                     'OMBDCBW027SBOG': 'SUM',\n",
    "                     'OMBFRIW027SBOG': 'SUM',\n",
    "                     'OMBLCBW027SBOG': 'SUM',\n",
    "                     'OMBSCBW027SBOG': 'SUM',\n",
    "                     'ONMACBW027SBOG': 'SUM',\n",
    "                     'ONMDCBW027SBOG': 'SUM',\n",
    "                     'ONMFRIW027SBOG': 'SUM',\n",
    "                     'ONMLCBW027SBOG': 'SUM',\n",
    "                     'ONMSCBW027SBOG': 'SUM',\n",
    "                     'OSEACBW027SBOG': 'SUM',\n",
    "                     'OSEDCBW027SBOG': 'SUM',\n",
    "                     'OSEFRIW027SBOG': 'SUM',\n",
    "                     'OSELCBW027SBOG': 'SUM',\n",
    "                     'OSESCBW027SBOG': 'SUM',\n",
    "                     'OTHCOMPN': 'SUM',\n",
    "                     'OTHL15': 'SUM',\n",
    "                     'OTHL1690': 'SUM',\n",
    "                     'OTHL1T5': 'SUM',\n",
    "                     'OTHL5T10': 'SUM',\n",
    "                     'OTHL91T1Y': 'SUM',\n",
    "                     'RAAAAPABO': 'SUM',\n",
    "                     'RAAHURA': 'SUM',\n",
    "                     'RAATA': 'SUM',\n",
    "                     'RABDSGWOL': 'SUM',\n",
    "                     'RABDTBD': 'SUM',\n",
    "                     'RABP': 'SUM',\n",
    "                     'RACBLS': 'SUM',\n",
    "                     'RADFFB': 'SUM',\n",
    "                     'RADFOFRB': 'SUM',\n",
    "                     'RADRCA': 'SUM',\n",
    "                     'RAFAOBO': 'SUM',\n",
    "                     'RAFAOHURA': 'SUM',\n",
    "                     'RAFAONS': 'SUM',\n",
    "                     'RAFAOTFAO': 'SUM',\n",
    "                     'RAFCDA': 'SUM',\n",
    "                     'RAGGCGCA': 'SUM',\n",
    "                     'RAGGCGRF': 'SUM',\n",
    "                     'RAGGCTGGC': 'SUM',\n",
    "                     'RAGSHURA': 'SUM',\n",
    "                     'RAGSONBI': 'SUM',\n",
    "                     'RAGSONBN': 'SUM',\n",
    "                     'RAGSOTBO': 'SUM',\n",
    "                     'RAGSOUSB': 'SUM',\n",
    "                     'RAGSOUSCIDO': 'SUM',\n",
    "                     'RAGSOUSTB': 'SUM',\n",
    "                     'RAGSOUSTN': 'SUM',\n",
    "                     'RAGSOUSTSIC': 'SUM',\n",
    "                     'RAGSTUSTS': 'SUM',\n",
    "                     'RAIAIL': 'SUM',\n",
    "                     'RAIPGRNPCPFF': 'SUM',\n",
    "                     'RAIPGRNPML1': 'SUM',\n",
    "                     'RAIPGRNPML2': 'SUM',\n",
    "                     'RAIPGRNPML3': 'SUM',\n",
    "                     'RAIPGRNPTALF': 'SUM',\n",
    "                     'RAIPGRPH': 'SUM',\n",
    "                     'RALACBW027SBOG': 'SUM',\n",
    "                     'RALDCBW027SBOG': 'SUM',\n",
    "                     'RALFRIW027SBOG': 'SUM',\n",
    "                     'RALLCBW027SBOG': 'SUM',\n",
    "                     'RALSCBW027SBOG': 'SUM',\n",
    "                     'RALTSCCRO': 'SUM',\n",
    "                     'RAMBS': 'SUM',\n",
    "                     'RAOE': 'SUM',\n",
    "                     'RAOR': 'SUM',\n",
    "                     'RATAC': 'SUM',\n",
    "                     'RATEATIESTBS': 'SUM',\n",
    "                     'RATPRA': 'SUM',\n",
    "                     'RATR': 'SUM',\n",
    "                     'RATSHO': 'SUM',\n",
    "                     'RAUDSHO': 'SUM',\n",
    "                     'RAUICIP': 'SUM',\n",
    "                     'RAUPSHO': 'SUM',\n",
    "                     'RELACBW027SBOG': 'SUM',\n",
    "                     'RELDCBW027SBOG': 'SUM',\n",
    "                     'RELFRIW027SBOG': 'SUM',\n",
    "                     'RELLCBW027SBOG': 'SUM',\n",
    "                     'RELSCBW027SBOG': 'SUM',\n",
    "                     'REP15': 'SUM',\n",
    "                     'REP1690': 'SUM',\n",
    "                     'RESH4AOXAWXCH1NWW': 'SUM',\n",
    "                     'RESH4AOXAWXCH52NWW': 'SUM',\n",
    "                     'RESH4AXAWXCH1NWW': 'SUM',\n",
    "                     'RESH4AXAWXCH52NWW': 'SUM',\n",
    "                     'RESH4DOFXAWXCH1NWW': 'SUM',\n",
    "                     'RESH4DOFXAWXCH52NWW': 'SUM',\n",
    "                     'RESH4DOTXAWXCH1NWW': 'SUM',\n",
    "                     'RESH4DOTXAWXCH52NWW': 'SUM',\n",
    "                     'RESH4DOXAWXCH1NWW': 'SUM',\n",
    "                     'RESH4DOXAWXCH52NWW': 'SUM',\n",
    "                     'RESH4DXAWXCH1NWW': 'SUM',\n",
    "                     'RESH4DXAWXCH52NWW': 'SUM',\n",
    "                     'RESH4FAXAWXCH1NWW': 'SUM',\n",
    "                     'RESH4FAXAWXCH52NWW': 'SUM',\n",
    "                     'RESH4FGXAWXCH1NWW': 'SUM',\n",
    "                     'RESH4FGXAWXCH52NWW': 'SUM',\n",
    "                     'RESH4FOXAWXCH1NWW': 'SUM',\n",
    "                     'RESH4FOXAWXCH52NWW': 'SUM',\n",
    "                     'RESH4FXAWXCH1NWW': 'SUM',\n",
    "                     'RESH4FXAWXCH52NWW': 'SUM',\n",
    "                     'RESH4MFNWW': 'SUM',\n",
    "                     'RESH4RXAWXCH1NWW': 'SUM',\n",
    "                     'RESH4RXAWXCH52NWW': 'SUM',\n",
    "                     'RESH4SCFXAWXCH1NWW': 'SUM',\n",
    "                     'RESH4SCFXAWXCH52NWW': 'SUM',\n",
    "                     'RESH4SCSXAWXCH1NWW': 'SUM',\n",
    "                     'RESH4SCSXAWXCH52NWW': 'SUM',\n",
    "                     'RESH4SCSXCH1NWW': 'SUM',\n",
    "                     'RESH4SCSXCH52NWW': 'SUM',\n",
    "                     'RESH4SCXAWXCH1NWW': 'SUM',\n",
    "                     'RESH4SCXAWXCH52NWW': 'SUM',\n",
    "                     'RESH4SOXAWXCH1NWW': 'SUM',\n",
    "                     'RESH4SOXAWXCH52NWW': 'SUM',\n",
    "                     'RESH4SXAWXCH1NWW': 'SUM',\n",
    "                     'RESH4SXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPAAML1LINWW': 'SUM',\n",
    "                     'RESPPAAML1LPNWW': 'SUM',\n",
    "                     'RESPPAAML2LINWW': 'SUM',\n",
    "                     'RESPPAAML2LPNWW': 'SUM',\n",
    "                     'RESPPAAML3LINWW': 'SUM',\n",
    "                     'RESPPAAML3LPNWW': 'SUM',\n",
    "                     'RESPPAATAL2HXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPACXCH1NWW': 'SUM',\n",
    "                     'RESPPACXCH52NWW': 'SUM',\n",
    "                     'RESPPAGXCH1NWW': 'SUM',\n",
    "                     'RESPPAGXCH52NWW': 'SUM',\n",
    "                     'RESPPAINWW': 'SUM',\n",
    "                     'RESPPALDCXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPALDCXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPALDPXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPALDPXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPALDQXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPALDQXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPALDSXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPALDSXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPALDTXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPALDTXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPALDVNWW': 'SUM',\n",
    "                     'RESPPALDXAWNWW': 'SUM',\n",
    "                     'RESPPALDXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPALDXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPALDXCH1NWW': 'SUM',\n",
    "                     'RESPPALDXCH52NWW': 'SUM',\n",
    "                     'RESPPALGAMD15XCH1NWW': 'SUM',\n",
    "                     'RESPPALGAMD16T90XCH1NWW': 'SUM',\n",
    "                     'RESPPALGAMXCH1NWW': 'SUM',\n",
    "                     'RESPPALGAMY01T05XCH1NWW': 'SUM',\n",
    "                     'RESPPALGAMY01XCH1NWW': 'SUM',\n",
    "                     'RESPPALGAMY05T10XCH1NWW': 'SUM',\n",
    "                     'RESPPALGAMY10PXCH1NWW': 'SUM',\n",
    "                     'RESPPALGAOXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPALGAOXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPALGAOXCH1NWW': 'SUM',\n",
    "                     'RESPPALGAOXCH52NWW': 'SUM',\n",
    "                     'RESPPALGASMCBNWW': 'SUM',\n",
    "                     'RESPPALGASMCSNWW': 'SUM',\n",
    "                     'RESPPALGASMENWW': 'SUM',\n",
    "                     'RESPPALGASMOD15XCH1NWW': 'SUM',\n",
    "                     'RESPPALGASMOD16T90XCH1NWW': 'SUM',\n",
    "                     'RESPPALGASMOXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPALGASMOXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPALGASMOXCH1NWW': 'SUM',\n",
    "                     'RESPPALGASMOXCH52NWW': 'SUM',\n",
    "                     'RESPPALGASMOY01T05XCH1NWW': 'SUM',\n",
    "                     'RESPPALGASMOY01XCH1NWW': 'SUM',\n",
    "                     'RESPPALGASMOY05T10XCH1NWW': 'SUM',\n",
    "                     'RESPPALGASMOY10PXCH1NWW': 'SUM',\n",
    "                     'RESPPALGTRXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPALGTRXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPALGTRXCH1NWW': 'SUM',\n",
    "                     'RESPPALGTRXCH52NWW': 'SUM',\n",
    "                     'RESPPALGUMD15XCH1NWW': 'SUM',\n",
    "                     'RESPPALGUMD16T90XCH1NWW': 'SUM',\n",
    "                     'RESPPALGUMXCH1NWW': 'SUM',\n",
    "                     'RESPPALGUMY01T05XCH1NWW': 'SUM',\n",
    "                     'RESPPALGUMY01XCH1NWW': 'SUM',\n",
    "                     'RESPPALGUMY05T10XCH1NWW': 'SUM',\n",
    "                     'RESPPALGUMY10PXCH1NWW': 'SUM',\n",
    "                     'RESPPALGUOBXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPALGUOBXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPALGUOBXCH1NWW': 'SUM',\n",
    "                     'RESPPALGUOBXCH52NWW': 'SUM',\n",
    "                     'RESPPALGUOMCXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPALGUOMCXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPALGUOMCXCH1NWW': 'SUM',\n",
    "                     'RESPPALGUOMCXCH52NWW': 'SUM',\n",
    "                     'RESPPALGUOMIXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPALGUOMIXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPALGUOMIXCH1NWW': 'SUM',\n",
    "                     'RESPPALGUOMIXCH52NWW': 'SUM',\n",
    "                     'RESPPALGUOMNXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPALGUOMNXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPALGUOMNXCH1NWW': 'SUM',\n",
    "                     'RESPPALGUOMNXCH52NWW': 'SUM',\n",
    "                     'RESPPALGUONNWW': 'SUM',\n",
    "                     'RESPPALGUOXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPALGUOXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPALGUOXCH1NWW': 'SUM',\n",
    "                     'RESPPALGUOXCH52NWW': 'SUM',\n",
    "                     'RESPPALGXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPALGXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPALGXCH1NWW': 'SUM',\n",
    "                     'RESPPALGXCH52NWW': 'SUM',\n",
    "                     'RESPPALSDXAWNWW': 'SUM',\n",
    "                     'RESPPALSDXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPALSDXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPALSDXCH1NWW': 'SUM',\n",
    "                     'RESPPALSDXCH52NWW': 'SUM',\n",
    "                     'RESPPALSPXAWNWW': 'SUM',\n",
    "                     'RESPPALSPXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPALSPXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPALSPXCH1NWW': 'SUM',\n",
    "                     'RESPPALSPXCH52NWW': 'SUM',\n",
    "                     'RESPPALXCH1NWW': 'SUM',\n",
    "                     'RESPPALXCH52NWW': 'SUM',\n",
    "                     'RESPPANNWW': 'SUM',\n",
    "                     'RESPPANWW': 'SUM',\n",
    "                     'RESPPAOFXAWNWW': 'SUM',\n",
    "                     'RESPPAOFXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPAOFXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPAOFXCH1NWW': 'SUM',\n",
    "                     'RESPPAOFXCH52NWW': 'SUM',\n",
    "                     'RESPPAOXCH1NWW': 'SUM',\n",
    "                     'RESPPAOXCH52NWW': 'SUM',\n",
    "                     'RESPPAPXCH1NWW': 'SUM',\n",
    "                     'RESPPAPXCH52NWW': 'SUM',\n",
    "                     'RESPPASXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPASXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPASXCH1NWW': 'SUM',\n",
    "                     'RESPPASXCH52NWW': 'SUM',\n",
    "                     'RESPPLAML1LTNWW': 'SUM',\n",
    "                     'RESPPLAML2LTNWW': 'SUM',\n",
    "                     'RESPPLAML3LTNWW': 'SUM',\n",
    "                     'RESPPLCPXCH1NWW': 'SUM',\n",
    "                     'RESPPLCPXCH52NWW': 'SUM',\n",
    "                     'RESPPLCSXCH1NWW': 'SUM',\n",
    "                     'RESPPLCSXCH52NWW': 'SUM',\n",
    "                     'RESPPLCUXCH1NWW': 'SUM',\n",
    "                     'RESPPLCUXCH52NWW': 'SUM',\n",
    "                     'RESPPLCXCH1NWW': 'SUM',\n",
    "                     'RESPPLCXCH52NWW': 'SUM',\n",
    "                     'RESPPLLBXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPLLBXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPLLCNWW': 'SUM',\n",
    "                     'RESPPLLDAXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPLLDAXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPLLDAXCH1NWW': 'SUM',\n",
    "                     'RESPPLLDAXCH52NWW': 'SUM',\n",
    "                     'RESPPLLDDXCH1NWW': 'SUM',\n",
    "                     'RESPPLLDDXCH52NWW': 'SUM',\n",
    "                     'RESPPLLDFXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPLLDFXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPLLDFXCH1NWW': 'SUM',\n",
    "                     'RESPPLLDFXCH52NWW': 'SUM',\n",
    "                     'RESPPLLDNWW': 'SUM',\n",
    "                     'RESPPLLDOXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPLLDOXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPLLDOXCH1NWW': 'SUM',\n",
    "                     'RESPPLLDOXCH52NWW': 'SUM',\n",
    "                     'RESPPLLDTXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPLLDTXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPLLDTXCH1NWW': 'SUM',\n",
    "                     'RESPPLLDTXCH52NWW': 'SUM',\n",
    "                     'RESPPLLNHNWW': 'SUM',\n",
    "                     'RESPPLLNOCNWW': 'SUM',\n",
    "                     'RESPPLLNONNWW': 'SUM',\n",
    "                     'RESPPLLNONWW': 'SUM',\n",
    "                     'RESPPLLNWW': 'SUM',\n",
    "                     'RESPPLLNXCH1NWW': 'SUM',\n",
    "                     'RESPPLLNXCH52NWW': 'SUM',\n",
    "                     'RESPPLLOONWW': 'SUM',\n",
    "                     'RESPPLLOPNWW': 'SUM',\n",
    "                     'RESPPLLOXCH1NWW': 'SUM',\n",
    "                     'RESPPLLOXCH52NWW': 'SUM',\n",
    "                     'RESPPLLRDXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPLLRDXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPLLRFXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPLLRFXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPLLRXAWXCH1NWW': 'SUM',\n",
    "                     'RESPPLLRXAWXCH52NWW': 'SUM',\n",
    "                     'RESPPLLRXCH1NWW': 'SUM',\n",
    "                     'RESPPLLRXCH52NWW': 'SUM',\n",
    "                     'RESPPLNWW': 'SUM',\n",
    "                     'RESPPMAIXCH1NWW': 'SUM',\n",
    "                     'RESPPMAIXCH52NWW': 'SUM',\n",
    "                     'RESPPMAXCH1NWW': 'SUM',\n",
    "                     'RESPPMAXCH52NWW': 'SUM',\n",
    "                     'RESPPMLLCXCH1NWW': 'SUM',\n",
    "                     'RESPPMLLCXCH52NWW': 'SUM',\n",
    "                     'RESPPMLLDONWW': 'SUM',\n",
    "                     'RESPPMLLDXCH1NWW': 'SUM',\n",
    "                     'RESPPMLLDXCH52NWW': 'SUM',\n",
    "                     'RESPPMLLXCH1NWW': 'SUM',\n",
    "                     'RESPPMLLXCH52NWW': 'SUM',\n",
    "                     'RESPPNGNWW': 'SUM',\n",
    "                     'RESPPNNWW': 'SUM',\n",
    "                     'RESPPNONWW': 'SUM',\n",
    "                     'RESPPNSNWW': 'SUM',\n",
    "                     'RESPPNTEPNWW': 'SUM',\n",
    "                     'RESPPNTEPPNWW': 'SUM',\n",
    "                     'RESPPNTNWW': 'SUM',\n",
    "                     'RESTBCXAWXCH1NWW': 'SUM',\n",
    "                     'RESTBCXAWXCH52NWW': 'SUM',\n",
    "                     'RESTBHTXAWXCH1NWW': 'SUM',\n",
    "                     'RESTBHTXAWXCH52NWW': 'SUM',\n",
    "                     'RESTBMGXAWXCH1NWW': 'SUM',\n",
    "                     'RESTBMGXAWXCH52NWW': 'SUM',\n",
    "                     'RESTBMTXAWXCH1NWW': 'SUM',\n",
    "                     'RESTBMTXAWXCH52NWW': 'SUM',\n",
    "                     'RHEACBW027SBOG': 'SUM',\n",
    "                     'RHEDCBW027SBOG': 'SUM',\n",
    "                     'RHEFRIW027SBOG': 'SUM',\n",
    "                     'RHELCBW027SBOG': 'SUM',\n",
    "                     'RHESCBW027SBOG': 'SUM',\n",
    "                     'RREACBW027SBOG': 'SUM',\n",
    "                     'RREDCBW027SBOG': 'SUM',\n",
    "                     'RREFRIW027SBOG': 'SUM',\n",
    "                     'RRELCBW027SBOG': 'SUM',\n",
    "                     'RREP15': 'SUM',\n",
    "                     'RREP1690': 'SUM',\n",
    "                     'RRESCBW027SBOG': 'SUM',\n",
    "                     'SBCACBW027SBOG': 'SUM',\n",
    "                     'SBCDCBW027SBOG': 'SUM',\n",
    "                     'SBCFRIW027SBOG': 'SUM',\n",
    "                     'SBCLCBW027SBOG': 'SUM',\n",
    "                     'SBCSCBW027SBOG': 'SUM',\n",
    "                     'SBFACBW027SBOG': 'SUM',\n",
    "                     'SBFDCBW027SBOG': 'SUM',\n",
    "                     'SBFFRIW027SBOG': 'SUM',\n",
    "                     'SBFLCBW027SBOG': 'SUM',\n",
    "                     'SBFSCBW027SBOG': 'SUM',\n",
    "                     'SMPACBW027SBOG': 'SUM',\n",
    "                     'SMPDCBW027SBOG': 'SUM',\n",
    "                     'SMPFRIW027SBOG': 'SUM',\n",
    "                     'SMPLCBW027SBOG': 'SUM',\n",
    "                     'SMPSCBW027SBOG': 'SUM',\n",
    "                     'SNFACBW027SBOG': 'SUM',\n",
    "                     'SNFDCBW027SBOG': 'SUM',\n",
    "                     'SNFFRIW027SBOG': 'SUM',\n",
    "                     'SNFLCBW027SBOG': 'SUM',\n",
    "                     'SNFSCBW027SBOG': 'SUM',\n",
    "                     'SWP10Y': 'SUM',\n",
    "                     'SWP15': 'SUM',\n",
    "                     'SWP1690': 'SUM',\n",
    "                     'SWP1T5': 'SUM',\n",
    "                     'SWP5T10': 'SUM',\n",
    "                     'SWP911Y': 'SUM',\n",
    "                     'SWPT': 'SUM',\n",
    "                     'TAMACBW027SBOG': 'SUM',\n",
    "                     'TAMDCBW027SBOG': 'SUM',\n",
    "                     'TAMFRIW027SBOG': 'SUM',\n",
    "                     'TAMLCBW027SBOG': 'SUM',\n",
    "                     'TAMSCBW027SBOG': 'SUM',\n",
    "                     'TASACBW027SBOG': 'SUM',\n",
    "                     'TASDCBW027SBOG': 'SUM',\n",
    "                     'TASFRIW027SBOG': 'SUM',\n",
    "                     'TASLCBW027SBOG': 'SUM',\n",
    "                     'TASSCBW027SBOG': 'SUM',\n",
    "                     'TERM15': 'SUM',\n",
    "                     'TERM1690': 'SUM',\n",
    "                     'TERM911Y': 'SUM',\n",
    "                     'TERMT': 'SUM',\n",
    "                     'TLAACBW027SBOG': 'SUM',\n",
    "                     'TLADCBW027SBOG': 'SUM',\n",
    "                     'TLAFRIW027SBOG': 'SUM',\n",
    "                     'TLALCBW027SBOG': 'SUM',\n",
    "                     'TLASCBW027SBOG': 'SUM',\n",
    "                     'TLBACBW027SBOG': 'SUM',\n",
    "                     'TLBDCBW027SBOG': 'SUM',\n",
    "                     'TLBFRIW027SBOG': 'SUM',\n",
    "                     'TLBLCBW027SBOG': 'SUM',\n",
    "                     'TLBSCBW027SBOG': 'SUM',\n",
    "                     'TMBACBW027SBOG': 'SUM',\n",
    "                     'TMBDCBW027SBOG': 'SUM',\n",
    "                     'TMBFRIW027SBOG': 'SUM',\n",
    "                     'TMBLCBW027SBOG': 'SUM',\n",
    "                     'TMBSCBW027SBOG': 'SUM',\n",
    "                     'TNMACBW027SBOG': 'SUM',\n",
    "                     'TNMDCBW027SBOG': 'SUM',\n",
    "                     'TNMFRIW027SBOG': 'SUM',\n",
    "                     'TNMLCBW027SBOG': 'SUM',\n",
    "                     'TNMSCBW027SBOG': 'SUM',\n",
    "                     'TOTBKCR': 'SUM',\n",
    "                     'TOTBORR': 'SUM',\n",
    "                     'TOTCI': 'SUM',\n",
    "                     'TOTLCA': 'SUM',\n",
    "                     'TOTLL': 'SUM',\n",
    "                     'TOTRA': 'SUM',\n",
    "                     'TREAS10Y': 'SUM',\n",
    "                     'TREAS15': 'SUM',\n",
    "                     'TREAS1590': 'SUM',\n",
    "                     'TREAS1T5': 'SUM',\n",
    "                     'TREAS5T10': 'SUM',\n",
    "                     'TREAS911Y': 'SUM',\n",
    "                     'TREAST': 'SUM',\n",
    "                     'WABPL': 'SUM',\n",
    "                     'WACL': 'SUM',\n",
    "                     'WALCL': 'SUM',\n",
    "                     'WALL': 'SUM',\n",
    "                     'WAOAL': 'SUM',\n",
    "                     'WBUSAPPWNSAUS': 'SUM',\n",
    "                     'WCBLSA': 'SUM',\n",
    "                     'WCICL': 'SUM',\n",
    "                     'WCPCA': 'SUM',\n",
    "                     'WCPIL': 'SUM',\n",
    "                     'WCSL': 'SUM',\n",
    "                     'WCTCL': 'SUM',\n",
    "                     'WCURCIR': 'SUM',\n",
    "                     'WCURRNS': 'SUM',\n",
    "                     'WDDNS': 'SUM',\n",
    "                     'WDFOA': 'SUM',\n",
    "                     'WDFOL': 'SUM',\n",
    "                     'WDSFAL': 'SUM',\n",
    "                     'WDTGAL': 'SUM',\n",
    "                     'WFASEC1': 'SUM',\n",
    "                     'WFASECL1': 'SUM',\n",
    "                     'WFCDA': 'SUM',\n",
    "                     'WFEDSEC': 'SUM',\n",
    "                     'WGCAL': 'SUM',\n",
    "                     'WLAD': 'SUM',\n",
    "                     'WLCFLL': 'SUM',\n",
    "                     'WLCFLPCL': 'SUM',\n",
    "                     'WLCFLSCL': 'SUM',\n",
    "                     'WLCFLSECL': 'SUM',\n",
    "                     'WLCFOCEL': 'SUM',\n",
    "                     'WLDACL': 'SUM',\n",
    "                     'WLDACLC': 'SUM',\n",
    "                     'WLDECL': 'SUM',\n",
    "                     'WLDLCL': 'SUM',\n",
    "                     'WLFN': 'SUM',\n",
    "                     'WLOCL': 'SUM',\n",
    "                     'WLODL': 'SUM',\n",
    "                     'WLODLL': 'SUM',\n",
    "                     'WLRRAA': 'SUM',\n",
    "                     'WLRRAFOIAL': 'SUM',\n",
    "                     'WLRRAL': 'SUM',\n",
    "                     'WLRRAOL': 'SUM',\n",
    "                     'WLTDHDIA': 'SUM',\n",
    "                     'WLTEC': 'SUM',\n",
    "                     'WLTLECL': 'SUM',\n",
    "                     'WM1NS': 'SUM',\n",
    "                     'WM2NS': 'SUM',\n",
    "                     'WMBSEC': 'SUM',\n",
    "                     'WMTSEC1': 'SUM',\n",
    "                     'WMTSECL1': 'SUM',\n",
    "                     'WOCE': 'SUM',\n",
    "                     'WOFDRBORBA': 'SUM',\n",
    "                     'WOFDRBORBL': 'SUM',\n",
    "                     'WOFDRBTHA': 'SUM',\n",
    "                     'WOFDRBTHL': 'SUM',\n",
    "                     'WOFRAL': 'SUM',\n",
    "                     'WOFSRBFA': 'SUM',\n",
    "                     'WOFSRBFL': 'SUM',\n",
    "                     'WOFSRBGSA': 'SUM',\n",
    "                     'WOFSRBGSL': 'SUM',\n",
    "                     'WOFSRBRBC': 'SUM',\n",
    "                     'WOLCL': 'SUM',\n",
    "                     'WORAL': 'SUM',\n",
    "                     'WOSDRA': 'SUM',\n",
    "                     'WOSDRL': 'SUM',\n",
    "                     'WOTHAST': 'SUM',\n",
    "                     'WOTHLB': 'SUM',\n",
    "                     'WOTHLIAB': 'SUM',\n",
    "                     'WPC': 'SUM',\n",
    "                     'WPCL': 'SUM',\n",
    "                     'WPCLC': 'SUM',\n",
    "                     'WRBWFRBL': 'SUM',\n",
    "                     'WREPO': 'SUM',\n",
    "                     'WREPODEL': 'SUM',\n",
    "                     'WREPOFOR': 'SUM',\n",
    "                     'WRESBAL': 'SUM',\n",
    "                     'WRESCRT': 'SUM',\n",
    "                     'WRMFNS': 'SUM',\n",
    "                     'WSB': 'SUM',\n",
    "                     'WSC': 'SUM',\n",
    "                     'WSDEAL': 'SUM',\n",
    "                     'WSDEALL': 'SUM',\n",
    "                     'WSDFDSA': 'SUM',\n",
    "                     'WSDFDSL': 'SUM',\n",
    "                     'WSDONT': 'SUM',\n",
    "                     'WSDONTL': 'SUM',\n",
    "                     'WSDTREAA': 'SUM',\n",
    "                     'WSDTREAL': 'SUM',\n",
    "                     'WSECOUT': 'SUM',\n",
    "                     'WSEFINO': 'SUM',\n",
    "                     'WSEFINOL': 'SUM',\n",
    "                     'WSEFINT1': 'SUM',\n",
    "                     'WSEFINTL1': 'SUM',\n",
    "                     'WSHOBA': 'SUM',\n",
    "                     'WSHOBL': 'SUM',\n",
    "                     'WSHOFADSL': 'SUM',\n",
    "                     'WSHOICA': 'SUM',\n",
    "                     'WSHOICL': 'SUM',\n",
    "                     'WSHOMCB': 'SUM',\n",
    "                     'WSHONBIIA': 'SUM',\n",
    "                     'WSHONBIIL': 'SUM',\n",
    "                     'WSHONBNA': 'SUM',\n",
    "                     'WSHONBNL': 'SUM',\n",
    "                     'WSHOSHO': 'SUM',\n",
    "                     'WSHOTSA': 'SUM',\n",
    "                     'WSHOTSL': 'SUM',\n",
    "                     'WSMTMNS': 'SUM',\n",
    "                     'WSRLL': 'SUM',\n",
    "                     'WTCOA': 'SUM',\n",
    "                     'WTCOL': 'SUM',\n",
    "                     'WTFORBAFA': 'SUM',\n",
    "                     'WTFORBAFL': 'SUM',\n",
    "                     'WTFSRFA': 'SUM',\n",
    "                     'WTFSRFL': 'SUM',\n",
    "                     'WTREGEN': 'SUM',\n",
    "                     'WUDSHO': 'SUM',\n",
    "                     'WUPSHO': 'SUM'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vintagiser(ip_release_dates, date):\n",
    "    '''\n",
    "    Cuts the three frequency dataframes to the vintage specified using ip release dates\n",
    "    \n",
    "    Input - a datetime date\n",
    "    \n",
    "    Outputs - Three dataframes for each frequency\n",
    "    '''\n",
    "    # finds closest previous date in IP release dates and then uses the month released \n",
    "    ip_vintage = ip.loc[:ip_release_dates.loc[ip_release_dates.index[ip_release_dates.index.get_loc(date, method = 'pad')]].values[0]]\n",
    "    # get daily vintage\n",
    "    daily_vintage = daily_trim.loc[:date]\n",
    "    # get weekly vintage\n",
    "    weekly_vintage = weekly_trim.loc[:date]    \n",
    "    # tuple assignment so forecasts can be performed pre aggregation\n",
    "    return ip_vintage, daily_vintage, weekly_vintage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregator(df, agg_dict):\n",
    "    '''\n",
    "    Aggregates the daily/weekly dfs to monthly frequency based on the aggregation mappings in the dictionary.\n",
    "    '''\n",
    "    df_list = []\n",
    "    for i in agg_dict.keys():\n",
    "        if i == 'AVERAGE':\n",
    "            df_avg = df[agg_dict[i]]\n",
    "            df_avg = df_avg.groupby(pd.Grouper(freq='M')).mean()\n",
    "            df_list.append(df_avg)\n",
    "        elif i == 'SUM':\n",
    "            df_sum = df[agg_dict[i]]\n",
    "            df_sum = df_sum.groupby(pd.Grouper(freq='M')).sum()\n",
    "            # all leading nan values have been converted to 0, following code locates these and returns them nan\n",
    "            start_points = df_sum.ne(0).idxmax()\n",
    "            for i in df_sum.columns:\n",
    "                df_sum.loc[:start_points[i],i].replace(0, np.nan, inplace=True)\n",
    "            df_list.append(df_sum)\n",
    "        elif i == 'CLOSE':\n",
    "            df_close = df[agg_dict[i]]\n",
    "            df_close = df_close.groupby(pd.Grouper(freq='M')).last()\n",
    "            df_list.append(df_close)\n",
    "    df_agg = pd.concat(df_list, axis =1)\n",
    "    return df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_month(year, month, day):\n",
    "    '''\n",
    "    Increments a datetime.date object by 1 month\n",
    "    '''\n",
    "    d = datetime.date(year, month, day)\n",
    "    month = d.month + 1\n",
    "    if month == 13:\n",
    "        month = 11\n",
    "        year = d.year + 1\n",
    "    return datetime.date(year, month, day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def working_days(year, month, day):\n",
    "    '''\n",
    "    Counts the number of working days within a specific month.\n",
    "    '''\n",
    "    weekend = (5, 6)\n",
    "    count = 0\n",
    "    d = datetime.date(year, month, day)\n",
    "    next_month = increment_month(year, month, day)\n",
    "    while d < next_month:\n",
    "        if d.weekday() not in weekend:\n",
    "            count += 1\n",
    "        d += datetime.timedelta(days = 1)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_working_day(year, month, day):\n",
    "    '''\n",
    "    Locates the last working day in the month. Does not account for holidays.\n",
    "    '''\n",
    "    d = datetime.date(year, month, day)\n",
    "    weekend = (5, 6)\n",
    "    if d.weekday() == 6:\n",
    "        d = datetime.date(year, month, day-2)\n",
    "    elif d.weekday() == 5:\n",
    "        d = datetime.date(year, month, day-1)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregator_avg_daily(df, agg_dict):\n",
    "    '''\n",
    "    Aggregates the daily/weekly dfs to monthly frequency based on the aggregation mappings in the dictionary.\n",
    "    \n",
    "    Average and close methods unchanged. Final month sum series have average extrapolated by the number of \n",
    "    remaining release days.\n",
    "    '''\n",
    "    df_list = []\n",
    "    for i in agg_dict.keys():\n",
    "        if i == 'AVERAGE':\n",
    "            df_avg = df[agg_dict[i]]\n",
    "            df_avg = df_avg.groupby(pd.Grouper(freq='M')).mean()\n",
    "            df_list.append(df_avg)\n",
    "        elif i == 'SUM':\n",
    "            df_sum = df[agg_dict[i]]\n",
    "            df_counts = df_sum.groupby(pd.Grouper(freq='M')).count()\n",
    "            df_sum = df_sum.groupby(pd.Grouper(freq='M')).sum()\n",
    "            # scale up sum variables by the remaining working days in the month\n",
    "            if df.index[-1] < last_working_day(df_sum.index[-1].year, df_sum.index[-1].month, df_sum.index[-1].day):\n",
    "                work_days = working_days(df_sum.index[-1].year, df_sum.index[-1].month,1)\n",
    "                for i in df_sum.columns:\n",
    "                    df_sum.loc[df_sum.index[-1],i] = (work_days/df_counts.loc[df_counts.index[-1],i])*df_sum.loc[df_sum.index[-1],i]\n",
    "            # all leading nan values have been converted to 0, following code locates these and returns them nan\n",
    "            start_points = df_sum.ne(0).idxmax()\n",
    "            for i in df_sum.columns:\n",
    "                df_sum.loc[:start_points[i],i].replace(0, np.nan, inplace=True)\n",
    "            df_list.append(df_sum)\n",
    "        elif i == 'CLOSE':\n",
    "            df_close = df[agg_dict[i]]\n",
    "            df_close = df_close.groupby(pd.Grouper(freq='M')).last()\n",
    "            df_list.append(df_close)\n",
    "    df_agg = pd.concat(df_list, axis =1)\n",
    "    return df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregator_avg_weekly(df, agg_dict):\n",
    "    '''\n",
    "    Aggregates the daily/weekly dfs to monthly frequency based on the aggregation mappings in the dictionary.\n",
    "    \n",
    "    Average and close methods unchanged. Final month sum series have average extrapolated by the number of \n",
    "    remaining release days.\n",
    "    '''\n",
    "    df_list = []\n",
    "    for i in agg_dict.keys():\n",
    "        if i == 'AVERAGE':\n",
    "            df_avg = df[agg_dict[i]]\n",
    "            df_avg = df_avg.groupby(pd.Grouper(freq='M')).mean()\n",
    "            df_list.append(df_avg)\n",
    "        elif i == 'SUM':\n",
    "            df_sum = df[agg_dict[i]]\n",
    "            df_counts = df_sum.groupby(pd.Grouper(freq='M')).count()\n",
    "            df_sum = df_sum.groupby(pd.Grouper(freq='M')).sum()\n",
    "            # scale up sum variables by the remaining working days in the month\n",
    "            if df.index[-1] < last_working_day(df_sum.index[-1].year, df_sum.index[-1].month, df_sum.index[-1].day):\n",
    "                work_days = working_days(df_sum.index[-1].year, df_sum.index[-1].month,1)\n",
    "                for i in df_sum.columns:\n",
    "                    df_sum.loc[df_sum.index[-1],i] = (4/df_counts.loc[df_counts.index[-1],i])*df_sum.loc[df_sum.index[-1],i]\n",
    "            # all leading nan values have been converted to 0, following code loc/ returns them nan\n",
    "            start_points = df_sum.ne(0).idxmax()\n",
    "            for i in df_sum.columns:\n",
    "                df_sum.loc[:start_points[i],i].replace(0, np.nan, inplace=True)\n",
    "            df_list.append(df_sum)\n",
    "        elif i == 'CLOSE':\n",
    "            df_close = df[agg_dict[i]]\n",
    "            df_close = df_close.groupby(pd.Grouper(freq='M')).last()\n",
    "            df_list.append(df_close)\n",
    "    df_agg = pd.concat(df_list, axis =1)\n",
    "    return df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_df(df):\n",
    "    '''\n",
    "    Performs the augmented dickey fuller test on all columns on the dictionary\n",
    "    '''\n",
    "    adf_dict = {}\n",
    "    for i in df.columns:\n",
    "        first_index = df[i].first_valid_index()\n",
    "        last_index = df[i].last_valid_index()\n",
    "\n",
    "        adf = adfuller(df.loc[first_index:last_index, i].interpolate())\n",
    "        \n",
    "        adf_dict[i] = {'adf_stat' : adf[0],\n",
    "                       'p_value' : adf[1],\n",
    "                       'crit_values' : adf[4]}\n",
    "    return adf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_adf(adf_dict, p_value):\n",
    "    '''\n",
    "    converts the results of adf_df() to a list of non-stationary features based on the defined p-value\n",
    "    '''\n",
    "    nonstationary_list = []\n",
    "    for i in adf_dict.keys():\n",
    "        # identify the series not determined to be stationary at the 5% significance level\n",
    "        if adf_dict[i]['p_value'] > p_value:\n",
    "            nonstationary_list.append(i)\n",
    "    \n",
    "    return nonstationary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nowcast_monthly_series(df, point_in_month = 'end'):\n",
    "    '''\n",
    "    Converts nowcast results into a monthly time series based on point in the month specified.\n",
    "    '''\n",
    "    nowcast_monthly = {}\n",
    "    if point_in_month == 'end':\n",
    "        for i in df.index[1:]:\n",
    "            try:\n",
    "                nowcast_monthly[i] = df.loc[i,str(i.date())]\n",
    "            except KeyError:\n",
    "                continue\n",
    "    else:\n",
    "        for i in df.index[1:]:\n",
    "            nowcast_monthly[i] = df.loc[i,str(datetime.date(i.year, i.month, point_in_month))]\n",
    "        \n",
    "    return pd.Series(nowcast_monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nowcast_monthly_var(df):\n",
    "    '''\n",
    "    Calculates the variance of the nowcasts for each month.\n",
    "    '''\n",
    "    nowcast_vars = {}\n",
    "    for i in df.index:\n",
    "        nowcast_vars[i] = df.loc[i, str(datetime.date(i.year, i.month, 1)):i].T.dropna().var()\n",
    "    \n",
    "    return nowcast_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nowcast_vintage(vintage, feature_selection, model, cutoff_date, cutoff_series):\n",
    "    '''\n",
    "    Will perform a nowcast from a specified vintage. \n",
    "    \n",
    "    Series from a specific feature selection and the model can be specified, alongside which cutoff series and df to use.\n",
    "    '''\n",
    "    # create vintages of each frequency\n",
    "    ip_vint, daily_vint, weekly_vint = vintagiser(ip_release_dates, vintage)\n",
    "    # perform higher frequency aggregation - data out to the end of the month extrapolated (no forecasts)\n",
    "    daily_vint = aggregator_avg_daily(daily_vint, agg_daily)\n",
    "    weekly_vint = aggregator_avg_weekly(weekly_vint, agg_weekly)\n",
    "    # combine dfs and wrangle data\n",
    "    combined_df = pd.concat([ip_vint, daily_vint, weekly_vint], axis=1)\n",
    "    vint_df = combined_df.loc[cutoff_date:,cutoff_series]\n",
    "    vint_df.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "    # cut df into the vintage and higher frequency data for nowcast\n",
    "    vint_cut = vint_df.loc[:vint_df['INDPRO'].last_valid_index()]\n",
    "    nowcast_df = vint_df.loc[vint_df['INDPRO'].last_valid_index() < vint_df.index]\n",
    "    # \n",
    "    y = vint_cut['INDPRO']\n",
    "    x = vint_cut[feature_selection]\n",
    "    model.fit(x,y)\n",
    "    # setup the nowcast df with features and index\n",
    "    x_nowcast = nowcast_df[feature_selection]\n",
    "    # if nowcast df only contains one month of nowcast adjust so it only predicts one row\n",
    "    try:\n",
    "        yhat = model.predict(x_nowcast)\n",
    "        yhat = pd.DataFrame(yhat, index = x_nowcast.index)\n",
    "    # reaches the except when not all HF series have data available for that month yet - then just takes the first row.\n",
    "    except ValueError:\n",
    "        try:\n",
    "            index = x_nowcast.index[0]\n",
    "            x_nowcast = x_nowcast.iloc[0]\n",
    "            x_nowcast = x_nowcast.values.reshape(1,-1)\n",
    "            yhat = model.predict(x_nowcast)\n",
    "            yhat = pd.DataFrame(yhat, index = [index])\n",
    "        except ValueError:\n",
    "            return\n",
    "\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_nowcast(periods, vintage, fs, model, cutoff_date, cutoff_series):\n",
    "    '''\n",
    "    Performs nowcasts over a rolling basis, starting from the vintage specified for the number of periods specified.\n",
    "    '''\n",
    "    count = 0\n",
    "    nowcast_dict = {}\n",
    "    while count < periods:\n",
    "        nowcast = nowcast_vintage(vintage, fs, model, cutoff_date, cutoff_series)\n",
    "        nowcast_dict[vintage] = nowcast\n",
    "        vintage += datetime.timedelta(1)\n",
    "        count +=1\n",
    "    return nowcast_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significant_lags_fs(x_df, y_df, threshold, result_list):    \n",
    "    '''\n",
    "    Calculates significant lags of features and outputs a dictionary containing pvalues of each significant lag\n",
    "    '''\n",
    "    model = sm.OLS(y_df,x_df)\n",
    "    results = model.fit()\n",
    "    print(results.pvalues)\n",
    "    # -1 index means this always selects the last lag value\n",
    "    if results.pvalues[-1] < threshold:\n",
    "        # store p value\n",
    "        result_list.append(results.pvalues[-1])\n",
    "        # take lags of x variable and add to df, rerun and check p values of the lag\n",
    "        lag = x_df.shift()\n",
    "        new_df = pd.concat([x_df, lag],axis=1)\n",
    "        new_df = new_df.iloc[1:]\n",
    "        y_lag = y_df.loc[new_df.index]\n",
    "        return significant_lags_fs(new_df, y_lag, threshold, result_list)\n",
    "    else:\n",
    "        return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_df(result_dict, df):\n",
    "    '''\n",
    "    Converts the resulting dictionary from significant_lags_fs() and creates the lagged columns in the resultant dictionary\n",
    "    '''\n",
    "    for i in result_dict.keys():\n",
    "        if len(result_dict[i]) > 1:\n",
    "            for j in range(len(result_dict[i])):\n",
    "                if j == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    new_column = df[i].shift(j)\n",
    "                    new_column.name = new_column.name + '_lag'+str(j)\n",
    "                    df = pd.concat([df, new_column], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcst_eom_daily(df):\n",
    "    '''\n",
    "    Takes a dataframe of daily frequency data and forecasts out to the end of the month using a simple AR(1) model. \n",
    "    '''\n",
    "    \n",
    "    # calculate the last day in the month and create a dataframe that contains an index from the last point in the df \n",
    "    # to the end of the month\n",
    "    to_eom = pd.date_range(start = df.index[-1] + datetime.timedelta(days = 1), \n",
    "                           end = datetime.datetime(df.index[-1].year, df.index[-1].month, \n",
    "                                                   calendar.monthrange(df.index[-1].year, df.index[-1].month)[1]))   \n",
    "    to_eom = pd.DataFrame(index = to_eom, columns = df.columns)\n",
    "    # pad out dataframe with the to end of month df\n",
    "    df_padded = pd.concat([df, to_eom])\n",
    "\n",
    "    # interpolate to remove NaN weekend values\n",
    "    df_pad_int = df_padded.interpolate(method = 'pad', limit_area = 'inside')\n",
    "\n",
    "    # replace interpolated trailing NaNs with their correct endpoints\n",
    "    for i in df_padded.columns:\n",
    "        df_pad_int[i] = df_pad_int[i].where(df_pad_int.index < df_padded[i].last_valid_index(), np.nan)\n",
    "\n",
    "    # perform a rolling forecast on all columns in the dataframe\n",
    "    for i in df_pad_int.columns:\n",
    "        while df_pad_int[i].last_valid_index() != df_padded.index[-1]:\n",
    "            # at each new value retrain AR model with the latest prediction fit and predict it\n",
    "            next_date = df_pad_int[i].last_valid_index() + datetime.timedelta(days = 1)\n",
    "            model = AutoReg(df_pad_int[i].loc[df_pad_int[i].first_valid_index():df_pad_int[i].last_valid_index()], \n",
    "                            lags = 1,\n",
    "                            old_names = True)\n",
    "            fit = model.fit()\n",
    "            pred = fit.predict(start = next_date, end = next_date, dynamic=False)\n",
    "            df_pad_int[i].loc[next_date] = pred.values[0]\n",
    "\n",
    "    # place forecasts into the padded dataframe - preserves NaNs that were removed from interpolating\n",
    "    for i in df_padded.columns:\n",
    "        df_padded.loc[df[i].last_valid_index() + datetime.timedelta(days=1):, i] = df_pad_int.loc[df[i].last_valid_index() + datetime.timedelta(days=1):, i]\n",
    "\n",
    "    # re,ove forecasted values on the weekends when data is not typically released\n",
    "    for i in df_padded.loc[str(df_padded.index[-1].year)+'-'+str(df_padded.index[-1].month)].index:\n",
    "        # 5 - Saturday, 6 - Sunday\n",
    "        if i.weekday() == 5 or i.weekday() == 6:\n",
    "            df_padded.loc[i] = np.nan\n",
    "    \n",
    "    return df_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcst_eom_weekly(df):\n",
    "    '''\n",
    "    Takes a dataframe of weekly frequency data and forecasts out to the end of the month using a simple AR(1) model.\n",
    "    \n",
    "    Process is much the same as fcst_eom_daily(df) except for the \n",
    "    '''\n",
    "    \n",
    "    # calculate the last day in the month and create a dataframe that contains an index from the last point in the df to the end of the month\n",
    "    to_eom = pd.date_range(start = df.index[-1] + datetime.timedelta(days = 1) , \n",
    "                           end = datetime.datetime(df.index[-1].year, df.index[-1].month, \n",
    "                                                   calendar.monthrange(df.index[-1].year, df.index[-1].month)[1]))\n",
    "    to_eom = pd.DataFrame(index = to_eom, columns = df.columns)\n",
    "\n",
    "    # pad out dataframe with the to end of month df\n",
    "    df_padded = pd.concat([df, to_eom])\n",
    "\n",
    "    # interpolate to remove NaN weekend values\n",
    "    df_pad_int = df_padded.interpolate(method = 'pad', limit_area = 'inside')\n",
    "\n",
    "    # replace interpolated trailing NaNs with their correct endpoints\n",
    "    for i in df_padded.columns:\n",
    "        df_pad_int[i] = df_pad_int[i].where(df_pad_int.index < df_padded[i].last_valid_index(), np.nan)\n",
    "\n",
    "    # specify index is daily frequency to remove warning message\n",
    "    \n",
    "    \n",
    "    # perform a rolling forecast on all columns in the dataframe\n",
    "    for i in df_pad_int.columns:\n",
    "        while df_pad_int[i].last_valid_index() != df_padded.index[-1]:\n",
    "            # at each new value retrain AR model with the latest prediction fit and predict it\n",
    "            next_date = df_pad_int[i].last_valid_index() + datetime.timedelta(days = 1)\n",
    "            model = AutoReg(df_pad_int[i].loc[df_pad_int[i].first_valid_index():df_pad_int[i].last_valid_index()], \n",
    "                            lags = 1,\n",
    "                            old_names = True)\n",
    "            fit = model.fit()\n",
    "            pred = fit.predict(start = next_date, end = next_date, dynamic=False)\n",
    "            df_pad_int[i].loc[next_date] = pred.values[0]\n",
    "\n",
    "    # place forecasts into the padded dataframe - preserves NaNs that were removed from interpolating\n",
    "    for i in df_padded.columns:\n",
    "        df_padded.loc[df[i].last_valid_index() + datetime.timedelta(days=1):, i] = df_pad_int.loc[df[i].last_valid_index() + datetime.timedelta(days=1):, i]\n",
    "\n",
    "    # check previous complete month to find the day of the week for the release of each series\n",
    "    last_year = df_padded.index[-1].year\n",
    "    last_month = df_padded.index[-1].month\n",
    "\n",
    "    if last_month == 1:\n",
    "        prev_month = str(last_year - 1)+\"-12\"\n",
    "    else:\n",
    "        prev_month = str(last_year) + \"-\" + str(last_month-1)\n",
    "\n",
    "    for i in df_padded.columns:\n",
    "        for j in df_padded.loc[prev_month].index:\n",
    "            # find the first non null day of the week in the previous month - assume this is the weekly release day\n",
    "            # set release day and break out of the index loop\n",
    "            if pd.notnull(df_padded.loc[j,i]):\n",
    "                release_day = j.weekday()\n",
    "                break\n",
    "        for j in df_padded.loc[str(df_padded.index[-1].year)+'-'+str(df_padded.index[-1].month)].index:\n",
    "            if j.weekday() != release_day:\n",
    "                df_padded.loc[j,i] = np.nan\n",
    "                \n",
    "    return df_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nowcast_vintage_fcst(vintage, feature_selection, model, cutoff_date, cutoff_series):\n",
    "    '''\n",
    "    Will perform a nowcast from a specified vintage. \n",
    "    \n",
    "    Series from a specific feature selection and the model can be specified, alongside which cutoff series and df to use.\n",
    "    '''\n",
    "    # create vintages of each frequency\n",
    "    ip_vint, daily_vint, weekly_vint = vintagiser(ip_release_dates, vintage)\n",
    "    # populate the daily and weekly dataframes\n",
    "    daily_vint = fcst_eom_daily(daily_vint)\n",
    "    weekly_vint = fcst_eom_weekly(weekly_vint)\n",
    "    # perform higher frequency aggregation\n",
    "    daily_vint = aggregator(daily_vint, agg_daily)\n",
    "    weekly_vint = aggregator(weekly_vint, agg_weekly)\n",
    "    # combine dfs and wrangle data\n",
    "    combined_df = pd.concat([ip_vint, daily_vint, weekly_vint], axis=1)\n",
    "    vint_df = combined_df.loc[cutoff_date:,cutoff_series]\n",
    "    vint_df.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "    # cut df into the vintage and higher frequency data for nowcast\n",
    "    vint_cut = vint_df.loc[:vint_df['INDPRO'].last_valid_index()]\n",
    "    nowcast_df = vint_df.loc[vint_df['INDPRO'].last_valid_index() < vint_df.index]\n",
    "    # \n",
    "    y = vint_cut['INDPRO']\n",
    "    x = vint_cut[feature_selection]\n",
    "    model.fit(x,y)\n",
    "    # setup the nowcast df with features and index\n",
    "    x_nowcast = nowcast_df[feature_selection]\n",
    "    # if nowcast df only contains one month of nowcast adjust so it only predicts one row\n",
    "    try:\n",
    "        yhat = model.predict(x_nowcast)\n",
    "        yhat = pd.DataFrame(yhat, index = x_nowcast.index)\n",
    "    # reaches the except when not all HF series have data available for that month yet - then just takes the first row.\n",
    "    except ValueError:\n",
    "        try:\n",
    "            index = x_nowcast.index[0]\n",
    "            x_nowcast = x_nowcast.iloc[0]\n",
    "            x_nowcast = x_nowcast.values.reshape(1,-1)\n",
    "            yhat = model.predict(x_nowcast)\n",
    "            yhat = pd.DataFrame(yhat, index = [index])\n",
    "        except ValueError:\n",
    "            return\n",
    "\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_nowcast_fcst(periods, vintage, fs, model, cutoff_date, cutoff_series):\n",
    "    '''\n",
    "    Performs nowcasts over a rolling basis, starting from the vintage specified for the number of periods specified.\n",
    "    '''\n",
    "    count = 0\n",
    "    nowcast_dict = {}\n",
    "    while count < periods:\n",
    "        nowcast = nowcast_vintage_fcst(vintage, fs, model, cutoff_date, cutoff_series)\n",
    "        nowcast_dict[vintage] = nowcast\n",
    "        print(vintage)\n",
    "        vintage += datetime.timedelta(1)\n",
    "        count +=1\n",
    "    return nowcast_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nowcast_vintage_fcst_v2(vintage, feature_selection, model, cutoff_date, cutoff_series):\n",
    "    '''\n",
    "    Will perform a nowcast from a specified vintage. \n",
    "    \n",
    "    Series from a specific feature selection and the model can be specified, alongside which cutoff series and df to use.\n",
    "    '''\n",
    "    # create vintages of each frequency\n",
    "    ip_vint, daily_vint, weekly_vint = vintagiser(ip_release_dates, vintage)\n",
    "    \n",
    "    # perform cutoff\n",
    "    ip_vint = ip_vint.loc[cutoff_date:,]\n",
    "    daily_vint = daily_vint.loc[cutoff_date:,cutoff_series['daily']]\n",
    "    daily_vint.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "    # ensure the index is set to daily to avoid error messages\n",
    "    daily_vint.index = pd.DatetimeIndex(daily_vint.index.values, freq = 'd')\n",
    "    weekly_vint = weekly_vint.loc[cutoff_date:,cutoff_series['weekly']]\n",
    "    weekly_vint.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "    \n",
    "    # populate the daily and weekly dataframes\n",
    "    daily_vint = fcst_eom_daily(daily_vint)\n",
    "    weekly_vint = fcst_eom_weekly(weekly_vint)\n",
    "    \n",
    "    # obtain aggregation dictionaries for the cutoff periods\n",
    "    agg_dict_daily = {'AVERAGE' : [],\n",
    "                     'SUM' : [],\n",
    "                     'CLOSE' : []}\n",
    "    agg_dict_weekly = {'AVERAGE' : [],\n",
    "                       'SUM' : [],\n",
    "                       'CLOSE' : []}\n",
    "    for i in cutoff_series['daily']:\n",
    "        agg_dict_daily[agg_daily_reverse[i]].append(i)\n",
    "    \n",
    "    for i in cutoff_series['weekly']:\n",
    "        agg_dict_weekly[agg_weekly_reverse[i]].append(i)\n",
    "    \n",
    "    # check if features are daily, weekly or both and run subsequent nowcast \n",
    "    \n",
    "    # perform higher frequency aggregation\n",
    "    daily_vint = aggregator(daily_vint, agg_dict_daily)\n",
    "    weekly_vint = aggregator(weekly_vint, agg_dict_weekly)\n",
    "\n",
    "    # combine dfs and wrangle data\n",
    "    combined_df = pd.concat([ip_vint, daily_vint, weekly_vint], axis=1)\n",
    "\n",
    "    \n",
    "    # cut df into the vintage and higher frequency data for nowcast\n",
    "    vint_cut = combined_df.loc[:combined_df['INDPRO'].last_valid_index()]\n",
    "    nowcast_df = combined_df.loc[combined_df['INDPRO'].last_valid_index() < combined_df.index]\n",
    "    # \n",
    "    y = vint_cut['INDPRO']\n",
    "    x = vint_cut[feature_selection]\n",
    "    \n",
    "    model.fit(x,y)\n",
    "    # setup the nowcast df with features and index\n",
    "    x_nowcast = nowcast_df[feature_selection]\n",
    "    # if nowcast df only contains one month of nowcast adjust so it only predicts one row\n",
    "    try:\n",
    "        yhat = model.predict(x_nowcast)\n",
    "        yhat = pd.DataFrame(yhat, index = x_nowcast.index)\n",
    "    # reaches the except when not all HF series have data available for that month yet - then just takes the first row.\n",
    "    except ValueError:\n",
    "        try:\n",
    "            index = x_nowcast.index[0]\n",
    "            x_nowcast = x_nowcast.iloc[0]\n",
    "            x_nowcast = x_nowcast.values.reshape(1,-1)\n",
    "            yhat = model.predict(x_nowcast)\n",
    "            yhat = pd.DataFrame(yhat, index = [index])\n",
    "        except ValueError:\n",
    "            return\n",
    "\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_frequency(feature_selection):\n",
    "    '''\n",
    "    Calculates the frequency of the features chosen by feature selection.\n",
    "    '''\n",
    "    # create dictionary mapping the features to their frequency\n",
    "    fs_breakdown = {'daily' : [],\n",
    "                    'weekly' : []}\n",
    "    for i in feature_selection:\n",
    "        if i in daily_trim.columns:\n",
    "            fs_breakdown['daily'].append(i)\n",
    "        else:\n",
    "            fs_breakdown['weekly'].append(i)\n",
    "    \n",
    "    # check if features are daily, weekly or both\n",
    "    if len(fs_breakdown['daily']) > 0 and len(fs_breakdown['weekly']) == 0:\n",
    "        return 'daily'\n",
    "    elif len(fs_breakdown['daily']) == 0 and len(fs_breakdown['weekly']) > 0:\n",
    "        return 'weekly'\n",
    "    else:\n",
    "        return 'both'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nowcast_vintage_fcst_v3(vintage, feature_selection, feature_frequency, model, cutoff_date, cutoff_series):\n",
    "    '''\n",
    "    Will perform a nowcast from a specified vintage. \n",
    "    \n",
    "    Series from a specific feature selection and the model can be specified, alongside which cutoff series and df to use.\n",
    "    '''\n",
    "    if feature_frequency == 'both':\n",
    "        # create vintages of each frequency\n",
    "        ip_vint, daily_vint, weekly_vint = vintagiser(ip_release_dates, vintage)\n",
    "\n",
    "        # perform cutoff\n",
    "        ip_vint = ip_vint.loc[cutoff_date:,]\n",
    "        daily_vint = daily_vint.loc[cutoff_date:,cutoff_series['daily']]\n",
    "        daily_vint.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "        # ensure the index is set to daily to avoid error messages\n",
    "        daily_vint.index = pd.DatetimeIndex(daily_vint.index.values, freq = 'd')\n",
    "        weekly_vint = weekly_vint.loc[cutoff_date:,cutoff_series['weekly']]\n",
    "        weekly_vint.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "\n",
    "        # identify the frequency of feature selections\n",
    "        fs_breakdown = {'daily' : [],\n",
    "                        'weekly' : []}\n",
    "        for i in feature_selection:\n",
    "            if i in daily_trim.columns:\n",
    "                fs_breakdown['daily'].append(i)\n",
    "            else:\n",
    "                fs_breakdown['weekly'].append(i)\n",
    "\n",
    "        # take feature selection now to speed up process - no need to forward cast all series\n",
    "        daily_vint_fs = daily_vint[fs_breakdown['daily']]\n",
    "        weekly_vint_fs = weekly_vint[fs_breakdown['weekly']]\n",
    "\n",
    "        # populate the daily and weekly dataframes\n",
    "        daily_vint_fs = fcst_eom_daily(daily_vint_fs)\n",
    "        weekly_vint_fs = fcst_eom_weekly(weekly_vint_fs)\n",
    "\n",
    "        # obtain aggregation dictionaries for the cutoff periods\n",
    "        agg_dict_daily = {'AVERAGE' : [],\n",
    "                         'SUM' : [],\n",
    "                         'CLOSE' : []}\n",
    "        agg_dict_weekly = {'AVERAGE' : [],\n",
    "                           'SUM' : [],\n",
    "                           'CLOSE' : []}\n",
    "        for i in fs_breakdown['daily']:\n",
    "            agg_dict_daily[agg_daily_reverse[i]].append(i)\n",
    "\n",
    "        for i in fs_breakdown['weekly']:\n",
    "            agg_dict_weekly[agg_weekly_reverse[i]].append(i)\n",
    "\n",
    "        # perform higher frequency aggregation\n",
    "        daily_vint_fs = aggregator(daily_vint, agg_dict_daily)\n",
    "        weekly_vint_fs = aggregator(weekly_vint, agg_dict_weekly)\n",
    "\n",
    "        # combine dfs and wrangle data\n",
    "        combined_df = pd.concat([ip_vint, daily_vint_fs, weekly_vint_fs], axis=1)\n",
    "\n",
    "        # cut df into the vintage and higher frequency data for nowcast\n",
    "        vint_cut = combined_df.loc[:combined_df['INDPRO'].last_valid_index()]\n",
    "        nowcast_df = combined_df.loc[combined_df['INDPRO'].last_valid_index() < combined_df.index]\n",
    "        # \n",
    "        y = vint_cut['INDPRO']\n",
    "        x = vint_cut[feature_selection]\n",
    "\n",
    "        model.fit(x,y)\n",
    "        # setup the nowcast df with features and index\n",
    "        x_nowcast = nowcast_df[feature_selection]\n",
    "        # if nowcast df only contains one month of nowcast adjust so it only predicts one row\n",
    "        try:\n",
    "            yhat = model.predict(x_nowcast)\n",
    "            yhat = pd.DataFrame(yhat, index = x_nowcast.index)\n",
    "        # reaches the except when not all HF series have data available for that month yet - then just takes the first row.\n",
    "        except ValueError:\n",
    "            try:\n",
    "                index = x_nowcast.index[0]\n",
    "                x_nowcast = x_nowcast.iloc[0]\n",
    "                x_nowcast = x_nowcast.values.reshape(1,-1)\n",
    "                yhat = model.predict(x_nowcast)\n",
    "                yhat = pd.DataFrame(yhat, index = [index])\n",
    "            except ValueError:\n",
    "                return\n",
    "\n",
    "        return yhat\n",
    "    \n",
    "    elif feature_frequency == 'daily':\n",
    "        # create vintages of each frequency\n",
    "        ip_vint, daily_vint, weekly_vint = vintagiser(ip_release_dates, vintage)\n",
    "\n",
    "        # perform cutoff\n",
    "        ip_vint = ip_vint.loc[cutoff_date:,]\n",
    "        daily_vint = daily_vint.loc[cutoff_date:,cutoff_series['daily']]\n",
    "        daily_vint.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "        # ensure the index is set to daily to avoid error messages\n",
    "        daily_vint.index = pd.DatetimeIndex(daily_vint.index.values, freq = 'd')\n",
    "\n",
    "        # take feature selection now to speed up process - no need to forward cast all series\n",
    "        daily_vint_fs = daily_vint[feature_selection]\n",
    "\n",
    "        # populate the daily and weekly dataframes\n",
    "        daily_vint_fs = fcst_eom_daily(daily_vint_fs)\n",
    "\n",
    "        # obtain aggregation dictionaries for the cutoff periods\n",
    "        agg_dict_daily = {'AVERAGE' : [],\n",
    "                         'SUM' : [],\n",
    "                         'CLOSE' : []}\n",
    "\n",
    "        for i in feature_selection:\n",
    "            agg_dict_daily[agg_daily_reverse[i]].append(i)\n",
    "\n",
    "        # perform higher frequency aggregation\n",
    "        daily_vint_fs = aggregator(daily_vint, agg_dict_daily)\n",
    "\n",
    "        # combine dfs and wrangle data\n",
    "        combined_df = pd.concat([ip_vint, daily_vint_fs], axis=1)\n",
    "\n",
    "        # cut df into the vintage and higher frequency data for nowcast\n",
    "        vint_cut = combined_df.loc[:combined_df['INDPRO'].last_valid_index()]\n",
    "        nowcast_df = combined_df.loc[combined_df['INDPRO'].last_valid_index() < combined_df.index]\n",
    "        # \n",
    "        y = vint_cut['INDPRO']\n",
    "        x = vint_cut[feature_selection]\n",
    "\n",
    "        model.fit(x,y)\n",
    "        # setup the nowcast df with features and index\n",
    "        x_nowcast = nowcast_df[feature_selection]\n",
    "        # if nowcast df only contains one month of nowcast adjust so it only predicts one row\n",
    "        try:\n",
    "            yhat = model.predict(x_nowcast)\n",
    "            yhat = pd.DataFrame(yhat, index = x_nowcast.index)\n",
    "        # reaches the except when not all HF series have data available for that month yet - then just takes the first row.\n",
    "        except ValueError:\n",
    "            try:\n",
    "                index = x_nowcast.index[0]\n",
    "                x_nowcast = x_nowcast.iloc[0]\n",
    "                x_nowcast = x_nowcast.values.reshape(1,-1)\n",
    "                yhat = model.predict(x_nowcast)\n",
    "                yhat = pd.DataFrame(yhat, index = [index])\n",
    "            except ValueError:\n",
    "                return\n",
    "\n",
    "        return yhat\n",
    "    \n",
    "    elif feature_frequency == 'weekly':\n",
    "        # create vintages of each frequency\n",
    "        ip_vint, daily_vint, weekly_vint = vintagiser(ip_release_dates, vintage)\n",
    "\n",
    "        # perform cutoff\n",
    "        ip_vint = ip_vint.loc[cutoff_date:,]\n",
    "\n",
    "        weekly_vint = weekly_vint.loc[cutoff_date:,cutoff_series['weekly']]\n",
    "        weekly_vint.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "\n",
    "        # take feature selection now to speed up process - no need to forward cast all series\n",
    "        weekly_vint_fs = weekly_vint[feature_selection]\n",
    "\n",
    "        # populate the daily and weekly dataframes\n",
    "        weekly_vint_fs = fcst_eom_weekly(weekly_vint_fs)\n",
    "\n",
    "        # obtain aggregation dictionaries for the cutoff periods\n",
    "        agg_dict_weekly = {'AVERAGE' : [],\n",
    "                           'SUM' : [],\n",
    "                           'CLOSE' : []}\n",
    "\n",
    "        for i in feature_selection:\n",
    "            agg_dict_weekly[agg_weekly_reverse[i]].append(i)\n",
    "\n",
    "        # perform higher frequency aggregation\n",
    "        weekly_vint_fs = aggregator(weekly_vint, agg_dict_weekly)\n",
    "\n",
    "        # combine dfs and wrangle data\n",
    "        combined_df = pd.concat([ip_vint, weekly_vint_fs], axis=1)\n",
    "\n",
    "        # cut df into the vintage and higher frequency data for nowcast\n",
    "        vint_cut = combined_df.loc[:combined_df['INDPRO'].last_valid_index()]\n",
    "        nowcast_df = combined_df.loc[combined_df['INDPRO'].last_valid_index() < combined_df.index]\n",
    "        # \n",
    "        y = vint_cut['INDPRO']\n",
    "        x = vint_cut[feature_selection]\n",
    "\n",
    "        model.fit(x,y)\n",
    "        # setup the nowcast df with features and index\n",
    "        x_nowcast = nowcast_df[feature_selection]\n",
    "        # if nowcast df only contains one month of nowcast adjust so it only predicts one row\n",
    "        try:\n",
    "            yhat = model.predict(x_nowcast)\n",
    "            yhat = pd.DataFrame(yhat, index = x_nowcast.index)\n",
    "        # reaches the except when not all HF series have data available for that month yet - then just takes the first row.\n",
    "        except ValueError:\n",
    "            try:\n",
    "                index = x_nowcast.index[0]\n",
    "                x_nowcast = x_nowcast.iloc[0]\n",
    "                x_nowcast = x_nowcast.values.reshape(1,-1)\n",
    "                yhat = model.predict(x_nowcast)\n",
    "                yhat = pd.DataFrame(yhat, index = [index])\n",
    "            except ValueError:\n",
    "                return\n",
    "\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_nowcast_fcst_v2(periods, vintage, fs, model, cutoff_date, cutoff_series):\n",
    "    '''\n",
    "    Performs nowcasts over a rolling basis, starting from the vintage specified for the number of periods specified.\n",
    "    '''\n",
    "    count = 0\n",
    "    nowcast_dict = {}\n",
    "    while count < periods:\n",
    "        nowcast = nowcast_vintage_fcst_v2(vintage, fs, model, cutoff_date, cutoff_series)\n",
    "        nowcast_dict[vintage] = nowcast\n",
    "        print(vintage)\n",
    "        vintage += datetime.timedelta(1)\n",
    "        count +=1\n",
    "    return nowcast_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_nowcast_fcst_v3(periods, vintage, fs, fs_frequency, model, cutoff_date, cutoff_series):\n",
    "    '''\n",
    "    Performs nowcasts over a rolling basis, starting from the vintage specified for the number of periods specified.\n",
    "    '''\n",
    "    count = 0\n",
    "    nowcast_dict = {}\n",
    "    while count < periods:\n",
    "        nowcast = nowcast_vintage_fcst_v3(vintage, fs, fs_frequency, model, cutoff_date, cutoff_series)\n",
    "        nowcast_dict[vintage] = nowcast\n",
    "        print(vintage)\n",
    "        vintage += datetime.timedelta(1)\n",
    "        count +=1\n",
    "    return nowcast_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nowcast_vintage_v2(vintage, feature_selection, model, cutoff_date, cutoff_series, stationary_dict):\n",
    "    '''\n",
    "    Will perform a nowcast from a specified vintage. \n",
    "    \n",
    "    Series from a specific feature selection and the model can be specified, alongside which cutoff series and df to use.\n",
    "    '''\n",
    "    # create vintages of each frequency\n",
    "    ip_vint, daily_vint, weekly_vint = vintagiser(ip_release_dates, vintage)\n",
    "    # perform higher frequency aggregation - data out to the end of the month extrapolated (no forecasts)\n",
    "    daily_vint = aggregator_avg_daily(daily_vint, agg_daily)\n",
    "    weekly_vint = aggregator_avg_weekly(weekly_vint, agg_weekly)\n",
    "    # combine dfs and wrangle data\n",
    "    combined_df = pd.concat([ip_vint, daily_vint, weekly_vint], axis=1)\n",
    "    vint_df = combined_df.loc[cutoff_date:,cutoff_series]\n",
    "    vint_df.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "    # take differences to make the data stationary\n",
    "    stationary_vars = {}\n",
    "    for i in vint_df.columns:\n",
    "        if i in stationary_dict[1]:\n",
    "            if i in stationary_dict[2]:\n",
    "                stationary_vars[i] = vint_df[i].diff().diff()\n",
    "            else:\n",
    "                stationary_vars[i] = vint_df[i].diff()\n",
    "        else:\n",
    "            stationary_vars[i] = vint_df[i]\n",
    "    vint_df = pd.DataFrame(stationary_vars)\n",
    "    # remove the NaNs from the first two rows caused by differencing\n",
    "    vint_df = vint_df.iloc[2:]\n",
    "    \n",
    "    # cut df into the vintage and higher frequency data for nowcast\n",
    "    vint_cut = vint_df.loc[:vint_df['INDPRO'].last_valid_index()]\n",
    "    nowcast_df = vint_df.loc[vint_df['INDPRO'].last_valid_index() < vint_df.index]\n",
    "    # \n",
    "    y = vint_cut['INDPRO']\n",
    "    x = vint_cut[feature_selection]\n",
    "    model.fit(x,y)\n",
    "    # setup the nowcast df with features and index\n",
    "    x_nowcast = nowcast_df[feature_selection]\n",
    "    # if nowcast df only contains one month of nowcast adjust so it only predicts one row\n",
    "    try:\n",
    "        yhat = model.predict(x_nowcast)\n",
    "        yhat = pd.DataFrame(yhat, index = x_nowcast.index)\n",
    "    # reaches the except when not all HF series have data available for that month yet - then just takes the first row.\n",
    "    except ValueError:\n",
    "        try:\n",
    "            index = x_nowcast.index[0]\n",
    "            x_nowcast = x_nowcast.iloc[0]\n",
    "            x_nowcast = x_nowcast.values.reshape(1,-1)\n",
    "            yhat = model.predict(x_nowcast)\n",
    "            yhat = pd.DataFrame(yhat, index = [index])\n",
    "        except ValueError:\n",
    "            return\n",
    "\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_nowcast_v2(periods, vintage, fs, model, cutoff_date, cutoff_series, stationary_dict):\n",
    "    '''\n",
    "    Performs nowcasts over a rolling basis, starting from the vintage specified for the number of periods specified.\n",
    "    '''\n",
    "    count = 0\n",
    "    nowcast_dict = {}\n",
    "    while count < periods:\n",
    "        nowcast = nowcast_vintage_v2(vintage, fs, model, cutoff_date, cutoff_series, stationary_dict)\n",
    "        nowcast_dict[vintage] = nowcast\n",
    "        vintage += datetime.timedelta(1)\n",
    "        count +=1\n",
    "    return nowcast_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nowcast_vintage_fcst_v4(vintage, feature_selection, feature_frequency, model, cutoff_date, cutoff_series, stationary_dict):\n",
    "    '''\n",
    "    Will perform a nowcast from a specified vintage. \n",
    "    \n",
    "    Series from a specific feature selection and the model can be specified, alongside which cutoff series and df to use.\n",
    "    '''\n",
    "    if feature_frequency == 'both':\n",
    "        # create vintages of each frequency\n",
    "        ip_vint, daily_vint, weekly_vint = vintagiser(ip_release_dates, vintage)\n",
    "\n",
    "        # perform cutoff\n",
    "        ip_vint = ip_vint.loc[cutoff_date:,]\n",
    "        daily_vint = daily_vint.loc[cutoff_date:,cutoff_series['daily']]\n",
    "        daily_vint.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "        # ensure the index is set to daily to avoid error messages\n",
    "        daily_vint.index = pd.DatetimeIndex(daily_vint.index.values, freq = 'd')\n",
    "        weekly_vint = weekly_vint.loc[cutoff_date:,cutoff_series['weekly']]\n",
    "        weekly_vint.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "\n",
    "        # identify the frequency of feature selections\n",
    "        fs_breakdown = {'daily' : [],\n",
    "                        'weekly' : []}\n",
    "        for i in feature_selection:\n",
    "            if i in daily_trim.columns:\n",
    "                fs_breakdown['daily'].append(i)\n",
    "            else:\n",
    "                fs_breakdown['weekly'].append(i)\n",
    "\n",
    "        # take feature selection now to speed up process - no need to forward cast all series\n",
    "        daily_vint_fs = daily_vint[fs_breakdown['daily']]\n",
    "        weekly_vint_fs = weekly_vint[fs_breakdown['weekly']]\n",
    "\n",
    "        # populate the daily and weekly dataframes\n",
    "        daily_vint_fs = fcst_eom_daily(daily_vint_fs)\n",
    "        weekly_vint_fs = fcst_eom_weekly(weekly_vint_fs)\n",
    "\n",
    "        # obtain aggregation dictionaries for the cutoff periods\n",
    "        agg_dict_daily = {'AVERAGE' : [],\n",
    "                         'SUM' : [],\n",
    "                         'CLOSE' : []}\n",
    "        agg_dict_weekly = {'AVERAGE' : [],\n",
    "                           'SUM' : [],\n",
    "                           'CLOSE' : []}\n",
    "        for i in fs_breakdown['daily']:\n",
    "            agg_dict_daily[agg_daily_reverse[i]].append(i)\n",
    "\n",
    "        for i in fs_breakdown['weekly']:\n",
    "            agg_dict_weekly[agg_weekly_reverse[i]].append(i)\n",
    "\n",
    "        # perform higher frequency aggregation\n",
    "        daily_vint_fs = aggregator(daily_vint, agg_dict_daily)\n",
    "        weekly_vint_fs = aggregator(weekly_vint, agg_dict_weekly)\n",
    "\n",
    "        # combine dfs and wrangle data\n",
    "        combined_df = pd.concat([ip_vint, daily_vint_fs, weekly_vint_fs], axis=1)\n",
    "        \n",
    "        # take differences to make the data stationary\n",
    "        stationary_vars = {}\n",
    "        for i in combined_df.columns:\n",
    "            if i in stationary_dict[1]:\n",
    "                if i in stationary_dict[2]:\n",
    "                    stationary_vars[i] = vint_df[i].diff().diff()\n",
    "                else:\n",
    "                    stationary_vars[i] = vint_df[i].diff()\n",
    "            else:\n",
    "                stationary_vars[i] = vint_df[i]\n",
    "        combined_df = pd.DataFrame(stationary_vars)\n",
    "        # remove the NaNs from the first two rows caused by differencing\n",
    "        combined_df = combined_df.iloc[2:]\n",
    "\n",
    "        # cut df into the vintage and higher frequency data for nowcast\n",
    "        vint_cut = combined_df.loc[:combined_df['INDPRO'].last_valid_index()]\n",
    "        nowcast_df = combined_df.loc[combined_df['INDPRO'].last_valid_index() < combined_df.index]\n",
    "        # \n",
    "        y = vint_cut['INDPRO']\n",
    "        x = vint_cut[feature_selection]\n",
    "\n",
    "        model.fit(x,y)\n",
    "        # setup the nowcast df with features and index\n",
    "        x_nowcast = nowcast_df[feature_selection]\n",
    "        # if nowcast df only contains one month of nowcast adjust so it only predicts one row\n",
    "        try:\n",
    "            yhat = model.predict(x_nowcast)\n",
    "            yhat = pd.DataFrame(yhat, index = x_nowcast.index)\n",
    "        # reaches the except when not all HF series have data available for that month yet - then just takes the first row.\n",
    "        except ValueError:\n",
    "            try:\n",
    "                index = x_nowcast.index[0]\n",
    "                x_nowcast = x_nowcast.iloc[0]\n",
    "                x_nowcast = x_nowcast.values.reshape(1,-1)\n",
    "                yhat = model.predict(x_nowcast)\n",
    "                yhat = pd.DataFrame(yhat, index = [index])\n",
    "            except ValueError:\n",
    "                return\n",
    "\n",
    "        return yhat\n",
    "    \n",
    "    elif feature_frequency == 'daily':\n",
    "        # create vintages of each frequency\n",
    "        ip_vint, daily_vint, weekly_vint = vintagiser(ip_release_dates, vintage)\n",
    "\n",
    "        # perform cutoff\n",
    "        ip_vint = ip_vint.loc[cutoff_date:,]\n",
    "        daily_vint = daily_vint.loc[cutoff_date:,cutoff_series['daily']]\n",
    "        daily_vint.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "        # ensure the index is set to daily to avoid error messages\n",
    "        daily_vint.index = pd.DatetimeIndex(daily_vint.index.values, freq = 'd')\n",
    "\n",
    "        # take feature selection now to speed up process - no need to forward cast all series\n",
    "        daily_vint_fs = daily_vint[feature_selection]\n",
    "\n",
    "        # populate the daily and weekly dataframes\n",
    "        daily_vint_fs = fcst_eom_daily(daily_vint_fs)\n",
    "\n",
    "        # obtain aggregation dictionaries for the cutoff periods\n",
    "        agg_dict_daily = {'AVERAGE' : [],\n",
    "                         'SUM' : [],\n",
    "                         'CLOSE' : []}\n",
    "\n",
    "        for i in feature_selection:\n",
    "            agg_dict_daily[agg_daily_reverse[i]].append(i)\n",
    "\n",
    "        # perform higher frequency aggregation\n",
    "        daily_vint_fs = aggregator(daily_vint, agg_dict_daily)\n",
    "\n",
    "        # combine dfs and wrangle data\n",
    "        combined_df = pd.concat([ip_vint, daily_vint_fs], axis=1)\n",
    "        \n",
    "        # take differences to make the data stationary\n",
    "        stationary_vars = {}\n",
    "        for i in combined_df.columns:\n",
    "            if i in stationary_dict[1]:\n",
    "                if i in stationary_dict[2]:\n",
    "                    stationary_vars[i] = vint_df[i].diff().diff()\n",
    "                else:\n",
    "                    stationary_vars[i] = vint_df[i].diff()\n",
    "            else:\n",
    "                stationary_vars[i] = vint_df[i]\n",
    "        combined_df = pd.DataFrame(stationary_vars)\n",
    "        # remove the NaNs from the first two rows caused by differencing\n",
    "        combined_df = combined_df.iloc[2:]\n",
    "\n",
    "        # cut df into the vintage and higher frequency data for nowcast\n",
    "        vint_cut = combined_df.loc[:combined_df['INDPRO'].last_valid_index()]\n",
    "        nowcast_df = combined_df.loc[combined_df['INDPRO'].last_valid_index() < combined_df.index]\n",
    "        # \n",
    "        y = vint_cut['INDPRO']\n",
    "        x = vint_cut[feature_selection]\n",
    "\n",
    "        model.fit(x,y)\n",
    "        # setup the nowcast df with features and index\n",
    "        x_nowcast = nowcast_df[feature_selection]\n",
    "        # if nowcast df only contains one month of nowcast adjust so it only predicts one row\n",
    "        try:\n",
    "            yhat = model.predict(x_nowcast)\n",
    "            yhat = pd.DataFrame(yhat, index = x_nowcast.index)\n",
    "        # reaches the except when not all HF series have data available for that month yet - then just takes the first row.\n",
    "        except ValueError:\n",
    "            try:\n",
    "                index = x_nowcast.index[0]\n",
    "                x_nowcast = x_nowcast.iloc[0]\n",
    "                x_nowcast = x_nowcast.values.reshape(1,-1)\n",
    "                yhat = model.predict(x_nowcast)\n",
    "                yhat = pd.DataFrame(yhat, index = [index])\n",
    "            except ValueError:\n",
    "                return\n",
    "\n",
    "        return yhat\n",
    "    \n",
    "    elif feature_frequency == 'weekly':\n",
    "        # create vintages of each frequency\n",
    "        ip_vint, daily_vint, weekly_vint = vintagiser(ip_release_dates, vintage)\n",
    "\n",
    "        # perform cutoff\n",
    "        ip_vint = ip_vint.loc[cutoff_date:,]\n",
    "\n",
    "        weekly_vint = weekly_vint.loc[cutoff_date:,cutoff_series['weekly']]\n",
    "        weekly_vint.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "\n",
    "        # take feature selection now to speed up process - no need to forward cast all series\n",
    "        weekly_vint_fs = weekly_vint[feature_selection]\n",
    "\n",
    "        # populate the daily and weekly dataframes\n",
    "        weekly_vint_fs = fcst_eom_weekly(weekly_vint_fs)\n",
    "\n",
    "        # obtain aggregation dictionaries for the cutoff periods\n",
    "        agg_dict_weekly = {'AVERAGE' : [],\n",
    "                           'SUM' : [],\n",
    "                           'CLOSE' : []}\n",
    "\n",
    "        for i in feature_selection:\n",
    "            agg_dict_weekly[agg_weekly_reverse[i]].append(i)\n",
    "\n",
    "        # perform higher frequency aggregation\n",
    "        weekly_vint_fs = aggregator(weekly_vint, agg_dict_weekly)\n",
    "\n",
    "        # combine dfs and wrangle data\n",
    "        combined_df = pd.concat([ip_vint, weekly_vint_fs], axis=1)\n",
    "        \n",
    "        # take differences to make the data stationary\n",
    "        stationary_vars = {}\n",
    "        for i in combined_df.columns:\n",
    "            if i in stationary_dict[1]:\n",
    "                if i in stationary_dict[2]:\n",
    "                    stationary_vars[i] = vint_df[i].diff().diff()\n",
    "                else:\n",
    "                    stationary_vars[i] = vint_df[i].diff()\n",
    "            else:\n",
    "                stationary_vars[i] = vint_df[i]\n",
    "        combined_df = pd.DataFrame(stationary_vars)\n",
    "        # remove the NaNs from the first two rows caused by differencing\n",
    "        combined_df = combined_df.iloc[2:]\n",
    "\n",
    "        # cut df into the vintage and higher frequency data for nowcast\n",
    "        vint_cut = combined_df.loc[:combined_df['INDPRO'].last_valid_index()]\n",
    "        nowcast_df = combined_df.loc[combined_df['INDPRO'].last_valid_index() < combined_df.index]\n",
    "        # \n",
    "        y = vint_cut['INDPRO']\n",
    "        x = vint_cut[feature_selection]\n",
    "\n",
    "        model.fit(x,y)\n",
    "        # setup the nowcast df with features and index\n",
    "        x_nowcast = nowcast_df[feature_selection]\n",
    "        # if nowcast df only contains one month of nowcast adjust so it only predicts one row\n",
    "        try:\n",
    "            yhat = model.predict(x_nowcast)\n",
    "            yhat = pd.DataFrame(yhat, index = x_nowcast.index)\n",
    "        # reaches the except when not all HF series have data available for that month yet - then just takes the first row.\n",
    "        except ValueError:\n",
    "            try:\n",
    "                index = x_nowcast.index[0]\n",
    "                x_nowcast = x_nowcast.iloc[0]\n",
    "                x_nowcast = x_nowcast.values.reshape(1,-1)\n",
    "                yhat = model.predict(x_nowcast)\n",
    "                yhat = pd.DataFrame(yhat, index = [index])\n",
    "            except ValueError:\n",
    "                return\n",
    "\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_nowcast_fcst_v4(periods, vintage, fs, fs_frequency, model, cutoff_date, cutoff_series, stationary_dict):\n",
    "    '''\n",
    "    Performs nowcasts over a rolling basis, starting from the vintage specified for the number of periods specified.\n",
    "    '''\n",
    "    count = 0\n",
    "    nowcast_dict = {}\n",
    "    while count < periods:\n",
    "        nowcast = nowcast_vintage_fcst_v4(vintage, fs, fs_frequency, model, cutoff_date, cutoff_series, stationary_dict)\n",
    "        nowcast_dict[vintage] = nowcast\n",
    "        print(vintage)\n",
    "        vintage += datetime.timedelta(1)\n",
    "        count +=1\n",
    "    return nowcast_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nowcast_vintage_v2_nn(vintage, feature_selection, model, cutoff_date, cutoff_series, stationary_dict, epochs, batch_size):\n",
    "    '''\n",
    "    Will perform a nowcast from a specified vintage. \n",
    "    \n",
    "    Series from a specific feature selection and the model can be specified, alongside which cutoff series and df to use.\n",
    "    '''\n",
    "    # create vintages of each frequency\n",
    "    ip_vint, daily_vint, weekly_vint = vintagiser(ip_release_dates, vintage)\n",
    "    # perform higher frequency aggregation - data out to the end of the month extrapolated (no forecasts)\n",
    "    daily_vint = aggregator_avg_daily(daily_vint, agg_daily)\n",
    "    weekly_vint = aggregator_avg_weekly(weekly_vint, agg_weekly)\n",
    "    # combine dfs and wrangle data\n",
    "    combined_df = pd.concat([ip_vint, daily_vint, weekly_vint], axis=1)\n",
    "    vint_df = combined_df.loc[cutoff_date:,cutoff_series]\n",
    "    vint_df.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "    # take differences to make the data stationary\n",
    "    stationary_vars = {}\n",
    "    for i in vint_df.columns:\n",
    "        if i in stationary_dict[1]:\n",
    "            if i in stationary_dict[2]:\n",
    "                stationary_vars[i] = vint_df[i].diff().diff()\n",
    "            else:\n",
    "                stationary_vars[i] = vint_df[i].diff()\n",
    "        else:\n",
    "            stationary_vars[i] = vint_df[i]\n",
    "    vint_df = pd.DataFrame(stationary_vars)\n",
    "    # remove the NaNs from the first two rows caused by differencing\n",
    "    vint_df = vint_df.iloc[2:]\n",
    "    \n",
    "    # cut df into the vintage and higher frequency data for nowcast\n",
    "    vint_cut = vint_df.loc[:vint_df['INDPRO'].last_valid_index()]\n",
    "    nowcast_df = vint_df.loc[vint_df['INDPRO'].last_valid_index() < vint_df.index]\n",
    "    # \n",
    "    y = vint_cut['INDPRO']\n",
    "    x = vint_cut[feature_selection]\n",
    "    \n",
    "    # scale the inputs\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    x_minmax = min_max_scaler.fit_transform(x)\n",
    "    \n",
    "    fit = model.fit(x_minmax,y, epochs = epochs, batch_size = batch_size, verbose = 0)\n",
    "    # setup the nowcast df with features and index\n",
    "    x_nowcast = nowcast_df[feature_selection]\n",
    "    x_nowcast_minmax = min_max_scaler.transform(x_nowcast)\n",
    "    # if nowcast df only contains one month of nowcast adjust so it only predicts one row\n",
    "    try:\n",
    "        yhat = model.predict(x_nowcast_minmax)\n",
    "        yhat = pd.DataFrame(yhat, index = x_nowcast.index)\n",
    "    # reaches the except when not all HF series have data available for that month yet - then just takes the first row.\n",
    "    except ValueError:\n",
    "        try:\n",
    "            index = x_nowcast.index[0]\n",
    "            x_nowcast = x_nowcast.iloc[0]\n",
    "            x_nowcast = x_nowcast.values.reshape(1,-1)\n",
    "            \n",
    "            x_nowcast_minmax = min_max_scaler.transform(x_nowcast)\n",
    "            \n",
    "            yhat = model.predict(x_nowcast_minmax)\n",
    "            yhat = pd.DataFrame(yhat, index = [index])\n",
    "        except ValueError:\n",
    "            return\n",
    "\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_nowcast_v2_nn(periods, vintage, fs, model, cutoff_date, cutoff_series, stationary_dict, epochs, batch_size):\n",
    "    '''\n",
    "    Performs nowcasts over a rolling basis, starting from the vintage specified for the number of periods specified.\n",
    "    '''\n",
    "    count = 0\n",
    "    nowcast_dict = {}\n",
    "    while count < periods:\n",
    "        nowcast = nowcast_vintage_v2_nn(vintage, fs, model, cutoff_date, cutoff_series, stationary_dict, epochs, batch_size)\n",
    "        nowcast_dict[vintage] = nowcast\n",
    "        vintage += datetime.timedelta(1)\n",
    "        count +=1\n",
    "    return nowcast_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v3 - log differences, not just differences\n",
    "def nowcast_vintage_v3(vintage, feature_selection, model, cutoff_date, cutoff_series, stationary_dict, drop_log_series):\n",
    "    '''\n",
    "    Will perform a nowcast from a specified vintage. \n",
    "    \n",
    "    Series from a specific feature selection and the model can be specified, alongside which cutoff series and df to use.\n",
    "    '''\n",
    "    # create vintages of each frequency\n",
    "    ip_vint, daily_vint, weekly_vint = vintagiser(ip_release_dates, vintage)\n",
    "    # perform higher frequency aggregation - data out to the end of the month extrapolated (no forecasts)\n",
    "    daily_vint = aggregator_avg_daily(daily_vint, agg_daily)\n",
    "    weekly_vint = aggregator_avg_weekly(weekly_vint, agg_weekly)\n",
    "    # combine dfs and wrangle data\n",
    "    combined_df = pd.concat([ip_vint, daily_vint, weekly_vint], axis=1)\n",
    "    vint_df = combined_df.loc[cutoff_date:,cutoff_series]\n",
    "    vint_df.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "    \n",
    "    # take logs\n",
    "    log_series = {}\n",
    "    for i in vint_df.columns:\n",
    "        log_series[i] = np.log(vint_df[i])\n",
    "        \n",
    "    log_series = pd.DataFrame(log_series, index = vint_df.index)\n",
    "    vint_df = log_series.drop(drop_log_series, axis=1)\n",
    "    \n",
    "    # take differences to make the data stationary\n",
    "    stationary_vars = {}\n",
    "    for i in vint_df.columns:\n",
    "        if i in stationary_dict[1]:\n",
    "            stationary_vars[i] = vint_df[i].diff()\n",
    "        else:\n",
    "            stationary_vars[i] = vint_df[i]\n",
    "    vint_df = pd.DataFrame(stationary_vars)\n",
    "    # remove the NaNs from the first two rows caused by differencing\n",
    "    vint_df = vint_df.iloc[2:]\n",
    "    \n",
    "    # cut df into the vintage and higher frequency data for nowcast\n",
    "    vint_cut = vint_df.loc[:vint_df['INDPRO'].last_valid_index()]\n",
    "    nowcast_df = vint_df.loc[vint_df['INDPRO'].last_valid_index() < vint_df.index]\n",
    "    # \n",
    "    y = vint_cut['INDPRO']\n",
    "    x = vint_cut[feature_selection]\n",
    "    model.fit(x,y)\n",
    "    # setup the nowcast df with features and index\n",
    "    x_nowcast = nowcast_df[feature_selection]\n",
    "    # if nowcast df only contains one month of nowcast adjust so it only predicts one row\n",
    "    try:\n",
    "        yhat = model.predict(x_nowcast)\n",
    "        yhat = pd.DataFrame(yhat, index = x_nowcast.index)\n",
    "    # reaches the except when not all HF series have data available for that month yet - then just takes the first row.\n",
    "    except ValueError:\n",
    "        try:\n",
    "            index = x_nowcast.index[0]\n",
    "            x_nowcast = x_nowcast.iloc[0]\n",
    "            x_nowcast = x_nowcast.values.reshape(1,-1)\n",
    "            yhat = model.predict(x_nowcast)\n",
    "            yhat = pd.DataFrame(yhat, index = [index])\n",
    "        except ValueError:\n",
    "            return\n",
    "\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_nowcast_v3(periods, vintage, fs, model, cutoff_date, cutoff_series, stationary_dict, drop_log_series):\n",
    "    '''\n",
    "    Performs nowcasts over a rolling basis, starting from the vintage specified for the number of periods specified.\n",
    "    '''\n",
    "    count = 0\n",
    "    nowcast_dict = {}\n",
    "    while count < periods:\n",
    "        nowcast = nowcast_vintage_v3(vintage, fs, model, cutoff_date, cutoff_series, stationary_dict, drop_log_series)\n",
    "        nowcast_dict[vintage] = nowcast\n",
    "        vintage += datetime.timedelta(1)\n",
    "        count +=1\n",
    "    return nowcast_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nowcast_vintage_fcst_v5(vintage, feature_selection, feature_frequency, model, cutoff_date, cutoff_series, stationary_dict):\n",
    "    '''\n",
    "    Will perform a nowcast from a specified vintage. \n",
    "    \n",
    "    Series from a specific feature selection and the model can be specified, alongside which cutoff series and df to use.\n",
    "    '''\n",
    "    if feature_frequency == 'both':\n",
    "        # create vintages of each frequency\n",
    "        ip_vint, daily_vint, weekly_vint = vintagiser(ip_release_dates, vintage)\n",
    "\n",
    "        # perform cutoff\n",
    "        ip_vint = ip_vint.loc[cutoff_date:,]\n",
    "        daily_vint = daily_vint.loc[cutoff_date:,cutoff_series['daily']]\n",
    "        daily_vint.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "        # ensure the index is set to daily to avoid error messages\n",
    "        daily_vint.index = pd.DatetimeIndex(daily_vint.index.values, freq = 'd')\n",
    "        weekly_vint = weekly_vint.loc[cutoff_date:,cutoff_series['weekly']]\n",
    "        weekly_vint.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "\n",
    "        # identify the frequency of feature selections\n",
    "        fs_breakdown = {'daily' : [],\n",
    "                        'weekly' : []}\n",
    "        for i in feature_selection:\n",
    "            if i in daily_trim.columns:\n",
    "                fs_breakdown['daily'].append(i)\n",
    "            else:\n",
    "                fs_breakdown['weekly'].append(i)\n",
    "\n",
    "        # take feature selection now to speed up process - no need to forward cast all series\n",
    "        daily_vint_fs = daily_vint[fs_breakdown['daily']]\n",
    "        weekly_vint_fs = weekly_vint[fs_breakdown['weekly']]\n",
    "\n",
    "        # populate the daily and weekly dataframes\n",
    "        daily_vint_fs = fcst_eom_daily(daily_vint_fs)\n",
    "        weekly_vint_fs = fcst_eom_weekly(weekly_vint_fs)\n",
    "\n",
    "        # obtain aggregation dictionaries for the cutoff periods\n",
    "        agg_dict_daily = {'AVERAGE' : [],\n",
    "                         'SUM' : [],\n",
    "                         'CLOSE' : []}\n",
    "        agg_dict_weekly = {'AVERAGE' : [],\n",
    "                           'SUM' : [],\n",
    "                           'CLOSE' : []}\n",
    "        for i in fs_breakdown['daily']:\n",
    "            agg_dict_daily[agg_daily_reverse[i]].append(i)\n",
    "\n",
    "        for i in fs_breakdown['weekly']:\n",
    "            agg_dict_weekly[agg_weekly_reverse[i]].append(i)\n",
    "\n",
    "        # perform higher frequency aggregation\n",
    "        daily_vint_fs = aggregator(daily_vint, agg_dict_daily)\n",
    "        weekly_vint_fs = aggregator(weekly_vint, agg_dict_weekly)\n",
    "\n",
    "        # combine dfs and wrangle data\n",
    "        combined_df = pd.concat([ip_vint, daily_vint_fs, weekly_vint_fs], axis=1)\n",
    "        \n",
    "        # take logs\n",
    "        log_series = {}\n",
    "        for i in combined_df.columns:\n",
    "            log_series[i] = np.log(combined_df[i])\n",
    "\n",
    "        combined_df = pd.DataFrame(log_series, index = vint_df.index)\n",
    "        \n",
    "        \n",
    "        # take differences to make the data stationary\n",
    "        stationary_vars = {}\n",
    "        for i in combined_df.columns:\n",
    "            if i in stationary_dict[1]:\n",
    "                stationary_vars[i] = combined_df[i].diff()\n",
    "            else:\n",
    "                stationary_vars[i] = combined_df[i]\n",
    "        combined_df = pd.DataFrame(stationary_vars)\n",
    "        # remove the NaNs from the first two rows caused by differencing\n",
    "        combined_df = combined_df.iloc[2:]\n",
    "\n",
    "        # cut df into the vintage and higher frequency data for nowcast\n",
    "        vint_cut = combined_df.loc[:combined_df['INDPRO'].last_valid_index()]\n",
    "        nowcast_df = combined_df.loc[combined_df['INDPRO'].last_valid_index() < combined_df.index]\n",
    "        # \n",
    "        y = vint_cut['INDPRO']\n",
    "        x = vint_cut[feature_selection]\n",
    "\n",
    "        model.fit(x,y)\n",
    "        # setup the nowcast df with features and index\n",
    "        x_nowcast = nowcast_df[feature_selection]\n",
    "        # if nowcast df only contains one month of nowcast adjust so it only predicts one row\n",
    "        try:\n",
    "            yhat = model.predict(x_nowcast)\n",
    "            yhat = pd.DataFrame(yhat, index = x_nowcast.index)\n",
    "        # reaches the except when not all HF series have data available for that month yet - then just takes the first row.\n",
    "        except ValueError:\n",
    "            try:\n",
    "                index = x_nowcast.index[0]\n",
    "                x_nowcast = x_nowcast.iloc[0]\n",
    "                x_nowcast = x_nowcast.values.reshape(1,-1)\n",
    "                yhat = model.predict(x_nowcast)\n",
    "                yhat = pd.DataFrame(yhat, index = [index])\n",
    "            except ValueError:\n",
    "                return\n",
    "\n",
    "        return yhat\n",
    "    \n",
    "    elif feature_frequency == 'daily':\n",
    "        # create vintages of each frequency\n",
    "        ip_vint, daily_vint, weekly_vint = vintagiser(ip_release_dates, vintage)\n",
    "\n",
    "        # perform cutoff\n",
    "        ip_vint = ip_vint.loc[cutoff_date:,]\n",
    "        daily_vint = daily_vint.loc[cutoff_date:,cutoff_series['daily']]\n",
    "        daily_vint.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "        # ensure the index is set to daily to avoid error messages\n",
    "        daily_vint.index = pd.DatetimeIndex(daily_vint.index.values, freq = 'd')\n",
    "\n",
    "        # take feature selection now to speed up process - no need to forward cast all series\n",
    "        daily_vint_fs = daily_vint[feature_selection]\n",
    "\n",
    "        # populate the daily and weekly dataframes\n",
    "        daily_vint_fs = fcst_eom_daily(daily_vint_fs)\n",
    "\n",
    "        # obtain aggregation dictionaries for the cutoff periods\n",
    "        agg_dict_daily = {'AVERAGE' : [],\n",
    "                         'SUM' : [],\n",
    "                         'CLOSE' : []}\n",
    "\n",
    "        for i in feature_selection:\n",
    "            agg_dict_daily[agg_daily_reverse[i]].append(i)\n",
    "\n",
    "        # perform higher frequency aggregation\n",
    "        daily_vint_fs = aggregator(daily_vint, agg_dict_daily)\n",
    "\n",
    "        # combine dfs and wrangle data\n",
    "        combined_df = pd.concat([ip_vint, daily_vint_fs], axis=1)\n",
    "        \n",
    "        # take logs\n",
    "        log_series = {}\n",
    "        for i in combined_df.columns:\n",
    "            log_series[i] = np.log(combined_df[i])\n",
    "\n",
    "        combined_df = pd.DataFrame(log_series, index = vint_df.index)\n",
    "        \n",
    "        \n",
    "        # take differences to make the data stationary\n",
    "        stationary_vars = {}\n",
    "        for i in combined_df.columns:\n",
    "            if i in stationary_dict[1]:\n",
    "                stationary_vars[i] = combined_df[i].diff()\n",
    "            else:\n",
    "                stationary_vars[i] = combined_df[i]\n",
    "        combined_df = pd.DataFrame(stationary_vars)\n",
    "        # remove the NaNs from the first two rows caused by differencing\n",
    "        combined_df = combined_df.iloc[2:]\n",
    "\n",
    "        # cut df into the vintage and higher frequency data for nowcast\n",
    "        vint_cut = combined_df.loc[:combined_df['INDPRO'].last_valid_index()]\n",
    "        nowcast_df = combined_df.loc[combined_df['INDPRO'].last_valid_index() < combined_df.index]\n",
    "        # \n",
    "        y = vint_cut['INDPRO']\n",
    "        x = vint_cut[feature_selection]\n",
    "\n",
    "        model.fit(x,y)\n",
    "        # setup the nowcast df with features and index\n",
    "        x_nowcast = nowcast_df[feature_selection]\n",
    "        # if nowcast df only contains one month of nowcast adjust so it only predicts one row\n",
    "        try:\n",
    "            yhat = model.predict(x_nowcast)\n",
    "            yhat = pd.DataFrame(yhat, index = x_nowcast.index)\n",
    "        # reaches the except when not all HF series have data available for that month yet - then just takes the first row.\n",
    "        except ValueError:\n",
    "            try:\n",
    "                index = x_nowcast.index[0]\n",
    "                x_nowcast = x_nowcast.iloc[0]\n",
    "                x_nowcast = x_nowcast.values.reshape(1,-1)\n",
    "                yhat = model.predict(x_nowcast)\n",
    "                yhat = pd.DataFrame(yhat, index = [index])\n",
    "            except ValueError:\n",
    "                return\n",
    "\n",
    "        return yhat\n",
    "    \n",
    "    elif feature_frequency == 'weekly':\n",
    "        # create vintages of each frequency\n",
    "        ip_vint, daily_vint, weekly_vint = vintagiser(ip_release_dates, vintage)\n",
    "\n",
    "        # perform cutoff\n",
    "        ip_vint = ip_vint.loc[cutoff_date:,]\n",
    "\n",
    "        weekly_vint = weekly_vint.loc[cutoff_date:,cutoff_series['weekly']]\n",
    "        weekly_vint.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "\n",
    "        # take feature selection now to speed up process - no need to forward cast all series\n",
    "        weekly_vint_fs = weekly_vint[feature_selection]\n",
    "\n",
    "        # populate the daily and weekly dataframes\n",
    "        weekly_vint_fs = fcst_eom_weekly(weekly_vint_fs)\n",
    "\n",
    "        # obtain aggregation dictionaries for the cutoff periods\n",
    "        agg_dict_weekly = {'AVERAGE' : [],\n",
    "                           'SUM' : [],\n",
    "                           'CLOSE' : []}\n",
    "\n",
    "        for i in feature_selection:\n",
    "            agg_dict_weekly[agg_weekly_reverse[i]].append(i)\n",
    "\n",
    "        # perform higher frequency aggregation\n",
    "        weekly_vint_fs = aggregator(weekly_vint, agg_dict_weekly)\n",
    "\n",
    "        # combine dfs and wrangle data\n",
    "        combined_df = pd.concat([ip_vint, weekly_vint_fs], axis=1)\n",
    "        \n",
    "        # take logs\n",
    "        log_series = {}\n",
    "        for i in combined_df.columns:\n",
    "            log_series[i] = np.log(combined_df[i])\n",
    "\n",
    "        combined_df = pd.DataFrame(log_series, index = vint_df.index)\n",
    "        \n",
    "        \n",
    "        # take differences to make the data stationary\n",
    "        stationary_vars = {}\n",
    "        for i in combined_df.columns:\n",
    "            if i in stationary_dict[1]:\n",
    "                stationary_vars[i] = combined_df[i].diff()\n",
    "            else:\n",
    "                stationary_vars[i] = combined_df[i]\n",
    "        combined_df = pd.DataFrame(stationary_vars)\n",
    "        # remove the NaNs from the first two rows caused by differencing\n",
    "        combined_df = combined_df.iloc[2:]\n",
    "\n",
    "        # cut df into the vintage and higher frequency data for nowcast\n",
    "        vint_cut = combined_df.loc[:combined_df['INDPRO'].last_valid_index()]\n",
    "        nowcast_df = combined_df.loc[combined_df['INDPRO'].last_valid_index() < combined_df.index]\n",
    "        # \n",
    "        y = vint_cut['INDPRO']\n",
    "        x = vint_cut[feature_selection]\n",
    "\n",
    "        model.fit(x,y)\n",
    "        # setup the nowcast df with features and index\n",
    "        x_nowcast = nowcast_df[feature_selection]\n",
    "        # if nowcast df only contains one month of nowcast adjust so it only predicts one row\n",
    "        try:\n",
    "            yhat = model.predict(x_nowcast)\n",
    "            yhat = pd.DataFrame(yhat, index = x_nowcast.index)\n",
    "        # reaches the except when not all HF series have data available for that month yet - then just takes the first row.\n",
    "        except ValueError:\n",
    "            try:\n",
    "                index = x_nowcast.index[0]\n",
    "                x_nowcast = x_nowcast.iloc[0]\n",
    "                x_nowcast = x_nowcast.values.reshape(1,-1)\n",
    "                yhat = model.predict(x_nowcast)\n",
    "                yhat = pd.DataFrame(yhat, index = [index])\n",
    "            except ValueError:\n",
    "                return\n",
    "\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_nowcast_fcst_v5(periods, vintage, fs, fs_frequency, model, cutoff_date, cutoff_series, stationary_dict):\n",
    "    '''\n",
    "    Performs nowcasts over a rolling basis, starting from the vintage specified for the number of periods specified.\n",
    "    '''\n",
    "    count = 0\n",
    "    nowcast_dict = {}\n",
    "    while count < periods:\n",
    "        nowcast = nowcast_vintage_fcst_v5(vintage, fs, fs_frequency, model, cutoff_date, cutoff_series, stationary_dict)\n",
    "        nowcast_dict[vintage] = nowcast\n",
    "        print(vintage)\n",
    "        vintage += datetime.timedelta(1)\n",
    "        count +=1\n",
    "    return nowcast_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nowcast_vintage_v3_nn(vintage, feature_selection, model, cutoff_date, cutoff_series, stationary_dict, epochs, batch_size, drop_log_series):\n",
    "    '''\n",
    "    Will perform a nowcast from a specified vintage. \n",
    "    \n",
    "    Series from a specific feature selection and the model can be specified, alongside which cutoff series and df to use.\n",
    "    '''\n",
    "    # create vintages of each frequency\n",
    "    ip_vint, daily_vint, weekly_vint = vintagiser(ip_release_dates, vintage)\n",
    "    # perform higher frequency aggregation - data out to the end of the month extrapolated (no forecasts)\n",
    "    daily_vint = aggregator_avg_daily(daily_vint, agg_daily)\n",
    "    weekly_vint = aggregator_avg_weekly(weekly_vint, agg_weekly)\n",
    "    # combine dfs and wrangle data\n",
    "    combined_df = pd.concat([ip_vint, daily_vint, weekly_vint], axis=1)\n",
    "    vint_df = combined_df.loc[cutoff_date:,cutoff_series]\n",
    "    vint_df.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "    \n",
    "    # take logs\n",
    "    log_series = {}\n",
    "    for i in vint_df.columns:\n",
    "        log_series[i] = np.log(vint_df[i])\n",
    "\n",
    "    vint_df = pd.DataFrame(log_series, index = vint_df.index)\n",
    "    vint_df = vint_df.drop(drop_log_series, axis=1)\n",
    "    \n",
    "    # take differences to make the data stationary\n",
    "    stationary_vars = {}\n",
    "    for i in vint_df.columns:\n",
    "        if i in stationary_dict[1]:\n",
    "            stationary_vars[i] = vint_df[i].diff()\n",
    "        else:\n",
    "            stationary_vars[i] = vint_df[i]\n",
    "    vint_df = pd.DataFrame(stationary_vars)\n",
    "    # remove the NaNs from the first two rows caused by differencing\n",
    "    vint_df = vint_df.iloc[2:]\n",
    "    \n",
    "    # cut df into the vintage and higher frequency data for nowcast\n",
    "    vint_cut = vint_df.loc[:vint_df['INDPRO'].last_valid_index()]\n",
    "    nowcast_df = vint_df.loc[vint_df['INDPRO'].last_valid_index() < vint_df.index]\n",
    "    # \n",
    "    y = vint_cut['INDPRO']\n",
    "    x = vint_cut[feature_selection]\n",
    "    \n",
    "    # scale the inputs\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    x_minmax = min_max_scaler.fit_transform(x)\n",
    "    \n",
    "    fit = model.fit(x_minmax,y, epochs = epochs, batch_size = batch_size, verbose = 0)\n",
    "    # setup the nowcast df with features and index\n",
    "    x_nowcast = nowcast_df[feature_selection]\n",
    "    x_nowcast_minmax = min_max_scaler.transform(x_nowcast)\n",
    "    # if nowcast df only contains one month of nowcast adjust so it only predicts one row\n",
    "    try:\n",
    "        yhat = model.predict(x_nowcast_minmax)\n",
    "        yhat = pd.DataFrame(yhat, index = x_nowcast.index)\n",
    "    # reaches the except when not all HF series have data available for that month yet - then just takes the first row.\n",
    "    except ValueError:\n",
    "        try:\n",
    "            index = x_nowcast.index[0]\n",
    "            x_nowcast = x_nowcast.iloc[0]\n",
    "            x_nowcast = x_nowcast.values.reshape(1,-1)\n",
    "            \n",
    "            x_nowcast_minmax = min_max_scaler.transform(x_nowcast)\n",
    "            \n",
    "            yhat = model.predict(x_nowcast_minmax)\n",
    "            yhat = pd.DataFrame(yhat, index = [index])\n",
    "        except ValueError:\n",
    "            return\n",
    "\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_nowcast_v3_nn(periods, vintage, fs, model, cutoff_date, cutoff_series, stationary_dict, epochs, batch_size, drop_log_series):\n",
    "    '''\n",
    "    Performs nowcasts over a rolling basis, starting from the vintage specified for the number of periods specified.\n",
    "    '''\n",
    "    count = 0\n",
    "    nowcast_dict = {}\n",
    "    while count < periods:\n",
    "        nowcast = nowcast_vintage_v3_nn(vintage, fs, model, cutoff_date, cutoff_series, stationary_dict, epochs, batch_size, drop_log_series)\n",
    "        nowcast_dict[vintage] = nowcast\n",
    "        vintage += datetime.timedelta(1)\n",
    "        count +=1\n",
    "    return nowcast_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nowcast_vintage_load_nn(vintage, feature_selection, model_file, cutoff_date, cutoff_series, stationary_dict, drop_log_series):\n",
    "    '''\n",
    "    Will perform a nowcast from a specified vintage. \n",
    "    \n",
    "    Series from a specific feature selection and the model can be specified, alongside which cutoff series and df to use.\n",
    "    '''\n",
    "    # create vintages of each frequency\n",
    "    ip_vint, daily_vint, weekly_vint = vintagiser(ip_release_dates, vintage)\n",
    "    # perform higher frequency aggregation - data out to the end of the month extrapolated (no forecasts)\n",
    "    daily_vint = aggregator_avg_daily(daily_vint, agg_daily)\n",
    "    weekly_vint = aggregator_avg_weekly(weekly_vint, agg_weekly)\n",
    "    # combine dfs and wrangle data\n",
    "    combined_df = pd.concat([ip_vint, daily_vint, weekly_vint], axis=1)\n",
    "    vint_df = combined_df.loc[cutoff_date:,cutoff_series]\n",
    "    vint_df.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "    \n",
    "    # take logs\n",
    "    log_series = {}\n",
    "    for i in vint_df.columns:\n",
    "        log_series[i] = np.log(vint_df[i])\n",
    "\n",
    "    vint_df = pd.DataFrame(log_series, index = vint_df.index)\n",
    "    vint_df = vint_df.drop(drop_log_series, axis=1)\n",
    "    \n",
    "    # take differences to make the data stationary\n",
    "    stationary_vars = {}\n",
    "    for i in vint_df.columns:\n",
    "        if i in stationary_dict[1]:\n",
    "            stationary_vars[i] = vint_df[i].diff()\n",
    "        else:\n",
    "            stationary_vars[i] = vint_df[i]\n",
    "    vint_df = pd.DataFrame(stationary_vars)\n",
    "    # remove the NaNs from the first two rows caused by differencing\n",
    "    vint_df = vint_df.iloc[2:]\n",
    "    \n",
    "    # cut df into the vintage and higher frequency data for nowcast\n",
    "    vint_cut = vint_df.loc[:vint_df['INDPRO'].last_valid_index()]\n",
    "    nowcast_df = vint_df.loc[vint_df['INDPRO'].last_valid_index() < vint_df.index]\n",
    "    # \n",
    "    y = vint_cut['INDPRO']\n",
    "    x = vint_cut[feature_selection]\n",
    "    \n",
    "    # scale the inputs\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    x_minmax = min_max_scaler.fit_transform(x)\n",
    "    \n",
    "    model = tf.keras.models.load_model(model_file)\n",
    "    # setup the nowcast df with features and index\n",
    "    x_nowcast = nowcast_df[feature_selection]\n",
    "    x_nowcast_minmax = min_max_scaler.transform(x_nowcast)\n",
    "    # if nowcast df only contains one month of nowcast adjust so it only predicts one row\n",
    "    try:\n",
    "        yhat = model.predict(x_nowcast_minmax)\n",
    "        yhat = pd.DataFrame(yhat, index = x_nowcast.index)\n",
    "    # reaches the except when not all HF series have data available for that month yet - then just takes the first row.\n",
    "    except ValueError:\n",
    "        try:\n",
    "            index = x_nowcast.index[0]\n",
    "            x_nowcast = x_nowcast.iloc[0]\n",
    "            x_nowcast = x_nowcast.values.reshape(1,-1)\n",
    "            \n",
    "            x_nowcast_minmax = min_max_scaler.transform(x_nowcast)\n",
    "            \n",
    "            yhat = model.predict(x_nowcast_minmax)\n",
    "            yhat = pd.DataFrame(yhat, index = [index])\n",
    "        except ValueError:\n",
    "            return\n",
    "\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_nowcast_load_nn(periods, vintage, fs, model_file, cutoff_date, cutoff_series, stationary_dict, drop_log_series):\n",
    "    '''\n",
    "    Performs nowcasts over a rolling basis, starting from the vintage specified for the number of periods specified.\n",
    "    '''\n",
    "    count = 0\n",
    "    nowcast_dict = {}\n",
    "    while count < periods:\n",
    "        nowcast = nowcast_vintage_load_nn(vintage, fs, model_file, cutoff_date, cutoff_series, stationary_dict, drop_log_series)\n",
    "        nowcast_dict[vintage] = nowcast\n",
    "        vintage += datetime.timedelta(1)\n",
    "        count +=1\n",
    "    return nowcast_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps):\n",
    "    '''\n",
    "    sequences - data to split\n",
    "    n_steps - size of window\n",
    "    y variable should be the first column of y\n",
    "    \n",
    "    adapted from https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/\n",
    "    '''\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, 1:], sequences[end_ix-1, 0]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nowcast_vintage_lstm(vintage, feature_selection, cutoff_date, cutoff_series, stationary_dict, nodes, epochs, batch_size, drop_log_series, windows, scaler):\n",
    "    '''\n",
    "    Will perform a nowcast from a specified vintage. \n",
    "    \n",
    "    Series from a specific feature selection and the model can be specified, alongside which cutoff series and df to use.\n",
    "    '''\n",
    "    # create vintages of each frequency\n",
    "    ip_vint, daily_vint, weekly_vint = vintagiser(ip_release_dates, vintage)\n",
    "    # perform higher frequency aggregation - data out to the end of the month extrapolated (no forecasts)\n",
    "    daily_vint = aggregator_avg_daily(daily_vint, agg_daily)\n",
    "    weekly_vint = aggregator_avg_weekly(weekly_vint, agg_weekly)\n",
    "    # combine dfs and wrangle data\n",
    "    combined_df = pd.concat([ip_vint, daily_vint, weekly_vint], axis=1)\n",
    "    vint_df = combined_df.loc[cutoff_date:,cutoff_series]\n",
    "    vint_df.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "    \n",
    "    # take logs\n",
    "    log_series = {}\n",
    "    for i in vint_df.columns:\n",
    "        log_series[i] = np.log(vint_df[i])\n",
    "\n",
    "    vint_df = pd.DataFrame(log_series, index = vint_df.index)\n",
    "    vint_df = vint_df.drop(drop_log_series, axis=1)\n",
    "    \n",
    "    # take differences to make the data stationary\n",
    "    stationary_vars = {}\n",
    "    for i in vint_df.columns:\n",
    "        if i in stationary_dict[1]:\n",
    "            stationary_vars[i] = vint_df[i].diff()\n",
    "        else:\n",
    "            stationary_vars[i] = vint_df[i]\n",
    "    vint_df = pd.DataFrame(stationary_vars)\n",
    "    # remove the NaNs from the first two rows caused by differencing\n",
    "    vint_df = vint_df.iloc[2:]\n",
    "    \n",
    "    vint_df = pd.concat([vint_df['INDPRO'], vint_df[feature_selection]], axis=1)\n",
    "    \n",
    "    # work out how many periods of IP have NaNs\n",
    "    \n",
    "    nowcast_index = vint_df.loc[vint_df['INDPRO'].last_valid_index():].index[1:]\n",
    "    to_nowcast = vint_df.loc[:vint_df['INDPRO'].last_valid_index()].shape[0]\n",
    "    print(to_nowcast)\n",
    "    print(nowcast_index)\n",
    "    #nowcast_df = vint_df.loc[vint_df['INDPRO'].last_valid_index() < vint_df.index]\n",
    "    \n",
    "    # scale the data\n",
    "#     min_max_scaler = MinMaxScaler()\n",
    "#     data_scld = min_max_scaler.fit_transform(vint_df)\n",
    "\n",
    "    # new scaling\n",
    "    data_scld = scaler.transform(vint_df)\n",
    "    \n",
    "    # create windows\n",
    "    x,y = split_sequences(data_scld, windows)\n",
    "    \n",
    "    # split into train sets and series to nowcast\n",
    "    x_train = x[:to_nowcast]\n",
    "    y_train = y[:to_nowcast]\n",
    "    \n",
    "    x_nowcast = x[to_nowcast:]\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(nodes, activation='relu', input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=False))\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    fit = model.fit(x_train,y_train, epochs = epochs, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "    # if nowcast df only contains one month of nowcast adjust so it only predicts one row\n",
    "    try:\n",
    "        yhat = model.predict(x_nowcast)\n",
    "        yhat = pd.DataFrame(yhat, index = nowcast_index)\n",
    "    # reaches the except when not all HF series have data available for that month yet - then just takes the first row.\n",
    "    except ValueError:\n",
    "        try:\n",
    "            index = x_nowcast.index[0]\n",
    "            x_nowcast = x_nowcast.iloc[0]\n",
    "            x_nowcast = x_nowcast.values.reshape(1,-1)\n",
    "            \n",
    "#             x_nowcast_minmax = min_max_scaler.transform(x_nowcast)\n",
    "            \n",
    "            yhat = model.predict(x_nowcast)\n",
    "            yhat = pd.DataFrame(yhat, index = [index])\n",
    "        except ValueError:\n",
    "            return\n",
    "\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_nowcast_lstm(periods, vintage, fs, cutoff_date, cutoff_series, stationary_dict, nodes, epochs, batch_size, drop_log_series, windows, scaler):\n",
    "    '''\n",
    "    Performs nowcasts over a rolling basis, starting from the vintage specified for the number of periods specified.\n",
    "    '''\n",
    "    count = 0\n",
    "    nowcast_dict = {}\n",
    "    while count < periods:\n",
    "        nowcast = nowcast_vintage_lstm(vintage, fs, cutoff_date, cutoff_series, stationary_dict, nodes, epochs, batch_size, drop_log_series, windows, scaler)\n",
    "        nowcast_dict[vintage] = nowcast\n",
    "        vintage += datetime.timedelta(1)\n",
    "        count +=1\n",
    "    return nowcast_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nowcast_vintage_load_lstm_copy(vintage, feature_selection, model_file, cutoff_date, cutoff_series, stationary_dict, drop_log_series):\n",
    "    '''\n",
    "    Will perform a nowcast from a specified vintage. \n",
    "    \n",
    "    Series from a specific feature selection and the model can be specified, alongside which cutoff series and df to use.\n",
    "    '''\n",
    "    # create vintages of each frequency\n",
    "    ip_vint, daily_vint, weekly_vint = vintagiser(ip_release_dates, vintage)\n",
    "    # perform higher frequency aggregation - data out to the end of the month extrapolated (no forecasts)\n",
    "    daily_vint = aggregator_avg_daily(daily_vint, agg_daily)\n",
    "    weekly_vint = aggregator_avg_weekly(weekly_vint, agg_weekly)\n",
    "    # combine dfs and wrangle data\n",
    "    combined_df = pd.concat([ip_vint, daily_vint, weekly_vint], axis=1)\n",
    "    vint_df = combined_df.loc[cutoff_date:,cutoff_series]\n",
    "    vint_df.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "    \n",
    "    # take logs\n",
    "    log_series = {}\n",
    "    for i in vint_df.columns:\n",
    "        log_series[i] = np.log(vint_df[i])\n",
    "\n",
    "    vint_df = pd.DataFrame(log_series, index = vint_df.index)\n",
    "    vint_df = vint_df.drop(drop_log_series, axis=1)\n",
    "    \n",
    "    # take differences to make the data stationary\n",
    "    stationary_vars = {}\n",
    "    for i in vint_df.columns:\n",
    "        if i in stationary_dict[1]:\n",
    "            stationary_vars[i] = vint_df[i].diff()\n",
    "        else:\n",
    "            stationary_vars[i] = vint_df[i]\n",
    "    vint_df = pd.DataFrame(stationary_vars)\n",
    "    # remove the NaNs from the first two rows caused by differencing\n",
    "    vint_df = vint_df.iloc[2:]\n",
    "    \n",
    "    vint_df = pd.concat([vint_df['INDPRO'], vint_df[feature_selection]], axis=1)\n",
    "    \n",
    "    # work out how many periods of IP have NaNs\n",
    "    to_nowcast = vint_df.loc[:vint_df['INDPRO'].last_valid_index()].shape[1]\n",
    "    #nowcast_df = vint_df.loc[vint_df['INDPRO'].last_valid_index() < vint_df.index]\n",
    "    \n",
    "    # scale the data\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    data_scld = min_max_scaler.fit_transform(vint_df)\n",
    "    \n",
    "    # create windows\n",
    "    x,y = split_sequences(data_scld, windows)\n",
    "    \n",
    "    # split into train sets and series to nowcast\n",
    "    x_train = x[:to_nowcast]\n",
    "    y_train = y[:to_nowcast]\n",
    "    \n",
    "    x_nowcast = x[to_nowcast:]\n",
    "    \n",
    "    # create model\n",
    "    model = tf.keras.models.load_model(model_file)\n",
    "\n",
    "    # if nowcast df only contains one month of nowcast adjust so it only predicts one row\n",
    "    try:\n",
    "        yhat = model.predict(x_nowcast)\n",
    "        yhat = pd.DataFrame(yhat, index = x_nowcast.index)\n",
    "    # reaches the except when not all HF series have data available for that month yet - then just takes the first row.\n",
    "    except ValueError:\n",
    "        try:\n",
    "            index = x_nowcast.index[0]\n",
    "            x_nowcast = x_nowcast.iloc[0]\n",
    "            x_nowcast = x_nowcast.values.reshape(1,-1)\n",
    "            \n",
    "            x_nowcast_minmax = min_max_scaler.transform(x_nowcast)\n",
    "            \n",
    "            yhat = model.predict(x_nowcast_minmax)\n",
    "            yhat = pd.DataFrame(yhat, index = [index])\n",
    "        except ValueError:\n",
    "            return\n",
    "\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nowcast_vintage_load_lstm(vintage, feature_selection, model_file, cutoff_date, cutoff_series, stationary_dict, drop_log_series, windows, scaler):\n",
    "    '''\n",
    "    Will perform a nowcast from a specified vintage. \n",
    "    \n",
    "    Series from a specific feature selection and the model can be specified, alongside which cutoff series and df to use.\n",
    "    '''\n",
    "    # create vintages of each frequency\n",
    "    ip_vint, daily_vint, weekly_vint = vintagiser(ip_release_dates, vintage)\n",
    "    # perform higher frequency aggregation - data out to the end of the month extrapolated (no forecasts)\n",
    "    daily_vint = aggregator_avg_daily(daily_vint, agg_daily)\n",
    "    weekly_vint = aggregator_avg_weekly(weekly_vint, agg_weekly)\n",
    "    # combine dfs and wrangle data\n",
    "    combined_df = pd.concat([ip_vint, daily_vint, weekly_vint], axis=1)\n",
    "    vint_df = combined_df.loc[cutoff_date:,cutoff_series]\n",
    "    vint_df.interpolate(method = 'linear', limit_direction = 'backward', inplace = True)\n",
    "    \n",
    "    # take logs\n",
    "    log_series = {}\n",
    "    for i in vint_df.columns:\n",
    "        log_series[i] = np.log(vint_df[i])\n",
    "\n",
    "    vint_df = pd.DataFrame(log_series, index = vint_df.index)\n",
    "    vint_df = vint_df.drop(drop_log_series, axis=1)\n",
    "    \n",
    "    # take differences to make the data stationary\n",
    "    stationary_vars = {}\n",
    "    for i in vint_df.columns:\n",
    "        if i in stationary_dict[1]:\n",
    "            stationary_vars[i] = vint_df[i].diff()\n",
    "        else:\n",
    "            stationary_vars[i] = vint_df[i]\n",
    "    vint_df = pd.DataFrame(stationary_vars)\n",
    "    # remove the NaNs from the first two rows caused by differencing\n",
    "    vint_df = vint_df.iloc[2:]\n",
    "    \n",
    "    vint_df = pd.concat([vint_df['INDPRO'], vint_df[feature_selection]], axis=1)\n",
    "    \n",
    "    # work out how many periods of IP have NaNs\n",
    "    nowcast_index = vint_df.loc[vint_df['INDPRO'].last_valid_index():].index[1:]\n",
    "    to_nowcast = vint_df.loc[:vint_df['INDPRO'].last_valid_index()].shape[0]\n",
    "    print(to_nowcast)\n",
    "    print(nowcast_index)\n",
    "    \n",
    "    # scale the data\n",
    "#     min_max_scaler = MinMaxScaler()\n",
    "#     data_scld = min_max_scaler.fit_transform(vint_df)\n",
    "\n",
    "    # new scaling\n",
    "    data_scld = scaler.transform(vint_df)\n",
    "    \n",
    "    # create windows\n",
    "    x,y = split_sequences(data_scld, windows)\n",
    "    \n",
    "    # split into train sets and series to nowcast\n",
    "    x_train = x[:to_nowcast]\n",
    "    y_train = y[:to_nowcast]\n",
    "    \n",
    "    x_nowcast = x[to_nowcast:]\n",
    "    \n",
    "    # create model\n",
    "    model = tf.keras.models.load_model(model_file)\n",
    "\n",
    "    # if nowcast df only contains one month of nowcast adjust so it only predicts one row\n",
    "    try:\n",
    "        yhat = model.predict(x_nowcast)\n",
    "        yhat = pd.DataFrame(yhat, index = nowcast_index)\n",
    "    # reaches the except when not all HF series have data available for that month yet - then just takes the first row.\n",
    "    except ValueError:\n",
    "        try:\n",
    "            index = x_nowcast.index[0]\n",
    "            x_nowcast = x_nowcast.iloc[0]\n",
    "            x_nowcast = x_nowcast.values.reshape(1,-1)\n",
    "            \n",
    "            x_nowcast_minmax = min_max_scaler.transform(x_nowcast)\n",
    "            \n",
    "            yhat = model.predict(x_nowcast_minmax)\n",
    "            yhat = pd.DataFrame(yhat, index = [index])\n",
    "        except ValueError:\n",
    "            return\n",
    "\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_nowcast_load_lstm(periods, vintage, fs, model_file, cutoff_date, cutoff_series, stationary_dict, drop_log_series, windows, scaler):\n",
    "    '''\n",
    "    Performs nowcasts over a rolling basis, starting from the vintage specified for the number of periods specified.\n",
    "    '''\n",
    "    count = 0\n",
    "    nowcast_dict = {}\n",
    "    while count < periods:\n",
    "        nowcast = nowcast_vintage_load_lstm(vintage, fs, model_file, cutoff_date, cutoff_series, stationary_dict, drop_log_series, windows, scaler)\n",
    "        nowcast_dict[vintage] = nowcast\n",
    "        vintage += datetime.timedelta(1)\n",
    "        count +=1\n",
    "    return nowcast_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
